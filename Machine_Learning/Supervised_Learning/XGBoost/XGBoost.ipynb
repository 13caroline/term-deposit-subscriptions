{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1\n",
    "#### Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.37521</td>\n",
       "      <td>-0.756929</td>\n",
       "      <td>-1.925779</td>\n",
       "      <td>0.580938</td>\n",
       "      <td>-0.515445</td>\n",
       "      <td>0.939376</td>\n",
       "      <td>-0.453565</td>\n",
       "      <td>-0.763196</td>\n",
       "      <td>1.192581</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.561357</td>\n",
       "      <td>0.196894</td>\n",
       "      <td>-0.348973</td>\n",
       "      <td>0.188003</td>\n",
       "      <td>-0.118566</td>\n",
       "      <td>-0.651221</td>\n",
       "      <td>-0.324357</td>\n",
       "      <td>0.259352</td>\n",
       "      <td>0.395979</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.37521</td>\n",
       "      <td>1.471189</td>\n",
       "      <td>-0.283258</td>\n",
       "      <td>-0.824024</td>\n",
       "      <td>-0.515445</td>\n",
       "      <td>0.939376</td>\n",
       "      <td>-0.453565</td>\n",
       "      <td>1.310279</td>\n",
       "      <td>-0.098471</td>\n",
       "      <td>-0.713715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148956</td>\n",
       "      <td>0.196894</td>\n",
       "      <td>-0.348973</td>\n",
       "      <td>0.188003</td>\n",
       "      <td>0.837519</td>\n",
       "      <td>1.529013</td>\n",
       "      <td>-0.281151</td>\n",
       "      <td>0.769787</td>\n",
       "      <td>0.843536</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.37521</td>\n",
       "      <td>0.078615</td>\n",
       "      <td>-0.283258</td>\n",
       "      <td>1.049258</td>\n",
       "      <td>-0.515445</td>\n",
       "      <td>0.939376</td>\n",
       "      <td>-0.453565</td>\n",
       "      <td>-0.763196</td>\n",
       "      <td>-1.389523</td>\n",
       "      <td>1.432715</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.561357</td>\n",
       "      <td>0.196894</td>\n",
       "      <td>-0.348973</td>\n",
       "      <td>0.188003</td>\n",
       "      <td>0.837519</td>\n",
       "      <td>-0.230686</td>\n",
       "      <td>0.950220</td>\n",
       "      <td>0.773829</td>\n",
       "      <td>0.843536</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.37521</td>\n",
       "      <td>-0.756929</td>\n",
       "      <td>-0.283258</td>\n",
       "      <td>-0.824024</td>\n",
       "      <td>-0.515445</td>\n",
       "      <td>-1.090085</td>\n",
       "      <td>-0.453565</td>\n",
       "      <td>1.310279</td>\n",
       "      <td>1.192581</td>\n",
       "      <td>1.432715</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206200</td>\n",
       "      <td>0.196894</td>\n",
       "      <td>-0.348973</td>\n",
       "      <td>0.188003</td>\n",
       "      <td>-0.118566</td>\n",
       "      <td>-0.651221</td>\n",
       "      <td>-0.324357</td>\n",
       "      <td>0.284758</td>\n",
       "      <td>0.395979</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37521</td>\n",
       "      <td>-1.035444</td>\n",
       "      <td>-1.925779</td>\n",
       "      <td>1.049258</td>\n",
       "      <td>1.938451</td>\n",
       "      <td>0.939376</td>\n",
       "      <td>-0.453565</td>\n",
       "      <td>1.310279</td>\n",
       "      <td>0.762230</td>\n",
       "      <td>-0.713715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.859269</td>\n",
       "      <td>0.196894</td>\n",
       "      <td>-0.348973</td>\n",
       "      <td>0.188003</td>\n",
       "      <td>0.646302</td>\n",
       "      <td>0.717242</td>\n",
       "      <td>0.885411</td>\n",
       "      <td>0.710313</td>\n",
       "      <td>0.329470</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age       job   marital  education   default   housing      loan  \\\n",
       "0  0.37521 -0.756929 -1.925779   0.580938 -0.515445  0.939376 -0.453565   \n",
       "1  0.37521  1.471189 -0.283258  -0.824024 -0.515445  0.939376 -0.453565   \n",
       "2  0.37521  0.078615 -0.283258   1.049258 -0.515445  0.939376 -0.453565   \n",
       "3  0.37521 -0.756929 -0.283258  -0.824024 -0.515445 -1.090085 -0.453565   \n",
       "4  0.37521 -1.035444 -1.925779   1.049258  1.938451  0.939376 -0.453565   \n",
       "\n",
       "    contact     month  day_of_week  ...  campaign     pdays  previous  \\\n",
       "0 -0.763196  1.192581     0.001762  ... -0.561357  0.196894 -0.348973   \n",
       "1  1.310279 -0.098471    -0.713715  ...  0.148956  0.196894 -0.348973   \n",
       "2 -0.763196 -1.389523     1.432715  ... -0.561357  0.196894 -0.348973   \n",
       "3  1.310279  1.192581     1.432715  ... -0.206200  0.196894 -0.348973   \n",
       "4  1.310279  0.762230    -0.713715  ...  0.859269  0.196894 -0.348973   \n",
       "\n",
       "   poutcome  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
       "0  0.188003     -0.118566       -0.651221      -0.324357   0.259352   \n",
       "1  0.188003      0.837519        1.529013      -0.281151   0.769787   \n",
       "2  0.188003      0.837519       -0.230686       0.950220   0.773829   \n",
       "3  0.188003     -0.118566       -0.651221      -0.324357   0.284758   \n",
       "4  0.188003      0.646302        0.717242       0.885411   0.710313   \n",
       "\n",
       "   nr.employed  y  \n",
       "0     0.395979  0  \n",
       "1     0.843536  0  \n",
       "2     0.843536  0  \n",
       "3     0.395979  0  \n",
       "4     0.329470  0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_m1 = pd.read_csv('../../../../Data_AA2/train_m1.csv', sep = ',')\n",
    "train_m1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.37521</td>\n",
       "      <td>1.471189</td>\n",
       "      <td>-0.283258</td>\n",
       "      <td>0.580938</td>\n",
       "      <td>-0.515445</td>\n",
       "      <td>0.939376</td>\n",
       "      <td>-0.453565</td>\n",
       "      <td>1.310279</td>\n",
       "      <td>0.762230</td>\n",
       "      <td>0.717238</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.561357</td>\n",
       "      <td>0.196894</td>\n",
       "      <td>-0.348973</td>\n",
       "      <td>0.188003</td>\n",
       "      <td>0.646302</td>\n",
       "      <td>0.717242</td>\n",
       "      <td>0.885411</td>\n",
       "      <td>0.710313</td>\n",
       "      <td>0.329470</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.37521</td>\n",
       "      <td>0.914159</td>\n",
       "      <td>-1.925779</td>\n",
       "      <td>-0.355703</td>\n",
       "      <td>-0.515445</td>\n",
       "      <td>-1.090085</td>\n",
       "      <td>-0.453565</td>\n",
       "      <td>1.310279</td>\n",
       "      <td>0.762230</td>\n",
       "      <td>1.432715</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.561357</td>\n",
       "      <td>0.196894</td>\n",
       "      <td>-0.348973</td>\n",
       "      <td>0.188003</td>\n",
       "      <td>0.646302</td>\n",
       "      <td>0.717242</td>\n",
       "      <td>0.885411</td>\n",
       "      <td>0.709736</td>\n",
       "      <td>0.329470</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.37521</td>\n",
       "      <td>1.471189</td>\n",
       "      <td>-0.283258</td>\n",
       "      <td>0.580938</td>\n",
       "      <td>1.938451</td>\n",
       "      <td>0.939376</td>\n",
       "      <td>-0.453565</td>\n",
       "      <td>1.310279</td>\n",
       "      <td>0.762230</td>\n",
       "      <td>-1.429191</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.561357</td>\n",
       "      <td>0.196894</td>\n",
       "      <td>-0.348973</td>\n",
       "      <td>0.188003</td>\n",
       "      <td>0.646302</td>\n",
       "      <td>0.717242</td>\n",
       "      <td>0.885411</td>\n",
       "      <td>0.711468</td>\n",
       "      <td>0.329470</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.37521</td>\n",
       "      <td>-0.756929</td>\n",
       "      <td>1.359263</td>\n",
       "      <td>-1.760665</td>\n",
       "      <td>-0.515445</td>\n",
       "      <td>-1.090085</td>\n",
       "      <td>-0.453565</td>\n",
       "      <td>-0.763196</td>\n",
       "      <td>0.762230</td>\n",
       "      <td>1.432715</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.561357</td>\n",
       "      <td>0.196894</td>\n",
       "      <td>1.662067</td>\n",
       "      <td>-2.562036</td>\n",
       "      <td>-1.202130</td>\n",
       "      <td>-1.180338</td>\n",
       "      <td>-1.231682</td>\n",
       "      <td>-1.354522</td>\n",
       "      <td>-0.943918</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37521</td>\n",
       "      <td>-1.035444</td>\n",
       "      <td>-0.283258</td>\n",
       "      <td>1.049258</td>\n",
       "      <td>1.938451</td>\n",
       "      <td>0.939376</td>\n",
       "      <td>-0.453565</td>\n",
       "      <td>-0.763196</td>\n",
       "      <td>-1.389523</td>\n",
       "      <td>0.717238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148956</td>\n",
       "      <td>0.196894</td>\n",
       "      <td>-0.348973</td>\n",
       "      <td>0.188003</td>\n",
       "      <td>0.837519</td>\n",
       "      <td>-0.230686</td>\n",
       "      <td>0.950220</td>\n",
       "      <td>0.771519</td>\n",
       "      <td>0.843536</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age       job   marital  education   default   housing      loan  \\\n",
       "0  0.37521  1.471189 -0.283258   0.580938 -0.515445  0.939376 -0.453565   \n",
       "1  0.37521  0.914159 -1.925779  -0.355703 -0.515445 -1.090085 -0.453565   \n",
       "2  0.37521  1.471189 -0.283258   0.580938  1.938451  0.939376 -0.453565   \n",
       "3  0.37521 -0.756929  1.359263  -1.760665 -0.515445 -1.090085 -0.453565   \n",
       "4  0.37521 -1.035444 -0.283258   1.049258  1.938451  0.939376 -0.453565   \n",
       "\n",
       "    contact     month  day_of_week  ...  campaign     pdays  previous  \\\n",
       "0  1.310279  0.762230     0.717238  ... -0.561357  0.196894 -0.348973   \n",
       "1  1.310279  0.762230     1.432715  ... -0.561357  0.196894 -0.348973   \n",
       "2  1.310279  0.762230    -1.429191  ... -0.561357  0.196894 -0.348973   \n",
       "3 -0.763196  0.762230     1.432715  ... -0.561357  0.196894  1.662067   \n",
       "4 -0.763196 -1.389523     0.717238  ...  0.148956  0.196894 -0.348973   \n",
       "\n",
       "   poutcome  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
       "0  0.188003      0.646302        0.717242       0.885411   0.710313   \n",
       "1  0.188003      0.646302        0.717242       0.885411   0.709736   \n",
       "2  0.188003      0.646302        0.717242       0.885411   0.711468   \n",
       "3 -2.562036     -1.202130       -1.180338      -1.231682  -1.354522   \n",
       "4  0.188003      0.837519       -0.230686       0.950220   0.771519   \n",
       "\n",
       "   nr.employed  y  \n",
       "0     0.329470  0  \n",
       "1     0.329470  0  \n",
       "2     0.329470  0  \n",
       "3    -0.943918  0  \n",
       "4     0.843536  0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_m1 = pd.read_csv('../../../../Data_AA2/test_m1.csv', sep = ',')\n",
    "test_m1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get target\n",
    "train_m1_target = train_m1['y']\n",
    "train_m1 = train_m1.drop(columns=['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get target\n",
    "test_m1_target = test_m1['y']\n",
    "test_m1 = test_m1.drop(columns=['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for lower errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/49 [00:00<?, ?it/s]C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:03:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "\r",
      "  2%|█▋                                                                                 | 1/49 [00:00<00:13,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:03:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▍                                                                               | 2/49 [00:00<00:14,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:03:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|█████                                                                              | 3/49 [00:01<00:16,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:03:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▊                                                                            | 4/49 [00:01<00:19,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:03:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▍                                                                          | 5/49 [00:02<00:23,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:03:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|██████████▏                                                                        | 6/49 [00:03<00:27,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:04:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▊                                                                       | 7/49 [00:04<00:32,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:04:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████████████▌                                                                     | 8/49 [00:05<00:36,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:04:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|███████████████▏                                                                   | 9/49 [00:07<00:42,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:04:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▋                                                                 | 10/49 [00:08<00:48,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:04:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██████████████████▍                                                               | 11/49 [00:10<00:54,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:04:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|████████████████████                                                              | 12/49 [00:12<01:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:04:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|█████████████████████▊                                                            | 13/49 [00:15<01:07,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:04:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|███████████████████████▍                                                          | 14/49 [00:17<01:12,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:04:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████                                                         | 15/49 [00:20<01:16,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:04:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████▊                                                       | 16/49 [00:23<01:19,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:04:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████▍                                                     | 17/49 [00:26<01:25,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:04:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|██████████████████████████████                                                    | 18/49 [00:29<01:29,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:04:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███████████████████████████████▊                                                  | 19/49 [00:33<01:31,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:04:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|█████████████████████████████████▍                                                | 20/49 [00:36<01:29,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:04:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|███████████████████████████████████▏                                              | 21/49 [00:39<01:27,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:04:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████████████████████████████████████▊                                             | 22/49 [00:43<01:28,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:04:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|██████████████████████████████████████▍                                           | 23/49 [00:46<01:27,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:04:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████████████████████████████████████████▏                                         | 24/49 [00:50<01:25,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:04:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████████████████████████████████████████▊                                        | 25/49 [00:54<01:24,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:04:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|███████████████████████████████████████████▌                                      | 26/49 [00:57<01:22,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:04:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████████████████████████████████████████████▏                                    | 27/49 [01:01<01:20,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:04:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|██████████████████████████████████████████████▊                                   | 28/49 [01:05<01:17,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:05:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|████████████████████████████████████████████████▌                                 | 29/49 [01:09<01:17,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:05:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████████████████████████████████████████████████▏                               | 30/49 [01:13<01:12,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:05:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|███████████████████████████████████████████████████▉                              | 31/49 [01:17<01:11,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:05:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|█████████████████████████████████████████████████████▌                            | 32/49 [01:22<01:11,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:05:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|███████████████████████████████████████████████████████▏                          | 33/49 [01:26<01:06,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:05:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|████████████████████████████████████████████████████████▉                         | 34/49 [01:30<01:00,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:05:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|██████████████████████████████████████████████████████████▌                       | 35/49 [01:34<00:58,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:05:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|████████████████████████████████████████████████████████████▏                     | 36/49 [01:39<00:55,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:05:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|█████████████████████████████████████████████████████████████▉                    | 37/49 [01:43<00:49,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:05:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████████████████████████████████████████████████████████████▌                  | 38/49 [01:47<00:45,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:05:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▎                | 39/49 [01:51<00:39,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:05:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|██████████████████████████████████████████████████████████████████▉               | 40/49 [01:55<00:36,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:05:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████████████████████████████████████████████████████████████████▌             | 41/49 [01:58<00:31,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:05:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|██████████████████████████████████████████████████████████████████████▎           | 42/49 [02:02<00:27,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:06:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|███████████████████████████████████████████████████████████████████████▉          | 43/49 [02:06<00:23,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:06:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████████████████████████████████████████████████████████▋        | 44/49 [02:10<00:19,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:06:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|███████████████████████████████████████████████████████████████████████████▎      | 45/49 [02:14<00:15,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:06:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|████████████████████████████████████████████████████████████████████████████▉     | 46/49 [02:17<00:11,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:06:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|██████████████████████████████████████████████████████████████████████████████▋   | 47/49 [02:21<00:07,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:06:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|████████████████████████████████████████████████████████████████████████████████▎ | 48/49 [02:25<00:03,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:06:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [02:29<00:00,  3.04s/it]\n"
     ]
    }
   ],
   "source": [
    "error_rate = []\n",
    "\n",
    "for i in tqdm(range(1,50)):\n",
    "    xgb = XGBClassifier(max_depth=i)\n",
    "    xgb.fit(train_m1,train_m1_target)\n",
    "    predictions = xgb.predict(test_m1)\n",
    "    error_rate.append(np.mean(predictions != test_m1_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Error Rate')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(25,6))\n",
    "plt.plot(range(1,50),error_rate,color='blue',linestyle='dashed',marker='o',markerfacecolor='red',markersize=10)\n",
    "plt.title('Error Rate vs DepthValue')\n",
    "plt.xlabel(\"depth\")\n",
    "plt.ylabel(\"Error Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "[CV 1/5; 1/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:08:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 1/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 1/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:08:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 1/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 1/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:08:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 1/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 1/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:08:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 1/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 1/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:08:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 1/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 2/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:08:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 2/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.1s\n",
      "[CV 2/5; 2/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:08:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 2/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 2/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:08:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 2/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 2/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:08:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 2/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.1s\n",
      "[CV 5/5; 2/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:08:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 2/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.1s\n",
      "[CV 1/5; 3/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:08:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 3/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 3/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:08:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 3/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 3/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:08:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 3/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 3/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:08:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 3/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 3/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:08:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 3/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 4/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:08:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 4/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.1s\n",
      "[CV 2/5; 4/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:08:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 4/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 4/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:08:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 4/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 4/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:08:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 4/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 4/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:08:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 4/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 5/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:08:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 5/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 5/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:08:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 5/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 5/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:08:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 5/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 4/5; 5/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:08:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 5/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 5/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 5/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 6/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 6/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 6/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 6/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 6/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:08:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 6/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 6/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:08:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 6/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 6/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:08:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 6/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 7/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 7/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 7/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 7/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 7/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:08:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 7/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 7/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:08:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 7/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 7/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:08:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 7/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 8/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:08:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 8/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 8/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:08:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 8/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 8/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:08:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 8/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 8/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:08:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 8/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 8/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:08:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 8/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 9/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:08:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 9/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 2/5; 9/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:08:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 9/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 9/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:08:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 9/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 4/5; 9/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:08:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 9/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 9/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:08:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 9/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 1/5; 10/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:08:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 10/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 10/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:08:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 10/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 10/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:08:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 10/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 10/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:08:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 10/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 10/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:08:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 10/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 11/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:08:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 11/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 2/5; 11/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:08:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 11/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 3/5; 11/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:08:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 11/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 4/5; 11/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:08:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 11/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 11/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:08:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 11/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 1/5; 12/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:08:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 12/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 12/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:08:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 12/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 12/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:08:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 12/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 12/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:08:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 12/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 12/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:08:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 12/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 13/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:08:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 13/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 2/5; 13/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:08:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 13/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 3/5; 13/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:08:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 13/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 4/5; 13/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:09:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 13/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 13/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:09:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 13/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 1/5; 14/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:09:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 14/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 2/5; 14/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:09:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 14/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 14/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:09:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 14/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 4/5; 14/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:09:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 14/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 14/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:09:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 14/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 15/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:09:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 15/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 2/5; 15/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:09:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 15/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 3/5; 15/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:09:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 15/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 4/5; 15/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:09:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 15/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 5/5; 15/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:09:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 15/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 1/5; 16/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:09:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 16/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 16/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:09:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 16/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 16/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:09:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 16/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 16/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:09:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 16/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 16/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:09:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 16/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 17/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:09:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 17/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 17/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:09:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 17/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 17/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:09:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 17/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 17/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:09:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 17/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 17/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:09:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 17/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 18/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:09:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 18/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 18/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:09:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 18/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 18/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:09:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 18/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 18/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:09:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 18/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 18/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:09:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 18/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 19/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:09:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 19/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 19/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:09:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 19/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 19/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:09:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 19/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 19/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:09:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 19/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 19/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:09:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 19/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 20/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:09:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 20/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 20/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:09:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 20/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 20/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:09:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 20/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 20/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:09:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 20/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 20/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:09:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 20/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 21/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:09:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 21/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 21/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:09:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 21/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 21/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:09:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 21/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 21/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:09:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 21/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 21/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:09:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 21/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 22/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:09:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 22/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 22/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:09:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 22/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 22/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:09:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 22/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 22/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:09:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 22/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 22/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:09:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 22/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 23/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:09:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 23/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 23/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:09:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 23/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 23/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:09:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 23/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 4/5; 23/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:09:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 23/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 23/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:09:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 23/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 24/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:09:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 24/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 24/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:09:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 24/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 24/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:09:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 24/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 24/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:09:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 24/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 24/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:09:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 24/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 25/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:09:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 25/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 25/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:09:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 25/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 3/5; 25/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:09:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 25/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 4/5; 25/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:09:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 25/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 25/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:09:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 25/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 1/5; 26/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:09:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 26/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 26/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:09:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 26/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 26/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:09:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 26/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 26/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:09:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 26/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.7s\n",
      "[CV 5/5; 26/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:09:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 26/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 27/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:09:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 27/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 2/5; 27/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:09:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 27/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 27/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:09:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 27/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 4/5; 27/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:09:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 27/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 5/5; 27/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:09:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 27/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 1/5; 28/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:09:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 28/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 28/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:09:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 28/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 28/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:09:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 28/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 28/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:09:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 28/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 28/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:09:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 28/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 1/5; 29/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:09:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 29/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 2/5; 29/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:09:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 29/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 3/5; 29/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:09:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 29/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 4/5; 29/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:09:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 29/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 5/5; 29/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:09:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 29/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.8s\n",
      "[CV 1/5; 30/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:09:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 30/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 30/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:09:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 30/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 30/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:09:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 30/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 30/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:09:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 30/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 5/5; 30/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:09:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 30/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 1/5; 31/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:09:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 31/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 2/5; 31/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:09:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 31/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 3/5; 31/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:09:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 31/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 4/5; 31/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:09:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 31/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 31/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:09:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 31/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 1/5; 32/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:09:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 32/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 32/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:09:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 32/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 32/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:09:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 32/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 32/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:09:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 32/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 32/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:09:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 32/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 33/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:09:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 33/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 33/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:09:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 33/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 33/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:09:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 33/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 4/5; 33/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:09:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 33/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 33/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:09:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 33/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 34/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:09:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 34/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 34/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:09:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 34/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 34/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:09:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 34/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 34/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:09:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 34/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 34/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:09:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 34/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 35/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:09:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 35/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 35/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:09:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 35/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 35/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:09:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 35/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 35/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:09:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 35/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 35/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:09:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 35/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 36/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:09:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 36/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 36/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:09:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 36/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 36/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:09:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 36/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 36/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:09:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 36/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 36/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:09:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 36/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 37/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:09:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 37/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 2/5; 37/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:09:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 37/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 37/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:09:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 37/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 4/5; 37/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:09:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 37/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 37/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:09:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 37/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 38/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:09:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 38/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 38/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:09:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 38/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 38/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:09:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 38/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 38/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:10:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 38/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 38/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:10:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 38/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 39/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:10:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 39/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 39/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:10:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 39/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 3/5; 39/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:10:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 39/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 4/5; 39/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:10:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 39/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 5/5; 39/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:10:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 39/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 40/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:10:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 40/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 40/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:10:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 40/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 40/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:10:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 40/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 40/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:10:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 40/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 40/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:10:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 40/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 41/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:10:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 41/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 2/5; 41/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:10:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 41/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 41/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:10:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 41/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 4/5; 41/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:10:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 41/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 5/5; 41/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:10:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 41/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 1/5; 42/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:10:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 42/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 42/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:10:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 42/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 42/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:10:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 42/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 42/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:10:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 42/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 42/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:10:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 42/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 43/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:10:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 43/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 2/5; 43/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:10:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 43/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 43/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:10:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 43/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 4/5; 43/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:10:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 43/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 43/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:10:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 43/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.8s\n",
      "[CV 1/5; 44/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:10:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 44/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 2/5; 44/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:10:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 44/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 44/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:10:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 44/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 44/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:10:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 44/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 44/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:10:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 44/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 45/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:10:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 45/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 2/5; 45/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:10:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 45/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 3/5; 45/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:10:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 45/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 4/5; 45/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:10:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 45/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 5/5; 45/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:10:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 45/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.9s\n",
      "[CV 1/5; 46/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:10:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 46/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 46/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:10:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 46/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 46/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:10:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 46/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 4/5; 46/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:10:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 46/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.7s\n",
      "[CV 5/5; 46/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:10:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 46/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.7s\n",
      "[CV 1/5; 47/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:10:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 47/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.8s\n",
      "[CV 2/5; 47/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:10:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 47/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 47/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:10:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 47/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 4/5; 47/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:10:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 47/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 5/5; 47/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:10:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 47/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 1/5; 48/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:10:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 48/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 2/5; 48/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:10:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 48/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 3/5; 48/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:10:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 48/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.6s\n",
      "[CV 4/5; 48/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:10:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 48/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.6s\n",
      "[CV 5/5; 48/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:10:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 48/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.8s\n",
      "[CV 1/5; 49/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:10:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 49/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 2/5; 49/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:10:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 49/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 3/5; 49/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:10:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 49/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 4/5; 49/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:10:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 49/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 5/5; 49/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:10:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 49/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 50/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:10:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 50/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 50/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:10:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 50/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 50/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:10:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 50/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 50/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:10:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 50/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 50/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:10:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 50/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 51/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:10:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 51/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 51/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:10:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 51/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 51/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:10:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 51/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 4/5; 51/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:10:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 51/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 51/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:10:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 51/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 52/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:10:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 52/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 52/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:10:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 52/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 52/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:10:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 52/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 52/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:10:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 52/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 52/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:10:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 52/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 53/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:10:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 53/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 2/5; 53/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:10:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 53/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 3/5; 53/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:10:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 53/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 4/5; 53/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:10:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 53/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 53/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:10:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 53/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 54/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:10:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 54/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 54/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:10:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 54/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 54/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:10:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 54/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 54/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:10:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 54/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 54/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:10:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 54/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 55/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:10:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 55/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 2/5; 55/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:10:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 55/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 3/5; 55/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:10:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 55/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 4/5; 55/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:10:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 55/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 55/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:10:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 55/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 1/5; 56/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:10:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 56/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 56/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:10:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 56/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 56/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:10:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 56/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 56/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:10:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 56/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 56/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:10:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 56/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 57/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:10:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 57/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 2/5; 57/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:10:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 57/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 57/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:10:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 57/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 4/5; 57/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:10:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 57/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 57/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:10:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 57/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 1/5; 58/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:10:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 58/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 58/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:10:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 58/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 58/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:10:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 58/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 58/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:10:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 58/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 58/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:10:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 58/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 59/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:10:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 59/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 2/5; 59/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:10:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 59/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 59/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:10:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 59/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 4/5; 59/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:10:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 59/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 5/5; 59/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:10:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 59/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 1/5; 60/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:10:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:10:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 60/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 60/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:11:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 60/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 60/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:11:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 60/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 60/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:11:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 60/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 5/5; 60/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:11:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 60/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 61/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:11:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 61/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 2/5; 61/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:11:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 61/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 61/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:11:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 61/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 4/5; 61/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:11:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 61/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 61/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:11:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 61/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 1/5; 62/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:11:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 62/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 2/5; 62/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:11:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 62/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 62/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:11:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 62/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 62/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:11:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 62/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 5/5; 62/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:11:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 62/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 1/5; 63/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:11:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 63/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.8s\n",
      "[CV 2/5; 63/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:11:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 63/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 3/5; 63/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:11:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 63/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 4/5; 63/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:11:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 63/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 63/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:11:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 63/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 1/5; 64/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:11:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 64/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 2/5; 64/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:11:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 64/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 3/5; 64/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:11:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 64/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 4/5; 64/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:11:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 64/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 5/5; 64/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:11:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 64/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 1/5; 65/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:11:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 65/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 65/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:11:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 65/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 65/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:11:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 65/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 4/5; 65/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:11:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 65/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 65/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:11:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 65/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 66/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:11:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 66/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 66/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:11:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 66/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 66/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:11:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 66/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 66/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:11:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 66/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 66/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:11:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 66/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 67/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:11:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 67/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 67/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:11:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 67/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 67/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:11:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 67/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 67/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:11:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 67/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 67/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:11:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 67/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 68/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:11:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 68/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 68/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:11:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 68/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 68/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:11:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 68/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 68/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:11:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 68/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 68/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:11:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 68/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 69/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:11:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 69/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 69/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:11:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 69/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 69/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:11:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 69/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 4/5; 69/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:11:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 69/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 69/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:11:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 69/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 70/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:11:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 70/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 70/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:11:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 70/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 70/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:11:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 70/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 70/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:11:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 70/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 70/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:11:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 70/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 71/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:11:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 71/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 71/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:11:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 71/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 71/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:11:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 71/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 4/5; 71/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:11:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 71/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 71/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:11:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 71/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 72/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:11:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 72/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 72/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:11:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 72/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 72/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:11:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 72/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 72/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:11:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 72/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 72/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:11:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 72/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 73/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:11:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 73/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 2/5; 73/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:11:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 73/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 3/5; 73/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:11:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 73/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 4/5; 73/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:11:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 73/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 73/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:11:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 73/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 1/5; 74/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:11:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 74/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 2/5; 74/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:11:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 74/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 74/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:11:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 74/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 74/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:11:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 74/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 74/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:11:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 74/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 75/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:11:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 75/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 2/5; 75/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:11:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 75/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 75/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:11:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 75/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 4/5; 75/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:11:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 75/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 5/5; 75/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:11:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 75/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 1/5; 76/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:11:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 76/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 76/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:11:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 76/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 76/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:11:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 76/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 76/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:11:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 76/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 76/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:11:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 76/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 77/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:11:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 77/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 2/5; 77/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:11:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 77/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 3/5; 77/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:11:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 77/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.9s\n",
      "[CV 4/5; 77/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:11:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 77/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 5/5; 77/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:11:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 77/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 1/5; 78/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:11:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 78/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 2/5; 78/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:11:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 78/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 3/5; 78/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:11:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 78/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 4/5; 78/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:11:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 78/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 5/5; 78/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:11:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 78/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.6s\n",
      "[CV 1/5; 79/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:11:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 79/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 2/5; 79/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:11:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 79/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 3/5; 79/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:11:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 79/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 4/5; 79/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:11:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 79/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 5/5; 79/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:11:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 79/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 1/5; 80/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:11:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 80/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 2/5; 80/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:11:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 80/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 3/5; 80/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:11:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 80/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 80/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:11:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 80/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 5/5; 80/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:11:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 80/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 1/5; 81/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:11:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 81/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 81/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:11:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 81/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 81/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:11:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 81/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 81/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:11:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 81/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 81/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[22:11:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 81/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 82/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:12:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 82/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 82/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:12:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 82/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 82/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:12:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 82/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 82/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:12:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 82/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 82/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[22:12:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 82/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 83/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:12:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 83/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 83/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:12:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 83/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 83/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:12:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 83/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 83/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:12:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 83/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 83/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[22:12:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 83/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 84/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:12:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 84/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 84/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:12:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 84/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 84/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:12:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 84/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 84/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:12:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 84/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 84/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[22:12:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 84/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 85/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:12:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 85/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 85/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:12:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 85/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 85/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:12:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 85/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 4/5; 85/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:12:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 85/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 85/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[22:12:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 85/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 86/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:12:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 86/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 86/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:12:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 86/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 86/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:12:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 86/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 86/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:12:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 86/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 86/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[22:12:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 86/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 87/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:12:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 87/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 87/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:12:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 87/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 87/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:12:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 87/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 4/5; 87/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:12:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 87/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 5/5; 87/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[22:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 87/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 88/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 88/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 88/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 88/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 88/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 88/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 88/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 88/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 88/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[22:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 88/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 89/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 89/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 2/5; 89/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 89/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 89/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 89/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 4/5; 89/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 89/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 5/5; 89/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[22:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 89/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 1/5; 90/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 90/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 90/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 90/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 90/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 90/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 4/5; 90/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 90/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 5/5; 90/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[22:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 90/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 1/5; 91/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 91/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 2/5; 91/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 91/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 3/5; 91/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 91/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 4/5; 91/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 91/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 5/5; 91/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[22:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 91/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 1/5; 92/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 92/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 92/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 92/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 3/5; 92/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:12:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 92/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 4/5; 92/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:12:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 92/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 5/5; 92/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[22:12:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 92/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 1/5; 93/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:12:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 93/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 2/5; 93/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:12:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 93/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 3/5; 93/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:12:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 93/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 4/5; 93/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:12:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 93/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.8s\n",
      "[CV 5/5; 93/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[22:12:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 93/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 1/5; 94/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:12:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 94/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 2/5; 94/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:12:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 94/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.6s\n",
      "[CV 3/5; 94/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:12:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 94/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.7s\n",
      "[CV 4/5; 94/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:12:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 94/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 5/5; 94/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[22:12:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 94/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 1/5; 95/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:12:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 95/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 2/5; 95/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:12:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 95/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 95/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:12:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 95/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 4/5; 95/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:12:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 95/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.8s\n",
      "[CV 5/5; 95/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[22:12:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 95/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 1/5; 96/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:12:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 96/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 2/5; 96/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:12:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 96/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 96/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:12:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 96/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 96/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:12:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 96/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 5/5; 96/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[22:12:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 96/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[22:12:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.6, gamma=0.5, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=5, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, silent=True,\n",
      "              subsample=1.0, tree_method='exact', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "parameters = {\n",
    "        'min_child_weight': [1, 5],\n",
    "        'gamma': [0.5, 1, 1.5],\n",
    "        'subsample': [0.6, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8],\n",
    "        'max_depth': [2, 3,4, 5]\n",
    "        }\n",
    "\n",
    "# Create the model\n",
    "xgboost_model = XGBClassifier(use_label_encoder=False,objective ='binary:logistic',silent=True)\n",
    "\n",
    "# Best model\n",
    "opt_model_xgb = GridSearchCV(xgboost_model, parameters,  scoring='accuracy', verbose=10)\n",
    "\n",
    "# Fit the model\n",
    "opt_model_xgb.fit(train_m1, train_m1_target)\n",
    "\n",
    "print (opt_model_xgb.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=2,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, silent=True,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model with best parameters\n",
    "xgboost_model = XGBClassifier(max_depth=2, verbosity = 0,silent=True)\n",
    "\n",
    "# Fit the best model\n",
    "xgboost_model.fit(train_m1, train_m1_target)\n",
    "xgboost_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0     1    All\n",
      "Actual                       \n",
      "0          10647   321  10968\n",
      "1            696   693   1389\n",
      "All        11343  1014  12357\n"
     ]
    }
   ],
   "source": [
    "predictions = xgboost_model.predict(test_m1)\n",
    "\n",
    "# Confusion matrix\n",
    "confusion = pd.crosstab(test_m1_target,predictions, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusion )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.917698\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "score = accuracy_score(test_m1_target,predictions)\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95     10968\n",
      "           1       0.68      0.50      0.58      1389\n",
      "\n",
      "    accuracy                           0.92     12357\n",
      "   macro avg       0.81      0.73      0.77     12357\n",
      "weighted avg       0.91      0.92      0.91     12357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report\n",
    "print(classification_report(test_m1_target,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9106517689665807"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate model using best model and cross validation\n",
    "pecc_xgb = cross_val_score(xgboost_model, train_m1, train_m1_target, cv = 10).mean()\n",
    "pecc_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2\n",
    "#### Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.836283</td>\n",
       "      <td>-1.028419</td>\n",
       "      <td>-1.910223</td>\n",
       "      <td>-0.420230</td>\n",
       "      <td>-0.009681</td>\n",
       "      <td>0.917326</td>\n",
       "      <td>-0.43243</td>\n",
       "      <td>-0.699689</td>\n",
       "      <td>1.145570</td>\n",
       "      <td>-0.014944</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.187885</td>\n",
       "      <td>0.213335</td>\n",
       "      <td>-0.373253</td>\n",
       "      <td>0.190666</td>\n",
       "      <td>-0.011801</td>\n",
       "      <td>-0.548958</td>\n",
       "      <td>-0.289686</td>\n",
       "      <td>0.352458</td>\n",
       "      <td>0.470978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.406241</td>\n",
       "      <td>-1.028419</td>\n",
       "      <td>1.292265</td>\n",
       "      <td>1.086428</td>\n",
       "      <td>-0.009681</td>\n",
       "      <td>-1.090125</td>\n",
       "      <td>-0.43243</td>\n",
       "      <td>-0.699689</td>\n",
       "      <td>-1.366988</td>\n",
       "      <td>1.415229</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.556353</td>\n",
       "      <td>0.213335</td>\n",
       "      <td>-0.373253</td>\n",
       "      <td>0.190666</td>\n",
       "      <td>0.919127</td>\n",
       "      <td>-0.132418</td>\n",
       "      <td>0.937972</td>\n",
       "      <td>0.851480</td>\n",
       "      <td>0.899436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.406241</td>\n",
       "      <td>0.353247</td>\n",
       "      <td>-1.910223</td>\n",
       "      <td>1.086428</td>\n",
       "      <td>-0.009681</td>\n",
       "      <td>0.917326</td>\n",
       "      <td>-0.43243</td>\n",
       "      <td>-0.699689</td>\n",
       "      <td>-0.529469</td>\n",
       "      <td>0.700143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.187885</td>\n",
       "      <td>0.213335</td>\n",
       "      <td>-0.373253</td>\n",
       "      <td>0.190666</td>\n",
       "      <td>0.919127</td>\n",
       "      <td>0.676764</td>\n",
       "      <td>-0.435341</td>\n",
       "      <td>0.849794</td>\n",
       "      <td>0.899436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.406241</td>\n",
       "      <td>-0.475752</td>\n",
       "      <td>-0.308979</td>\n",
       "      <td>1.086428</td>\n",
       "      <td>-0.009681</td>\n",
       "      <td>-1.090125</td>\n",
       "      <td>-0.43243</td>\n",
       "      <td>-0.699689</td>\n",
       "      <td>-0.529469</td>\n",
       "      <td>1.415229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549049</td>\n",
       "      <td>0.213335</td>\n",
       "      <td>-0.373253</td>\n",
       "      <td>0.190666</td>\n",
       "      <td>0.919127</td>\n",
       "      <td>0.676764</td>\n",
       "      <td>-0.435341</td>\n",
       "      <td>0.850918</td>\n",
       "      <td>0.899436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.406241</td>\n",
       "      <td>0.076914</td>\n",
       "      <td>-0.308979</td>\n",
       "      <td>1.086428</td>\n",
       "      <td>-0.009681</td>\n",
       "      <td>0.917326</td>\n",
       "      <td>-0.43243</td>\n",
       "      <td>-0.699689</td>\n",
       "      <td>-1.366988</td>\n",
       "      <td>0.700143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.556353</td>\n",
       "      <td>0.213335</td>\n",
       "      <td>-0.373253</td>\n",
       "      <td>0.190666</td>\n",
       "      <td>0.919127</td>\n",
       "      <td>-0.132418</td>\n",
       "      <td>0.937972</td>\n",
       "      <td>0.852604</td>\n",
       "      <td>0.899436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       job   marital  education   default   housing     loan  \\\n",
       "0 -1.836283 -1.028419 -1.910223  -0.420230 -0.009681  0.917326 -0.43243   \n",
       "1  0.406241 -1.028419  1.292265   1.086428 -0.009681 -1.090125 -0.43243   \n",
       "2  0.406241  0.353247 -1.910223   1.086428 -0.009681  0.917326 -0.43243   \n",
       "3  0.406241 -0.475752 -0.308979   1.086428 -0.009681 -1.090125 -0.43243   \n",
       "4  0.406241  0.076914 -0.308979   1.086428 -0.009681  0.917326 -0.43243   \n",
       "\n",
       "    contact     month  day_of_week  ...  campaign     pdays  previous  \\\n",
       "0 -0.699689  1.145570    -0.014944  ... -0.187885  0.213335 -0.373253   \n",
       "1 -0.699689 -1.366988     1.415229  ... -0.556353  0.213335 -0.373253   \n",
       "2 -0.699689 -0.529469     0.700143  ... -0.187885  0.213335 -0.373253   \n",
       "3 -0.699689 -0.529469     1.415229  ...  0.549049  0.213335 -0.373253   \n",
       "4 -0.699689 -1.366988     0.700143  ... -0.556353  0.213335 -0.373253   \n",
       "\n",
       "   poutcome  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
       "0  0.190666     -0.011801       -0.548958      -0.289686   0.352458   \n",
       "1  0.190666      0.919127       -0.132418       0.937972   0.851480   \n",
       "2  0.190666      0.919127        0.676764      -0.435341   0.849794   \n",
       "3  0.190666      0.919127        0.676764      -0.435341   0.850918   \n",
       "4  0.190666      0.919127       -0.132418       0.937972   0.852604   \n",
       "\n",
       "   nr.employed  y  \n",
       "0     0.470978  0  \n",
       "1     0.899436  0  \n",
       "2     0.899436  0  \n",
       "3     0.899436  0  \n",
       "4     0.899436  0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_m2 = pd.read_csv('../../../../Data_AA2/train_m2.csv', sep = ',')\n",
    "train_m2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.406241</td>\n",
       "      <td>-0.752086</td>\n",
       "      <td>1.292265</td>\n",
       "      <td>-0.922449</td>\n",
       "      <td>-0.009681</td>\n",
       "      <td>0.917326</td>\n",
       "      <td>-0.43243</td>\n",
       "      <td>1.429206</td>\n",
       "      <td>-0.110709</td>\n",
       "      <td>-0.014944</td>\n",
       "      <td>...</td>\n",
       "      <td>2.759852</td>\n",
       "      <td>0.213335</td>\n",
       "      <td>-0.373253</td>\n",
       "      <td>0.190666</td>\n",
       "      <td>0.919127</td>\n",
       "      <td>1.610567</td>\n",
       "      <td>-0.248071</td>\n",
       "      <td>0.796408</td>\n",
       "      <td>0.899436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.406241</td>\n",
       "      <td>1.458580</td>\n",
       "      <td>1.292265</td>\n",
       "      <td>0.584209</td>\n",
       "      <td>-0.009681</td>\n",
       "      <td>0.917326</td>\n",
       "      <td>-0.43243</td>\n",
       "      <td>1.429206</td>\n",
       "      <td>-0.110709</td>\n",
       "      <td>1.415229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180582</td>\n",
       "      <td>0.213335</td>\n",
       "      <td>-0.373253</td>\n",
       "      <td>0.190666</td>\n",
       "      <td>0.919127</td>\n",
       "      <td>1.610567</td>\n",
       "      <td>-0.248071</td>\n",
       "      <td>0.848670</td>\n",
       "      <td>0.899436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.406241</td>\n",
       "      <td>-0.475752</td>\n",
       "      <td>-0.308979</td>\n",
       "      <td>1.086428</td>\n",
       "      <td>-0.009681</td>\n",
       "      <td>0.917326</td>\n",
       "      <td>-0.43243</td>\n",
       "      <td>-0.699689</td>\n",
       "      <td>-1.785748</td>\n",
       "      <td>1.415229</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.556353</td>\n",
       "      <td>0.213335</td>\n",
       "      <td>3.485114</td>\n",
       "      <td>-2.416003</td>\n",
       "      <td>-1.066853</td>\n",
       "      <td>-0.762350</td>\n",
       "      <td>-1.350882</td>\n",
       "      <td>-1.142923</td>\n",
       "      <td>-0.811744</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.406241</td>\n",
       "      <td>-0.752086</td>\n",
       "      <td>-1.910223</td>\n",
       "      <td>-0.420230</td>\n",
       "      <td>-0.009681</td>\n",
       "      <td>0.917326</td>\n",
       "      <td>-0.43243</td>\n",
       "      <td>1.429206</td>\n",
       "      <td>-0.110709</td>\n",
       "      <td>1.415229</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.556353</td>\n",
       "      <td>0.213335</td>\n",
       "      <td>-0.373253</td>\n",
       "      <td>0.190666</td>\n",
       "      <td>0.919127</td>\n",
       "      <td>1.610567</td>\n",
       "      <td>-0.248071</td>\n",
       "      <td>0.848670</td>\n",
       "      <td>0.899436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.406241</td>\n",
       "      <td>0.076914</td>\n",
       "      <td>-0.308979</td>\n",
       "      <td>0.584209</td>\n",
       "      <td>-0.009681</td>\n",
       "      <td>-1.090125</td>\n",
       "      <td>-0.43243</td>\n",
       "      <td>1.429206</td>\n",
       "      <td>0.726810</td>\n",
       "      <td>-1.445118</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.556353</td>\n",
       "      <td>0.213335</td>\n",
       "      <td>-0.373253</td>\n",
       "      <td>0.190666</td>\n",
       "      <td>0.732941</td>\n",
       "      <td>0.806507</td>\n",
       "      <td>0.875548</td>\n",
       "      <td>0.792474</td>\n",
       "      <td>0.407306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       job   marital  education   default   housing     loan  \\\n",
       "0  0.406241 -0.752086  1.292265  -0.922449 -0.009681  0.917326 -0.43243   \n",
       "1  0.406241  1.458580  1.292265   0.584209 -0.009681  0.917326 -0.43243   \n",
       "2  0.406241 -0.475752 -0.308979   1.086428 -0.009681  0.917326 -0.43243   \n",
       "3  0.406241 -0.752086 -1.910223  -0.420230 -0.009681  0.917326 -0.43243   \n",
       "4  0.406241  0.076914 -0.308979   0.584209 -0.009681 -1.090125 -0.43243   \n",
       "\n",
       "    contact     month  day_of_week  ...  campaign     pdays  previous  \\\n",
       "0  1.429206 -0.110709    -0.014944  ...  2.759852  0.213335 -0.373253   \n",
       "1  1.429206 -0.110709     1.415229  ...  0.180582  0.213335 -0.373253   \n",
       "2 -0.699689 -1.785748     1.415229  ... -0.556353  0.213335  3.485114   \n",
       "3  1.429206 -0.110709     1.415229  ... -0.556353  0.213335 -0.373253   \n",
       "4  1.429206  0.726810    -1.445118  ... -0.556353  0.213335 -0.373253   \n",
       "\n",
       "   poutcome  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
       "0  0.190666      0.919127        1.610567      -0.248071   0.796408   \n",
       "1  0.190666      0.919127        1.610567      -0.248071   0.848670   \n",
       "2 -2.416003     -1.066853       -0.762350      -1.350882  -1.142923   \n",
       "3  0.190666      0.919127        1.610567      -0.248071   0.848670   \n",
       "4  0.190666      0.732941        0.806507       0.875548   0.792474   \n",
       "\n",
       "   nr.employed  y  \n",
       "0     0.899436  0  \n",
       "1     0.899436  0  \n",
       "2    -0.811744  0  \n",
       "3     0.899436  0  \n",
       "4     0.407306  0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_m2 = pd.read_csv('../../../../Data_AA2/test_m2.csv', sep = ',')\n",
    "test_m2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get target\n",
    "train_m2_target = train_m2['y']\n",
    "train_m2 = train_m2.drop(columns=['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get target\n",
    "test_m2_target = test_m2['y']\n",
    "test_m2 = test_m2.drop(columns=['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for lower errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:33:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▏                                                                                | 1/39 [00:00<00:08,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:33:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|████▎                                                                              | 2/39 [00:00<00:08,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:33:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▍                                                                            | 3/39 [00:00<00:09,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:33:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▌                                                                          | 4/39 [00:01<00:11,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:33:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▋                                                                        | 5/39 [00:01<00:14,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:33:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▊                                                                      | 6/39 [00:02<00:18,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:33:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▉                                                                    | 7/39 [00:04<00:25,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:33:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|█████████████████                                                                  | 8/39 [00:05<00:30,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:33:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|███████████████████▏                                                               | 9/39 [00:07<00:36,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:33:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████                                                             | 10/39 [00:09<00:42,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:34:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|███████████████████████▏                                                          | 11/39 [00:10<00:42,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:34:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████▏                                                        | 12/39 [00:13<00:50,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:34:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███████████████████████████▎                                                      | 13/39 [00:16<00:56,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:34:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▍                                                    | 14/39 [00:19<01:01,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:34:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███████████████████████████████▌                                                  | 15/39 [00:23<01:06,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:34:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|█████████████████████████████████▋                                                | 16/39 [00:25<01:00,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:34:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|███████████████████████████████████▋                                              | 17/39 [00:27<00:55,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:34:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|█████████████████████████████████████▊                                            | 18/39 [00:30<00:51,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:34:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|███████████████████████████████████████▉                                          | 19/39 [00:32<00:49,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:34:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|██████████████████████████████████████████                                        | 20/39 [00:36<00:54,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:34:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|████████████████████████████████████████████▏                                     | 21/39 [00:39<00:54,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:34:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|██████████████████████████████████████████████▎                                   | 22/39 [00:43<00:53,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:34:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|████████████████████████████████████████████████▎                                 | 23/39 [00:46<00:52,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:34:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████████████████████████████████████████████████▍                               | 24/39 [00:49<00:47,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:34:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|████████████████████████████████████████████████████▌                             | 25/39 [00:53<00:47,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:34:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████████████████████████████▋                           | 26/39 [00:57<00:45,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:34:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|████████████████████████████████████████████████████████▊                         | 27/39 [01:00<00:42,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:34:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|██████████████████████████████████████████████████████████▊                       | 28/39 [01:04<00:38,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:34:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|████████████████████████████████████████████████████████████▉                     | 29/39 [01:07<00:33,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:34:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████████████████████████████████████████████████████████████                   | 30/39 [01:10<00:28,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:35:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|█████████████████████████████████████████████████████████████████▏                | 31/39 [01:12<00:23,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:35:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|███████████████████████████████████████████████████████████████████▎              | 32/39 [01:15<00:20,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:35:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|█████████████████████████████████████████████████████████████████████▍            | 33/39 [01:18<00:16,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:35:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|███████████████████████████████████████████████████████████████████████▍          | 34/39 [01:20<00:13,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:35:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████████████████████████████████████████████████████████▌        | 35/39 [01:23<00:10,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:35:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|███████████████████████████████████████████████████████████████████████████▋      | 36/39 [01:25<00:08,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:35:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████████████████████████████████████████████████████████████████████████▊    | 37/39 [01:28<00:05,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:35:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|███████████████████████████████████████████████████████████████████████████████▉  | 38/39 [01:32<00:02,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:35:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [01:34<00:00,  2.43s/it]\n"
     ]
    }
   ],
   "source": [
    "error_rate = []\n",
    "\n",
    "for i in tqdm(range(1,40)):\n",
    "    xgb = XGBClassifier(max_depth=i)\n",
    "    xgb.fit(train_m2,train_m2_target)\n",
    "    predictions = xgb.predict(test_m2)\n",
    "    error_rate.append(np.mean(predictions != test_m2_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Error Rate')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(25,6))\n",
    "plt.plot(range(1,40),error_rate,color='blue',linestyle='dashed',marker='o',markerfacecolor='red',markersize=10)\n",
    "plt.title('Error Rate vs DepthValue')\n",
    "plt.xlabel(\"depth\")\n",
    "plt.ylabel(\"Error Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "[CV 1/5; 1/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 1/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.2s\n",
      "[CV 2/5; 1/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 1/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.2s\n",
      "[CV 3/5; 1/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 1/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.2s\n",
      "[CV 4/5; 1/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 1/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.2s\n",
      "[CV 5/5; 1/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 1/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.2s\n",
      "[CV 1/5; 2/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 2/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.1s\n",
      "[CV 2/5; 2/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 2/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 2/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 2/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.1s\n",
      "[CV 4/5; 2/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 2/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.1s\n",
      "[CV 5/5; 2/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 2/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.1s\n",
      "[CV 1/5; 3/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 3/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.2s\n",
      "[CV 2/5; 3/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 3/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.2s\n",
      "[CV 3/5; 3/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 3/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.2s\n",
      "[CV 4/5; 3/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 3/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.2s\n",
      "[CV 5/5; 3/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 3/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.2s\n",
      "[CV 1/5; 4/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 4/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.1s\n",
      "[CV 2/5; 4/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 4/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.1s\n",
      "[CV 3/5; 4/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 4/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.1s\n",
      "[CV 4/5; 4/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 4/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.1s\n",
      "[CV 5/5; 4/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 4/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.1s\n",
      "[CV 1/5; 5/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 5/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 5/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 5/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 5/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 5/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 5/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 5/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 5/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 5/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 6/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 6/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 6/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 6/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 6/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 6/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 6/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 6/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 6/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 6/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 7/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 7/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 7/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 7/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 7/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 7/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 7/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 7/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 7/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 7/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 1/5; 8/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 8/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 8/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 8/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 8/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 8/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.6s\n",
      "[CV 4/5; 8/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 8/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 8/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 8/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 9/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 9/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 2/5; 9/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 9/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 9/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 9/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 4/5; 9/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 9/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 5/5; 9/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 9/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 1/5; 10/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 10/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 10/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 10/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 10/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 10/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 10/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 10/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 10/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 10/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 11/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 11/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 11/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 11/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 11/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 11/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 4/5; 11/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 11/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 11/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 11/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 12/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 12/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 12/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 12/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 12/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 12/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 12/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 12/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 12/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 12/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 13/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 13/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 2/5; 13/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 13/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 13/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 13/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 4/5; 13/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 13/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 13/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 13/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 14/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 14/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 14/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 14/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 14/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 14/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 14/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 14/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 14/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 14/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 1/5; 15/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 15/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 2/5; 15/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 15/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 15/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 15/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 4/5; 15/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 15/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 15/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 15/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 1/5; 16/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 16/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 16/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 16/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 16/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 16/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 4/5; 16/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 16/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 16/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 16/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 17/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 17/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.2s\n",
      "[CV 2/5; 17/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 17/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.2s\n",
      "[CV 3/5; 17/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 17/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.2s\n",
      "[CV 4/5; 17/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 17/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 17/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 17/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 18/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 18/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 18/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 18/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 18/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 18/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 18/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 18/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 18/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 18/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 19/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 19/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.2s\n",
      "[CV 2/5; 19/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 19/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.2s\n",
      "[CV 3/5; 19/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 19/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.2s\n",
      "[CV 4/5; 19/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 19/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.2s\n",
      "[CV 5/5; 19/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 19/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.2s\n",
      "[CV 1/5; 20/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 20/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.1s\n",
      "[CV 2/5; 20/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 20/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.1s\n",
      "[CV 3/5; 20/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 20/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.1s\n",
      "[CV 4/5; 20/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 20/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.1s\n",
      "[CV 5/5; 20/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 20/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.1s\n",
      "[CV 1/5; 21/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 21/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 21/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 21/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 21/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 21/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 21/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 21/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 21/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 21/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 22/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 22/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 22/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 22/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 22/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 22/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 22/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 22/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 22/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 22/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 23/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 23/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 23/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 23/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 23/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 23/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 4/5; 23/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 23/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 23/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 23/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 24/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 24/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 24/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 24/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 24/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 24/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 24/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 24/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 24/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 24/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 25/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 25/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 25/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 25/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 25/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 25/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 25/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 25/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 25/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 25/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 26/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 26/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 26/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 26/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 26/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 26/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 26/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 26/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 26/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 26/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 27/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 27/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 27/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 27/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 3/5; 27/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 27/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 27/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 27/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 27/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 27/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 28/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 28/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 28/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 28/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 28/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 28/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 28/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 28/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 28/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 28/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 29/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 29/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 2/5; 29/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 29/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 3/5; 29/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 29/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 4/5; 29/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 29/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 5/5; 29/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 29/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 30/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 30/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 30/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 30/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 30/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 30/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 30/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 30/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 30/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 30/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 31/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 31/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 31/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 31/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 3/5; 31/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 31/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 4/5; 31/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 31/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 31/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 31/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 1/5; 32/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 32/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 2/5; 32/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 32/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 32/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 32/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 32/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 32/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 32/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 32/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 33/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 33/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 33/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 33/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.2s\n",
      "[CV 3/5; 33/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 33/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.2s\n",
      "[CV 4/5; 33/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 33/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.2s\n",
      "[CV 5/5; 33/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 33/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 34/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 34/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.1s\n",
      "[CV 2/5; 34/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 34/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 34/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 34/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 34/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 34/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 34/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 34/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 35/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 35/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 35/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 35/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 35/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 35/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.2s\n",
      "[CV 4/5; 35/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 35/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 35/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 35/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 36/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 36/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 36/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 36/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 36/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 36/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 36/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 36/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 36/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 36/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 37/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 37/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 37/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 37/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 37/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 37/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 37/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 37/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 37/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 37/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 38/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 38/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 38/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 38/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 38/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 38/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 38/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 38/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.1s\n",
      "[CV 5/5; 38/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 38/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 39/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 39/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 39/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 39/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 39/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 39/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 39/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 39/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 39/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 39/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 40/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 40/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 40/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 40/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 40/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 40/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 40/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 40/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.1s\n",
      "[CV 5/5; 40/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 40/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 41/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 41/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 41/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 41/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 41/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 41/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 41/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 41/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 41/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 41/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 42/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 42/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 42/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 42/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 42/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 42/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 42/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 42/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 42/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 42/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 43/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 43/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 43/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 43/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 43/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 43/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 43/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 43/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 43/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 43/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 44/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 44/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 44/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 44/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 44/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 44/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 44/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 44/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 44/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 44/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 45/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 45/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 45/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 45/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 3/5; 45/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 45/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 4/5; 45/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 45/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 45/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 45/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 46/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 46/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 46/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 46/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 46/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 46/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 46/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 46/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 46/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 46/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 47/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 47/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 47/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 47/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 3/5; 47/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 47/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 4/5; 47/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 47/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 5/5; 47/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 47/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 1/5; 48/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 48/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 48/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 48/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 48/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 48/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 48/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 48/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 48/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 48/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 49/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 49/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 49/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 49/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 49/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 49/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 49/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 49/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 49/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 49/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 50/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 50/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 50/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 50/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 50/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 50/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 50/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 50/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 50/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 50/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 51/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 51/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 51/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 51/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.2s\n",
      "[CV 3/5; 51/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 51/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.2s\n",
      "[CV 4/5; 51/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 51/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.2s\n",
      "[CV 5/5; 51/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 51/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 52/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 52/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 52/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 52/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.1s\n",
      "[CV 3/5; 52/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 52/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.1s\n",
      "[CV 4/5; 52/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 52/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.1s\n",
      "[CV 5/5; 52/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 52/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.1s\n",
      "[CV 1/5; 53/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 53/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 53/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 53/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 53/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 53/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 53/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 53/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 53/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 53/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 54/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 54/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 54/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 54/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 54/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 54/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 54/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 54/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 54/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 54/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 55/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 55/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 55/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 55/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 55/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 55/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 55/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 55/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 55/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 55/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 56/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 56/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 56/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 56/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 56/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 56/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 56/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 56/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 56/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 56/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 57/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 57/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 57/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 57/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 57/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 57/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 4/5; 57/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 57/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 5/5; 57/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 57/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 1/5; 58/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 58/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 2/5; 58/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 58/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 3/5; 58/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 58/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 58/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 58/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 58/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 58/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 59/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 59/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 59/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 59/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 59/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 59/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 4/5; 59/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 59/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 59/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 59/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 1/5; 60/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 60/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 60/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 60/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 60/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 60/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 60/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 60/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 60/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 60/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 61/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 61/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 2/5; 61/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 61/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 3/5; 61/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 61/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 4/5; 61/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 61/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 61/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 61/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 62/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 62/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 62/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 62/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 62/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 62/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 62/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 62/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 5/5; 62/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 62/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 63/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 63/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 63/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 63/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 63/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 63/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 4/5; 63/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 63/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 63/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 63/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 64/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 64/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 64/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 64/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 64/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 64/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 64/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 64/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 64/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 64/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 65/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 65/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 65/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 65/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 65/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 65/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 65/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 65/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 65/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 65/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 66/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 66/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 66/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 66/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 66/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 66/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.1s\n",
      "[CV 4/5; 66/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 66/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.1s\n",
      "[CV 5/5; 66/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 66/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 67/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 67/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 67/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 67/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 67/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 67/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.2s\n",
      "[CV 4/5; 67/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 67/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 67/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 67/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 68/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 68/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.1s\n",
      "[CV 2/5; 68/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 68/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 68/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 68/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 68/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 68/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.1s\n",
      "[CV 5/5; 68/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 68/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.1s\n",
      "[CV 1/5; 69/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 69/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 69/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 69/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 69/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 69/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 4/5; 69/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 69/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 69/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 69/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 70/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 70/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 70/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 70/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 70/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 70/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 70/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 70/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 70/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 70/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 71/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 71/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 71/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 71/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 71/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 71/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 71/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 71/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 71/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 71/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 1/5; 72/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 72/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 72/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 72/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 72/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 72/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 72/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 72/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 72/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 72/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 73/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 73/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 2/5; 73/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 73/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 73/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 73/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 4/5; 73/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 73/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 5/5; 73/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 73/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 1/5; 74/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 74/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 74/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 74/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 74/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 74/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 74/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 74/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 5/5; 74/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 74/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 75/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 75/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 2/5; 75/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 75/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 75/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 75/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 4/5; 75/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 75/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 5/5; 75/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 75/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 1/5; 76/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 76/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 76/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 76/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 76/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 76/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 76/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 76/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.6s\n",
      "[CV 5/5; 76/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 76/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.6s\n",
      "[CV 1/5; 77/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 77/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.9s\n",
      "[CV 2/5; 77/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 77/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 3/5; 77/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 77/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.8s\n",
      "[CV 4/5; 77/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 77/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 77/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 77/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 1/5; 78/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 78/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 78/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 78/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 78/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 78/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 78/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 78/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 78/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 78/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 79/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 79/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 2/5; 79/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 79/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 3/5; 79/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 79/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 4/5; 79/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 79/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 79/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 79/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 1/5; 80/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 80/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 80/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 80/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 80/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 80/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 4/5; 80/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 80/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 5/5; 80/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 80/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 81/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 81/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.2s\n",
      "[CV 2/5; 81/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 81/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.2s\n",
      "[CV 3/5; 81/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 81/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.2s\n",
      "[CV 4/5; 81/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 81/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.2s\n",
      "[CV 5/5; 81/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 81/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.2s\n",
      "[CV 1/5; 82/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 82/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.1s\n",
      "[CV 2/5; 82/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 82/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 82/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 82/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 82/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 82/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 82/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 82/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 83/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 83/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 83/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 83/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 83/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 83/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 83/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 83/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 83/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 83/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 84/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 84/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 84/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 84/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 84/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 84/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.1s\n",
      "[CV 4/5; 84/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 84/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.1s\n",
      "[CV 5/5; 84/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 84/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.1s\n",
      "[CV 1/5; 85/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 85/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 85/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 85/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 85/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 85/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 85/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 85/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 85/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 85/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 86/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 86/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 86/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 86/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 86/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 86/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 86/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 86/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 86/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 86/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 87/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 87/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 87/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 87/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 87/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 87/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 87/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 87/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 87/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 87/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 88/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 88/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 88/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 88/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 88/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 88/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 88/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 88/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 88/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 88/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 89/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 89/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 89/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 89/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 89/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 89/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 4/5; 89/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 89/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 89/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 89/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 1/5; 90/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 90/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 2/5; 90/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 90/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 90/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 90/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 90/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 90/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 90/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 90/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 91/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 91/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 2/5; 91/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 91/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 91/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 91/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 4/5; 91/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 91/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 91/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 91/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 1/5; 92/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 92/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 2/5; 92/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 92/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 3/5; 92/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 92/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 92/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 92/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 5/5; 92/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 92/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 93/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 93/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.8s\n",
      "[CV 2/5; 93/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 93/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 3/5; 93/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 93/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 4/5; 93/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 93/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 5/5; 93/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 93/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 1/5; 94/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 94/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 94/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 94/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 94/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 94/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 94/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 94/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 94/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 94/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 95/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 95/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 2/5; 95/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 95/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 3/5; 95/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 95/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 4/5; 95/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 95/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 5/5; 95/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 95/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 1/5; 96/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 96/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 96/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 96/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 96/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 96/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 96/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 96/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 96/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 96/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.8, gamma=1, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=5, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1.0,\n",
      "              tree_method='exact', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "parameters = {\n",
    "        'min_child_weight': [1, 5],\n",
    "        'gamma': [0.5, 1, 1.5],\n",
    "        'subsample': [0.6, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8],\n",
    "        'max_depth': [2, 3,4, 5]\n",
    "        }\n",
    "\n",
    "# Create the model\n",
    "xgboost_model = XGBClassifier(use_label_encoder=False)\n",
    "\n",
    "# Best model\n",
    "opt_model_xgb = GridSearchCV(xgboost_model, parameters,  scoring='accuracy', verbose=10)\n",
    "\n",
    "# Fit the model\n",
    "opt_model_xgb.fit(train_m2, train_m2_target)\n",
    "\n",
    "print (opt_model_xgb.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8, gamma=1, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=5, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1.0,\n",
       "              tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model with best parameters\n",
    "xgboost_model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.8, gamma=1, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=0.300000012, max_delta_step=0, max_depth=3,\n",
    "              min_child_weight=5,\n",
    "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1.0,\n",
    "              tree_method='exact', use_label_encoder=False,\n",
    "              validate_parameters=1, verbosity=None)\n",
    "\n",
    "# Fit the best model\n",
    "xgboost_model.fit(train_m2, train_m2_target)\n",
    "xgboost_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted     0    1   All\n",
      "Actual                    \n",
      "0          7671  323  7994\n",
      "1           538  615  1153\n",
      "All        8209  938  9147\n"
     ]
    }
   ],
   "source": [
    "predictions = xgboost_model.predict(test_m2)\n",
    "\n",
    "# Confusion matrix\n",
    "confusion = pd.crosstab(test_m2_target,predictions, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusion )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.905871\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "score = accuracy_score(test_m2_target,predictions)\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95      7994\n",
      "           1       0.66      0.53      0.59      1153\n",
      "\n",
      "    accuracy                           0.91      9147\n",
      "   macro avg       0.80      0.75      0.77      9147\n",
      "weighted avg       0.90      0.91      0.90      9147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report\n",
    "print(classification_report(test_m2_target,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9040347655763759"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate model using best model and cross validation\n",
    "pecc_xgb = cross_val_score(xgboost_model, train_m2, train_m2_target, cv = 5).mean()\n",
    "pecc_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3\n",
    "#### Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.430712</td>\n",
       "      <td>1.468709</td>\n",
       "      <td>1.315671</td>\n",
       "      <td>0.575506</td>\n",
       "      <td>-0.009193</td>\n",
       "      <td>0.963609</td>\n",
       "      <td>-0.409284</td>\n",
       "      <td>1.511648</td>\n",
       "      <td>0.731850</td>\n",
       "      <td>0.727884</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167650</td>\n",
       "      <td>0.249588</td>\n",
       "      <td>-0.390321</td>\n",
       "      <td>0.162454</td>\n",
       "      <td>-0.975689</td>\n",
       "      <td>-1.023979</td>\n",
       "      <td>-1.142809</td>\n",
       "      <td>-1.113536</td>\n",
       "      <td>-0.696420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.430712</td>\n",
       "      <td>-1.026811</td>\n",
       "      <td>1.315671</td>\n",
       "      <td>1.079601</td>\n",
       "      <td>-0.009193</td>\n",
       "      <td>0.963609</td>\n",
       "      <td>-0.409284</td>\n",
       "      <td>-0.661530</td>\n",
       "      <td>-0.508577</td>\n",
       "      <td>-0.709064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204000</td>\n",
       "      <td>0.249588</td>\n",
       "      <td>-0.390321</td>\n",
       "      <td>0.162454</td>\n",
       "      <td>0.971222</td>\n",
       "      <td>0.699099</td>\n",
       "      <td>-0.434338</td>\n",
       "      <td>0.905339</td>\n",
       "      <td>0.940431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.430712</td>\n",
       "      <td>-1.026811</td>\n",
       "      <td>1.315671</td>\n",
       "      <td>1.079601</td>\n",
       "      <td>-0.009193</td>\n",
       "      <td>0.963609</td>\n",
       "      <td>-0.409284</td>\n",
       "      <td>-0.661530</td>\n",
       "      <td>-1.335529</td>\n",
       "      <td>0.009410</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167650</td>\n",
       "      <td>0.249588</td>\n",
       "      <td>-0.390321</td>\n",
       "      <td>0.162454</td>\n",
       "      <td>0.971222</td>\n",
       "      <td>-0.097719</td>\n",
       "      <td>0.901635</td>\n",
       "      <td>0.905889</td>\n",
       "      <td>0.940431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.595616</td>\n",
       "      <td>0.359589</td>\n",
       "      <td>-0.284073</td>\n",
       "      <td>-1.944969</td>\n",
       "      <td>-0.009193</td>\n",
       "      <td>-1.037765</td>\n",
       "      <td>-0.409284</td>\n",
       "      <td>-0.661530</td>\n",
       "      <td>-0.922053</td>\n",
       "      <td>1.446358</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167650</td>\n",
       "      <td>0.249588</td>\n",
       "      <td>-0.390321</td>\n",
       "      <td>0.162454</td>\n",
       "      <td>-1.705780</td>\n",
       "      <td>-1.326568</td>\n",
       "      <td>1.529138</td>\n",
       "      <td>-1.430308</td>\n",
       "      <td>-1.655691</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.430712</td>\n",
       "      <td>1.468709</td>\n",
       "      <td>-0.284073</td>\n",
       "      <td>1.079601</td>\n",
       "      <td>-0.009193</td>\n",
       "      <td>-1.037765</td>\n",
       "      <td>-0.409284</td>\n",
       "      <td>-0.661530</td>\n",
       "      <td>-1.335529</td>\n",
       "      <td>-0.709064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947301</td>\n",
       "      <td>0.249588</td>\n",
       "      <td>-0.390321</td>\n",
       "      <td>0.162454</td>\n",
       "      <td>0.971222</td>\n",
       "      <td>-0.097719</td>\n",
       "      <td>0.901635</td>\n",
       "      <td>0.906989</td>\n",
       "      <td>0.940431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       job   marital  education   default   housing      loan  \\\n",
       "0  0.430712  1.468709  1.315671   0.575506 -0.009193  0.963609 -0.409284   \n",
       "1  0.430712 -1.026811  1.315671   1.079601 -0.009193  0.963609 -0.409284   \n",
       "2  0.430712 -1.026811  1.315671   1.079601 -0.009193  0.963609 -0.409284   \n",
       "3  2.595616  0.359589 -0.284073  -1.944969 -0.009193 -1.037765 -0.409284   \n",
       "4  0.430712  1.468709 -0.284073   1.079601 -0.009193 -1.037765 -0.409284   \n",
       "\n",
       "    contact     month  day_of_week  ...  campaign     pdays  previous  \\\n",
       "0  1.511648  0.731850     0.727884  ... -0.167650  0.249588 -0.390321   \n",
       "1 -0.661530 -0.508577    -0.709064  ...  0.204000  0.249588 -0.390321   \n",
       "2 -0.661530 -1.335529     0.009410  ... -0.167650  0.249588 -0.390321   \n",
       "3 -0.661530 -0.922053     1.446358  ... -0.167650  0.249588 -0.390321   \n",
       "4 -0.661530 -1.335529    -0.709064  ...  0.947301  0.249588 -0.390321   \n",
       "\n",
       "   poutcome  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
       "0  0.162454     -0.975689       -1.023979      -1.142809  -1.113536   \n",
       "1  0.162454      0.971222        0.699099      -0.434338   0.905339   \n",
       "2  0.162454      0.971222       -0.097719       0.901635   0.905889   \n",
       "3  0.162454     -1.705780       -1.326568       1.529138  -1.430308   \n",
       "4  0.162454      0.971222       -0.097719       0.901635   0.906989   \n",
       "\n",
       "   nr.employed  y  \n",
       "0    -0.696420  0  \n",
       "1     0.940431  0  \n",
       "2     0.940431  0  \n",
       "3    -1.655691  1  \n",
       "4     0.940431  0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_m3 = pd.read_csv('../../../../Data_AA2/train_m3.csv', sep = ',')\n",
    "train_m3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.430712</td>\n",
       "      <td>-0.749531</td>\n",
       "      <td>-0.284073</td>\n",
       "      <td>-1.440874</td>\n",
       "      <td>-0.009193</td>\n",
       "      <td>0.963609</td>\n",
       "      <td>-0.409284</td>\n",
       "      <td>-0.661530</td>\n",
       "      <td>-0.508577</td>\n",
       "      <td>-0.709064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947301</td>\n",
       "      <td>0.249588</td>\n",
       "      <td>-0.390321</td>\n",
       "      <td>0.162454</td>\n",
       "      <td>0.971222</td>\n",
       "      <td>0.699099</td>\n",
       "      <td>-0.434338</td>\n",
       "      <td>0.904239</td>\n",
       "      <td>0.940431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.430712</td>\n",
       "      <td>-1.026811</td>\n",
       "      <td>-0.284073</td>\n",
       "      <td>-0.432684</td>\n",
       "      <td>-0.009193</td>\n",
       "      <td>0.963609</td>\n",
       "      <td>-0.409284</td>\n",
       "      <td>1.511648</td>\n",
       "      <td>0.731850</td>\n",
       "      <td>0.009410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575650</td>\n",
       "      <td>0.249588</td>\n",
       "      <td>-0.390321</td>\n",
       "      <td>0.162454</td>\n",
       "      <td>0.788699</td>\n",
       "      <td>0.826859</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.849244</td>\n",
       "      <td>0.469678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.430712</td>\n",
       "      <td>-1.026811</td>\n",
       "      <td>-0.284073</td>\n",
       "      <td>-1.440874</td>\n",
       "      <td>-0.009193</td>\n",
       "      <td>0.963609</td>\n",
       "      <td>2.443291</td>\n",
       "      <td>1.511648</td>\n",
       "      <td>0.731850</td>\n",
       "      <td>0.727884</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.539300</td>\n",
       "      <td>0.249588</td>\n",
       "      <td>-0.390321</td>\n",
       "      <td>0.162454</td>\n",
       "      <td>0.788699</td>\n",
       "      <td>0.826859</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.847594</td>\n",
       "      <td>0.469678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.430712</td>\n",
       "      <td>-1.026811</td>\n",
       "      <td>-0.284073</td>\n",
       "      <td>1.079601</td>\n",
       "      <td>-0.009193</td>\n",
       "      <td>0.963609</td>\n",
       "      <td>-0.409284</td>\n",
       "      <td>-0.661530</td>\n",
       "      <td>-0.095102</td>\n",
       "      <td>-0.709064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.539300</td>\n",
       "      <td>0.249588</td>\n",
       "      <td>1.459600</td>\n",
       "      <td>-2.255863</td>\n",
       "      <td>-1.644939</td>\n",
       "      <td>-0.906305</td>\n",
       "      <td>-0.049740</td>\n",
       "      <td>-1.155332</td>\n",
       "      <td>-0.986993</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.430712</td>\n",
       "      <td>-0.749531</td>\n",
       "      <td>-0.284073</td>\n",
       "      <td>-1.440874</td>\n",
       "      <td>-0.009193</td>\n",
       "      <td>0.963609</td>\n",
       "      <td>-0.409284</td>\n",
       "      <td>-0.661530</td>\n",
       "      <td>0.731850</td>\n",
       "      <td>0.727884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947301</td>\n",
       "      <td>0.249588</td>\n",
       "      <td>-0.390321</td>\n",
       "      <td>0.162454</td>\n",
       "      <td>-0.975689</td>\n",
       "      <td>-1.023979</td>\n",
       "      <td>-1.142809</td>\n",
       "      <td>-1.084388</td>\n",
       "      <td>-0.696420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       job   marital  education   default   housing      loan  \\\n",
       "0  0.430712 -0.749531 -0.284073  -1.440874 -0.009193  0.963609 -0.409284   \n",
       "1  0.430712 -1.026811 -0.284073  -0.432684 -0.009193  0.963609 -0.409284   \n",
       "2  0.430712 -1.026811 -0.284073  -1.440874 -0.009193  0.963609  2.443291   \n",
       "3  0.430712 -1.026811 -0.284073   1.079601 -0.009193  0.963609 -0.409284   \n",
       "4  0.430712 -0.749531 -0.284073  -1.440874 -0.009193  0.963609 -0.409284   \n",
       "\n",
       "    contact     month  day_of_week  ...  campaign     pdays  previous  \\\n",
       "0 -0.661530 -0.508577    -0.709064  ...  0.947301  0.249588 -0.390321   \n",
       "1  1.511648  0.731850     0.009410  ...  0.575650  0.249588 -0.390321   \n",
       "2  1.511648  0.731850     0.727884  ... -0.539300  0.249588 -0.390321   \n",
       "3 -0.661530 -0.095102    -0.709064  ... -0.539300  0.249588  1.459600   \n",
       "4 -0.661530  0.731850     0.727884  ...  0.947301  0.249588 -0.390321   \n",
       "\n",
       "   poutcome  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
       "0  0.162454      0.971222        0.699099      -0.434338   0.904239   \n",
       "1  0.162454      0.788699        0.826859       0.840909   0.849244   \n",
       "2  0.162454      0.788699        0.826859       0.840909   0.847594   \n",
       "3 -2.255863     -1.644939       -0.906305      -0.049740  -1.155332   \n",
       "4  0.162454     -0.975689       -1.023979      -1.142809  -1.084388   \n",
       "\n",
       "   nr.employed  y  \n",
       "0     0.940431  0  \n",
       "1     0.469678  0  \n",
       "2     0.469678  0  \n",
       "3    -0.986993  0  \n",
       "4    -0.696420  0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_m3 = pd.read_csv('../../../../Data_AA2/test_m3.csv', sep = ',')\n",
    "test_m3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get target\n",
    "train_m3_target = train_m3['y']\n",
    "train_m3 = train_m3.drop(columns=['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get target\n",
    "test_m3_target = test_m3['y']\n",
    "test_m3 = test_m3.drop(columns=['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for lower errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [02:00<00:00,  3.10s/it]\n"
     ]
    }
   ],
   "source": [
    "error_rate = []\n",
    "\n",
    "for i in tqdm(range(1,40)):\n",
    "    xgb = XGBClassifier(max_depth=i)\n",
    "    xgb.fit(train_m3,train_m3_target)\n",
    "    predictions = xgb.predict(test_m3)\n",
    "    error_rate.append(np.mean(predictions != test_m3_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Error Rate')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(25,6))\n",
    "plt.plot(range(1,40),error_rate,color='blue',linestyle='dashed',marker='o',markerfacecolor='red',markersize=10)\n",
    "plt.title('Error Rate vs DepthValue')\n",
    "plt.xlabel(\"depth\")\n",
    "plt.ylabel(\"Error Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.8, gamma=0.5, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=4,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1.0,\n",
      "              tree_method='exact', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "parameters = {\n",
    "        'min_child_weight': [1, 5],\n",
    "        'gamma': [0.5, 1, 1.5],\n",
    "        'subsample': [0.6, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8],\n",
    "        'max_depth': [2, 3,4]\n",
    "        }\n",
    "\n",
    "# Create the model\n",
    "xgboost_model = XGBClassifier(use_label_encoder=False)\n",
    "\n",
    "# Best model\n",
    "opt_model_xgb = GridSearchCV(xgboost_model, parameters,  scoring='accuracy', verbose=1)\n",
    "\n",
    "# Fit the model\n",
    "opt_model_xgb.fit(train_m3, train_m3_target)\n",
    "\n",
    "print (opt_model_xgb.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8, gamma=0.5, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=4,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1.0,\n",
       "              tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model with best parameters\n",
    "xgboost_model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.8, gamma=0.5, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=0.300000012, max_delta_step=0, max_depth=4,\n",
    "              min_child_weight=1, \n",
    "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1.0,\n",
    "              tree_method='exact', use_label_encoder=False,\n",
    "              validate_parameters=1, verbosity=None)\n",
    "\n",
    "# Fit the best model\n",
    "xgboost_model.fit(train_m3, train_m3_target)\n",
    "xgboost_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted     0     1   All\n",
      "Actual                     \n",
      "0          7506   454  7960\n",
      "1           428   759  1187\n",
      "All        7934  1213  9147\n"
     ]
    }
   ],
   "source": [
    "predictions = xgboost_model.predict(test_m3)\n",
    "\n",
    "# Confusion matrix\n",
    "confusion = pd.crosstab(test_m3_target,predictions, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusion )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.903575\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "score = accuracy_score(test_m3_target,predictions)\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94      7960\n",
      "           1       0.63      0.64      0.63      1187\n",
      "\n",
      "    accuracy                           0.90      9147\n",
      "   macro avg       0.79      0.79      0.79      9147\n",
      "weighted avg       0.90      0.90      0.90      9147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report\n",
    "print(classification_report(test_m3_target,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8920115940259276"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate model using best model and cross validation\n",
    "pecc_xgb = cross_val_score(xgboost_model, train_m3, train_m3_target, cv = 5).mean()\n",
    "pecc_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4\n",
    "#### Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>contact</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.038917</td>\n",
       "      <td>1.363073</td>\n",
       "      <td>-0.351284</td>\n",
       "      <td>-0.512695</td>\n",
       "      <td>1.325358</td>\n",
       "      <td>0.350664</td>\n",
       "      <td>-0.204429</td>\n",
       "      <td>0.196894</td>\n",
       "      <td>-0.351367</td>\n",
       "      <td>0.195096</td>\n",
       "      <td>0.840943</td>\n",
       "      <td>1.537557</td>\n",
       "      <td>-0.279432</td>\n",
       "      <td>0.778118</td>\n",
       "      <td>0.846583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.761163</td>\n",
       "      <td>-0.286126</td>\n",
       "      <td>-0.820426</td>\n",
       "      <td>-0.512695</td>\n",
       "      <td>1.325358</td>\n",
       "      <td>1.966453</td>\n",
       "      <td>0.156584</td>\n",
       "      <td>0.196894</td>\n",
       "      <td>-0.351367</td>\n",
       "      <td>0.195096</td>\n",
       "      <td>0.840943</td>\n",
       "      <td>0.594054</td>\n",
       "      <td>-0.473904</td>\n",
       "      <td>0.774087</td>\n",
       "      <td>0.846583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.038917</td>\n",
       "      <td>-0.286126</td>\n",
       "      <td>1.056145</td>\n",
       "      <td>-0.512695</td>\n",
       "      <td>-0.754513</td>\n",
       "      <td>-0.457231</td>\n",
       "      <td>-0.565442</td>\n",
       "      <td>0.196894</td>\n",
       "      <td>1.645136</td>\n",
       "      <td>-2.544702</td>\n",
       "      <td>-1.193288</td>\n",
       "      <td>-1.173936</td>\n",
       "      <td>-1.230186</td>\n",
       "      <td>-1.325914</td>\n",
       "      <td>-0.938246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.038917</td>\n",
       "      <td>1.363073</td>\n",
       "      <td>1.056145</td>\n",
       "      <td>-0.512695</td>\n",
       "      <td>1.325358</td>\n",
       "      <td>0.350664</td>\n",
       "      <td>-0.565442</td>\n",
       "      <td>0.196894</td>\n",
       "      <td>-0.351367</td>\n",
       "      <td>0.195096</td>\n",
       "      <td>-1.193288</td>\n",
       "      <td>-0.860010</td>\n",
       "      <td>-1.424658</td>\n",
       "      <td>-1.272939</td>\n",
       "      <td>-0.938246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.038917</td>\n",
       "      <td>-0.286126</td>\n",
       "      <td>1.056145</td>\n",
       "      <td>1.948838</td>\n",
       "      <td>1.325358</td>\n",
       "      <td>-1.265125</td>\n",
       "      <td>0.517596</td>\n",
       "      <td>0.196894</td>\n",
       "      <td>-0.351367</td>\n",
       "      <td>0.195096</td>\n",
       "      <td>0.840943</td>\n",
       "      <td>1.537557</td>\n",
       "      <td>-0.279432</td>\n",
       "      <td>0.771208</td>\n",
       "      <td>0.846583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        job   marital  education   default   contact  duration  campaign  \\\n",
       "0 -1.038917  1.363073  -0.351284 -0.512695  1.325358  0.350664 -0.204429   \n",
       "1 -0.761163 -0.286126  -0.820426 -0.512695  1.325358  1.966453  0.156584   \n",
       "2 -1.038917 -0.286126   1.056145 -0.512695 -0.754513 -0.457231 -0.565442   \n",
       "3 -1.038917  1.363073   1.056145 -0.512695  1.325358  0.350664 -0.565442   \n",
       "4 -1.038917 -0.286126   1.056145  1.948838  1.325358 -1.265125  0.517596   \n",
       "\n",
       "      pdays  previous  poutcome  emp.var.rate  cons.price.idx  cons.conf.idx  \\\n",
       "0  0.196894 -0.351367  0.195096      0.840943        1.537557      -0.279432   \n",
       "1  0.196894 -0.351367  0.195096      0.840943        0.594054      -0.473904   \n",
       "2  0.196894  1.645136 -2.544702     -1.193288       -1.173936      -1.230186   \n",
       "3  0.196894 -0.351367  0.195096     -1.193288       -0.860010      -1.424658   \n",
       "4  0.196894 -0.351367  0.195096      0.840943        1.537557      -0.279432   \n",
       "\n",
       "   euribor3m  nr.employed  y  \n",
       "0   0.778118     0.846583  0  \n",
       "1   0.774087     0.846583  1  \n",
       "2  -1.325914    -0.938246  0  \n",
       "3  -1.272939    -0.938246  0  \n",
       "4   0.771208     0.846583  0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_m4 = pd.read_csv('../../../../Data_AA2/train_m4.csv', sep = ',')\n",
    "train_m4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>contact</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.349854</td>\n",
       "      <td>-0.286126</td>\n",
       "      <td>-0.351284</td>\n",
       "      <td>-0.512695</td>\n",
       "      <td>-0.754513</td>\n",
       "      <td>1.158558</td>\n",
       "      <td>-0.565442</td>\n",
       "      <td>0.196894</td>\n",
       "      <td>-0.351367</td>\n",
       "      <td>0.195096</td>\n",
       "      <td>-0.112602</td>\n",
       "      <td>-0.644401</td>\n",
       "      <td>-0.322648</td>\n",
       "      <td>0.265066</td>\n",
       "      <td>0.399684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.905362</td>\n",
       "      <td>-0.286126</td>\n",
       "      <td>-0.351284</td>\n",
       "      <td>1.948838</td>\n",
       "      <td>-0.754513</td>\n",
       "      <td>-1.265125</td>\n",
       "      <td>-0.565442</td>\n",
       "      <td>0.196894</td>\n",
       "      <td>-0.351367</td>\n",
       "      <td>0.195096</td>\n",
       "      <td>-0.112602</td>\n",
       "      <td>-0.644401</td>\n",
       "      <td>-0.322648</td>\n",
       "      <td>0.233396</td>\n",
       "      <td>0.399684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.761163</td>\n",
       "      <td>-0.286126</td>\n",
       "      <td>-1.758712</td>\n",
       "      <td>1.948838</td>\n",
       "      <td>1.325358</td>\n",
       "      <td>-0.457231</td>\n",
       "      <td>-0.565442</td>\n",
       "      <td>0.196894</td>\n",
       "      <td>-0.351367</td>\n",
       "      <td>0.195096</td>\n",
       "      <td>0.650234</td>\n",
       "      <td>0.725144</td>\n",
       "      <td>0.887403</td>\n",
       "      <td>0.714778</td>\n",
       "      <td>0.333271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.460871</td>\n",
       "      <td>1.363073</td>\n",
       "      <td>1.056145</td>\n",
       "      <td>-0.512695</td>\n",
       "      <td>-0.754513</td>\n",
       "      <td>1.966453</td>\n",
       "      <td>-0.565442</td>\n",
       "      <td>0.196894</td>\n",
       "      <td>1.645136</td>\n",
       "      <td>-2.544702</td>\n",
       "      <td>-1.193288</td>\n",
       "      <td>-1.173936</td>\n",
       "      <td>-1.230186</td>\n",
       "      <td>-1.333976</td>\n",
       "      <td>-0.938246</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.038917</td>\n",
       "      <td>-1.935325</td>\n",
       "      <td>-0.351284</td>\n",
       "      <td>-0.512695</td>\n",
       "      <td>1.325358</td>\n",
       "      <td>-1.265125</td>\n",
       "      <td>-0.204429</td>\n",
       "      <td>0.196894</td>\n",
       "      <td>1.645136</td>\n",
       "      <td>-2.544702</td>\n",
       "      <td>-1.193288</td>\n",
       "      <td>-1.173936</td>\n",
       "      <td>-1.230186</td>\n",
       "      <td>-1.333976</td>\n",
       "      <td>-0.938246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        job   marital  education   default   contact  duration  campaign  \\\n",
       "0  0.349854 -0.286126  -0.351284 -0.512695 -0.754513  1.158558 -0.565442   \n",
       "1  0.905362 -0.286126  -0.351284  1.948838 -0.754513 -1.265125 -0.565442   \n",
       "2 -0.761163 -0.286126  -1.758712  1.948838  1.325358 -0.457231 -0.565442   \n",
       "3  1.460871  1.363073   1.056145 -0.512695 -0.754513  1.966453 -0.565442   \n",
       "4 -1.038917 -1.935325  -0.351284 -0.512695  1.325358 -1.265125 -0.204429   \n",
       "\n",
       "      pdays  previous  poutcome  emp.var.rate  cons.price.idx  cons.conf.idx  \\\n",
       "0  0.196894 -0.351367  0.195096     -0.112602       -0.644401      -0.322648   \n",
       "1  0.196894 -0.351367  0.195096     -0.112602       -0.644401      -0.322648   \n",
       "2  0.196894 -0.351367  0.195096      0.650234        0.725144       0.887403   \n",
       "3  0.196894  1.645136 -2.544702     -1.193288       -1.173936      -1.230186   \n",
       "4  0.196894  1.645136 -2.544702     -1.193288       -1.173936      -1.230186   \n",
       "\n",
       "   euribor3m  nr.employed  y  \n",
       "0   0.265066     0.399684  1  \n",
       "1   0.233396     0.399684  0  \n",
       "2   0.714778     0.333271  0  \n",
       "3  -1.333976    -0.938246  1  \n",
       "4  -1.333976    -0.938246  0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_m4 = pd.read_csv('../../../../Data_AA2/test_m4.csv', sep = ',')\n",
    "test_m4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get target\n",
    "train_m4_target = train_m4['y']\n",
    "train_m4 = train_m4.drop(columns=['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get target\n",
    "test_m4_target = test_m4['y']\n",
    "test_m4 = test_m4.drop(columns=['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for lower errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▍                                                                                 | 1/59 [00:00<00:17,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▊                                                                                | 2/59 [00:00<00:16,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|████▏                                                                              | 3/59 [00:00<00:18,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▋                                                                             | 4/59 [00:01<00:20,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███████                                                                            | 5/59 [00:02<00:24,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▍                                                                          | 6/59 [00:02<00:28,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▊                                                                         | 7/59 [00:03<00:33,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▎                                                                       | 8/59 [00:04<00:40,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▋                                                                      | 9/59 [00:06<00:50,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████▉                                                                    | 10/59 [00:08<00:59,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▎                                                                  | 11/59 [00:09<01:03,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▋                                                                 | 12/59 [00:11<01:12,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██████████████████                                                                | 13/59 [00:14<01:21,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▍                                                              | 14/59 [00:16<01:30,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▊                                                             | 15/59 [00:18<01:31,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██████████████████████▏                                                           | 16/59 [00:21<01:33,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|███████████████████████▋                                                          | 17/59 [00:23<01:34,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████                                                         | 18/59 [00:26<01:35,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|██████████████████████████▍                                                       | 19/59 [00:28<01:37,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▊                                                      | 20/59 [00:31<01:40,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▏                                                    | 21/59 [00:34<01:42,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|██████████████████████████████▌                                                   | 22/59 [00:38<01:48,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███████████████████████████████▉                                                  | 23/59 [00:41<01:49,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|█████████████████████████████████▎                                                | 24/59 [00:44<01:48,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|██████████████████████████████████▋                                               | 25/59 [00:48<01:49,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████████████████████████████████████▏                                             | 26/59 [00:51<01:47,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|█████████████████████████████████████▌                                            | 27/59 [00:55<01:45,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|██████████████████████████████████████▉                                           | 28/59 [00:58<01:46,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:45:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████████████████████████████████████████▎                                         | 29/59 [01:02<01:45,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:45:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████████████████████████████████████████▋                                        | 30/59 [01:06<01:48,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:45:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|███████████████████████████████████████████                                       | 31/59 [01:10<01:48,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:45:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|████████████████████████████████████████████▍                                     | 32/59 [01:15<01:51,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:45:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████████████████████████████████████████████▊                                    | 33/59 [01:19<01:48,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:45:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|███████████████████████████████████████████████▎                                  | 34/59 [01:24<01:47,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:45:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|████████████████████████████████████████████████▋                                 | 35/59 [01:28<01:42,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:45:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████████████████████████████████████████████████                                | 36/59 [01:32<01:37,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:45:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|███████████████████████████████████████████████████▍                              | 37/59 [01:36<01:28,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:45:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|████████████████████████████████████████████████████▊                             | 38/59 [01:40<01:23,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:45:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████████████████████████████████████████████████████▏                           | 39/59 [01:43<01:17,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:45:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|███████████████████████████████████████████████████████▌                          | 40/59 [01:47<01:12,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:45:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|████████████████████████████████████████████████████████▉                         | 41/59 [01:51<01:06,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:45:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|██████████████████████████████████████████████████████████▎                       | 42/59 [01:54<01:03,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:45:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████████████████████████████████████████████████████████▊                      | 43/59 [01:58<01:00,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:46:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|█████████████████████████████████████████████████████████████▏                    | 44/59 [02:02<00:56,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:46:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|██████████████████████████████████████████████████████████████▌                   | 45/59 [02:06<00:52,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:46:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████████████████████████████████████████████████████████████▉                  | 46/59 [02:09<00:48,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:46:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▎                | 47/59 [02:13<00:43,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:46:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|██████████████████████████████████████████████████████████████████▋               | 48/59 [02:16<00:40,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:46:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████████████████████████████████████████████████████████████████              | 49/59 [02:20<00:36,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:46:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|█████████████████████████████████████████████████████████████████████▍            | 50/59 [02:24<00:32,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:46:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|██████████████████████████████████████████████████████████████████████▉           | 51/59 [02:27<00:29,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:46:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████████████████████████████████████████████████████████████████████▎         | 52/59 [02:31<00:25,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:46:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████████████████████████████████████████████████████████▋        | 53/59 [02:35<00:21,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:46:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|███████████████████████████████████████████████████████████████████████████       | 54/59 [02:38<00:18,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:46:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|████████████████████████████████████████████████████████████████████████████▍     | 55/59 [02:42<00:14,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:46:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████████████████████████████████████████████████████████████████████████▊    | 56/59 [02:46<00:11,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:46:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|███████████████████████████████████████████████████████████████████████████████▏  | 57/59 [02:50<00:07,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:46:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|████████████████████████████████████████████████████████████████████████████████▌ | 58/59 [02:53<00:03,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:46:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [02:57<00:00,  3.01s/it]\n"
     ]
    }
   ],
   "source": [
    "error_rate = []\n",
    "\n",
    "for i in tqdm(range(1,60)):\n",
    "    xgb = XGBClassifier(max_depth=i)\n",
    "    xgb.fit(train_m4,train_m4_target)\n",
    "    predictions = xgb.predict(test_m4)\n",
    "    error_rate.append(np.mean(predictions != test_m4_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Error Rate')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(25,6))\n",
    "plt.plot(range(1,60),error_rate,color='blue',linestyle='dashed',marker='o',markerfacecolor='red',markersize=10)\n",
    "plt.title('Error Rate vs DepthValue')\n",
    "plt.xlabel(\"depth\")\n",
    "plt.ylabel(\"Error Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "[23:49:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:49:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:49:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:49:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:49:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:50:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:50:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:50:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:50:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:50:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:51:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:51:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:51:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:51:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:51:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:52:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:52:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:52:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.8, gamma=1.5, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1.0,\n",
      "              tree_method='exact', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "parameters = {\n",
    "        'min_child_weight': [1, 5],\n",
    "        'gamma': [0.5, 1, 1.5],\n",
    "        'subsample': [0.6, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8],\n",
    "        'max_depth': [2, 3,4, 5]\n",
    "        }\n",
    "\n",
    "# Create the model\n",
    "xgboost_model = XGBClassifier(use_label_encoder=False)\n",
    "\n",
    "# Best model\n",
    "opt_model_xgb = GridSearchCV(xgboost_model, parameters,  scoring='accuracy', verbose=1)\n",
    "\n",
    "# Fit the model\n",
    "opt_model_xgb.fit(train_m4, train_m4_target)\n",
    "\n",
    "print (opt_model_xgb.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:56:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8, gamma=1.5, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1.0,\n",
       "              tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model with best parameters\n",
    "xgboost_model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.8, gamma=1.5, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=0.300000012, max_delta_step=0, max_depth=3,\n",
    "              min_child_weight=1, monotone_constraints='()',\n",
    "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1.0,\n",
    "              tree_method='exact', use_label_encoder=False,\n",
    "              validate_parameters=1, verbosity=None)\n",
    "\n",
    "# Fit the best model\n",
    "xgboost_model.fit(train_m4, train_m4_target)\n",
    "xgboost_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0     1    All\n",
      "Actual                       \n",
      "0          10586   381  10967\n",
      "1            669   721   1390\n",
      "All        11255  1102  12357\n"
     ]
    }
   ],
   "source": [
    "predictions = xgboost_model.predict(test_m4)\n",
    "\n",
    "# Confusion matrix\n",
    "confusion = pd.crosstab(test_m4_target,predictions, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusion )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.915028\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "score = accuracy_score(test_m4_target,predictions)\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95     10967\n",
      "           1       0.65      0.52      0.58      1390\n",
      "\n",
      "    accuracy                           0.92     12357\n",
      "   macro avg       0.80      0.74      0.77     12357\n",
      "weighted avg       0.91      0.92      0.91     12357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report\n",
    "print(classification_report(test_m4_target,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:56:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:56:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:56:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:56:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:56:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9122126496149676"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate model using best model and cross validation\n",
    "pecc_xgb = cross_val_score(xgboost_model, train_m4, train_m4_target, cv = 5).mean()\n",
    "pecc_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5\n",
    "#### Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.542856</td>\n",
       "      <td>-1.154683</td>\n",
       "      <td>1.504582</td>\n",
       "      <td>1.376593</td>\n",
       "      <td>0.689601</td>\n",
       "      <td>-0.010201</td>\n",
       "      <td>0.928497</td>\n",
       "      <td>-0.429774</td>\n",
       "      <td>-0.758480</td>\n",
       "      <td>1.194001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.204674</td>\n",
       "      <td>-5.083824</td>\n",
       "      <td>1.660200</td>\n",
       "      <td>2.938971</td>\n",
       "      <td>-1.947193</td>\n",
       "      <td>-0.804593</td>\n",
       "      <td>2.226079</td>\n",
       "      <td>-1.425183</td>\n",
       "      <td>-2.064840</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.506227</td>\n",
       "      <td>-0.963193</td>\n",
       "      <td>-0.754426</td>\n",
       "      <td>1.376593</td>\n",
       "      <td>-1.766225</td>\n",
       "      <td>-0.010201</td>\n",
       "      <td>0.928497</td>\n",
       "      <td>-0.429774</td>\n",
       "      <td>-0.758480</td>\n",
       "      <td>-0.531893</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.204674</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>-0.351282</td>\n",
       "      <td>0.193233</td>\n",
       "      <td>0.763192</td>\n",
       "      <td>0.898330</td>\n",
       "      <td>-0.539387</td>\n",
       "      <td>0.760455</td>\n",
       "      <td>0.845530</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.116306</td>\n",
       "      <td>1.334690</td>\n",
       "      <td>1.504582</td>\n",
       "      <td>-1.926794</td>\n",
       "      <td>1.180766</td>\n",
       "      <td>-0.010201</td>\n",
       "      <td>-1.077009</td>\n",
       "      <td>2.326804</td>\n",
       "      <td>1.318426</td>\n",
       "      <td>0.762528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.204674</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>-0.351282</td>\n",
       "      <td>0.193233</td>\n",
       "      <td>0.763192</td>\n",
       "      <td>0.898330</td>\n",
       "      <td>0.949710</td>\n",
       "      <td>0.760455</td>\n",
       "      <td>0.332751</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.179061</td>\n",
       "      <td>-0.197232</td>\n",
       "      <td>-1.036802</td>\n",
       "      <td>-0.275101</td>\n",
       "      <td>1.180766</td>\n",
       "      <td>-0.010201</td>\n",
       "      <td>0.928497</td>\n",
       "      <td>2.326804</td>\n",
       "      <td>1.318426</td>\n",
       "      <td>0.762528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.204674</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>-0.351282</td>\n",
       "      <td>0.193233</td>\n",
       "      <td>0.763192</td>\n",
       "      <td>0.898330</td>\n",
       "      <td>0.949710</td>\n",
       "      <td>0.760455</td>\n",
       "      <td>0.332751</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.880355</td>\n",
       "      <td>-0.388722</td>\n",
       "      <td>-0.754426</td>\n",
       "      <td>1.376593</td>\n",
       "      <td>0.689601</td>\n",
       "      <td>-0.010201</td>\n",
       "      <td>0.928497</td>\n",
       "      <td>-0.429774</td>\n",
       "      <td>-0.758480</td>\n",
       "      <td>0.762528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.560688</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>-0.351282</td>\n",
       "      <td>0.193233</td>\n",
       "      <td>-1.269597</td>\n",
       "      <td>-0.804593</td>\n",
       "      <td>-1.177571</td>\n",
       "      <td>-1.425183</td>\n",
       "      <td>-0.942269</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index       age       job   marital  education   default   housing  \\\n",
       "0  1.542856 -1.154683  1.504582  1.376593   0.689601 -0.010201  0.928497   \n",
       "1 -0.506227 -0.963193 -0.754426  1.376593  -1.766225 -0.010201  0.928497   \n",
       "2 -1.116306  1.334690  1.504582 -1.926794   1.180766 -0.010201 -1.077009   \n",
       "3 -1.179061 -0.197232 -1.036802 -0.275101   1.180766 -0.010201  0.928497   \n",
       "4  0.880355 -0.388722 -0.754426  1.376593   0.689601 -0.010201  0.928497   \n",
       "\n",
       "       loan   contact     month  ...  campaign     pdays  previous  poutcome  \\\n",
       "0 -0.429774 -0.758480  1.194001  ... -0.204674 -5.083824  1.660200  2.938971   \n",
       "1 -0.429774 -0.758480 -0.531893  ... -0.204674  0.196704 -0.351282  0.193233   \n",
       "2  2.326804  1.318426  0.762528  ... -0.204674  0.196704 -0.351282  0.193233   \n",
       "3  2.326804  1.318426  0.762528  ... -0.204674  0.196704 -0.351282  0.193233   \n",
       "4 -0.429774 -0.758480  0.762528  ... -0.560688  0.196704 -0.351282  0.193233   \n",
       "\n",
       "   emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed    y  \n",
       "0     -1.947193       -0.804593       2.226079  -1.425183    -2.064840  1.0  \n",
       "1      0.763192        0.898330      -0.539387   0.760455     0.845530  0.0  \n",
       "2      0.763192        0.898330       0.949710   0.760455     0.332751  0.0  \n",
       "3      0.763192        0.898330       0.949710   0.760455     0.332751  0.0  \n",
       "4     -1.269597       -0.804593      -1.177571  -1.425183    -0.942269  0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_m5 = pd.read_csv('../../../../Data_AA2/train_m5.csv', sep = ',')\n",
    "train_m5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.090003</td>\n",
       "      <td>0.939830</td>\n",
       "      <td>-0.275101</td>\n",
       "      <td>-0.292730</td>\n",
       "      <td>-0.010201</td>\n",
       "      <td>0.928497</td>\n",
       "      <td>-0.429774</td>\n",
       "      <td>1.318426</td>\n",
       "      <td>0.762528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507356</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>-0.351282</td>\n",
       "      <td>0.193233</td>\n",
       "      <td>0.763192</td>\n",
       "      <td>0.898330</td>\n",
       "      <td>0.949710</td>\n",
       "      <td>0.760455</td>\n",
       "      <td>0.332751</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.580213</td>\n",
       "      <td>-1.036802</td>\n",
       "      <td>1.376593</td>\n",
       "      <td>-0.292730</td>\n",
       "      <td>-0.010201</td>\n",
       "      <td>-1.077009</td>\n",
       "      <td>-0.429774</td>\n",
       "      <td>-0.758480</td>\n",
       "      <td>0.762528</td>\n",
       "      <td>...</td>\n",
       "      <td>2.287429</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>-0.351282</td>\n",
       "      <td>0.193233</td>\n",
       "      <td>-1.269597</td>\n",
       "      <td>-0.804593</td>\n",
       "      <td>-1.177571</td>\n",
       "      <td>-1.425183</td>\n",
       "      <td>-0.942269</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.760219</td>\n",
       "      <td>-0.754426</td>\n",
       "      <td>-0.275101</td>\n",
       "      <td>-1.275060</td>\n",
       "      <td>-0.010201</td>\n",
       "      <td>0.928497</td>\n",
       "      <td>-0.429774</td>\n",
       "      <td>-0.758480</td>\n",
       "      <td>0.762528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.204674</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>-0.351282</td>\n",
       "      <td>0.193233</td>\n",
       "      <td>-1.269597</td>\n",
       "      <td>-0.804593</td>\n",
       "      <td>-1.177571</td>\n",
       "      <td>-1.425183</td>\n",
       "      <td>-0.942269</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.153847</td>\n",
       "      <td>0.375078</td>\n",
       "      <td>-1.926794</td>\n",
       "      <td>-1.766225</td>\n",
       "      <td>-0.010201</td>\n",
       "      <td>-1.077009</td>\n",
       "      <td>2.326804</td>\n",
       "      <td>-0.758480</td>\n",
       "      <td>-1.826313</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.560688</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>-0.351282</td>\n",
       "      <td>0.193233</td>\n",
       "      <td>-1.269597</td>\n",
       "      <td>-0.804593</td>\n",
       "      <td>-1.390299</td>\n",
       "      <td>-1.425183</td>\n",
       "      <td>-0.942269</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.813416</td>\n",
       "      <td>0.375078</td>\n",
       "      <td>-0.275101</td>\n",
       "      <td>0.689601</td>\n",
       "      <td>-0.010201</td>\n",
       "      <td>-1.077009</td>\n",
       "      <td>-0.429774</td>\n",
       "      <td>-0.758480</td>\n",
       "      <td>-1.394840</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.560688</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>-0.351282</td>\n",
       "      <td>0.193233</td>\n",
       "      <td>0.763192</td>\n",
       "      <td>-0.804593</td>\n",
       "      <td>0.949710</td>\n",
       "      <td>0.760455</td>\n",
       "      <td>0.845530</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0       age       job   marital  education   default   housing  \\\n",
       "0        1  0.090003  0.939830 -0.275101  -0.292730 -0.010201  0.928497   \n",
       "1        2 -0.580213 -1.036802  1.376593  -0.292730 -0.010201 -1.077009   \n",
       "2        3  0.760219 -0.754426 -0.275101  -1.275060 -0.010201  0.928497   \n",
       "3        4  3.153847  0.375078 -1.926794  -1.766225 -0.010201 -1.077009   \n",
       "4        5  1.813416  0.375078 -0.275101   0.689601 -0.010201 -1.077009   \n",
       "\n",
       "       loan   contact     month  ...  campaign     pdays  previous  poutcome  \\\n",
       "0 -0.429774  1.318426  0.762528  ...  0.507356  0.196704 -0.351282  0.193233   \n",
       "1 -0.429774 -0.758480  0.762528  ...  2.287429  0.196704 -0.351282  0.193233   \n",
       "2 -0.429774 -0.758480  0.762528  ... -0.204674  0.196704 -0.351282  0.193233   \n",
       "3  2.326804 -0.758480 -1.826313  ... -0.560688  0.196704 -0.351282  0.193233   \n",
       "4 -0.429774 -0.758480 -1.394840  ... -0.560688  0.196704 -0.351282  0.193233   \n",
       "\n",
       "   emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed    y  \n",
       "0      0.763192        0.898330       0.949710   0.760455     0.332751  0.0  \n",
       "1     -1.269597       -0.804593      -1.177571  -1.425183    -0.942269  0.0  \n",
       "2     -1.269597       -0.804593      -1.177571  -1.425183    -0.942269  0.0  \n",
       "3     -1.269597       -0.804593      -1.390299  -1.425183    -0.942269  1.0  \n",
       "4      0.763192       -0.804593       0.949710   0.760455     0.845530  0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_m5 = pd.read_csv('../../../../Data_AA2/test_m5.csv', sep = ',')\n",
    "test_m5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get target\n",
    "train_m5 = train_m5.drop(columns=['index'])\n",
    "train_m5_target = train_m5['y']\n",
    "train_m5 = train_m5.drop(columns=['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get target\n",
    "test_m5 = test_m5.drop(columns=['level_0'])\n",
    "test_m5_target = test_m5['y']\n",
    "test_m5 = test_m5.drop(columns=['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for lower errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [02:13<00:00,  3.42s/it]\n"
     ]
    }
   ],
   "source": [
    "error_rate = []\n",
    "\n",
    "for i in tqdm(range(1,40)):\n",
    "    xgb = XGBClassifier(max_depth=i)\n",
    "    xgb.fit(train_m5,train_m5_target)\n",
    "    predictions = xgb.predict(test_m5)\n",
    "    error_rate.append(np.mean(predictions != test_m5_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Error Rate')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(25,6))\n",
    "plt.plot(range(1,40),error_rate,color='blue',linestyle='dashed',marker='o',markerfacecolor='red',markersize=10)\n",
    "plt.title('Error Rate vs DepthValue')\n",
    "plt.xlabel(\"depth\")\n",
    "plt.ylabel(\"Error Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "[CV 1/5; 1/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 1/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 1/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 1/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 3/5; 1/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 1/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 4/5; 1/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 1/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 1/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 1/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 1/5; 2/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 2/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 2/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 2/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 2/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 2/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 2/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 2/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 2/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 2/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 3/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 3/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 3/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 3/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 3/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 3/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 4/5; 3/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 3/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 3/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 3/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 4/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 4/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 4/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 4/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 4/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 4/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 4/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 4/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 4/96] START colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 4/96] END colsample_bytree=0.6, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 5/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 5/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 2/5; 5/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 5/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 5/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 5/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 4/5; 5/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 5/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 5/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 5/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 1/5; 6/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 6/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 6/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 6/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 6/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 6/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 6/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 6/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 6/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 6/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 7/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 7/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 2/5; 7/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 7/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 7/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 7/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 4/5; 7/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 7/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 5/5; 7/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 7/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 1/5; 8/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 8/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 8/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 8/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 8/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 8/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 8/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 8/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 8/96] START colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 8/96] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 9/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 9/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 2/5; 9/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 9/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 9/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 9/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 4/5; 9/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 9/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 5/5; 9/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 9/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 1/5; 10/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 10/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 2/5; 10/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 10/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 3/5; 10/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 10/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 10/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 10/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 5/5; 10/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 10/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 1/5; 11/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 11/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 2/5; 11/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 11/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 11/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 11/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 4/5; 11/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 11/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 11/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 11/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 1/5; 12/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 12/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 12/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 12/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 3/5; 12/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 12/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 4/5; 12/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 12/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.6s\n",
      "[CV 5/5; 12/96] START colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 12/96] END colsample_bytree=0.6, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 1/5; 13/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 13/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.9s\n",
      "[CV 2/5; 13/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 13/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.8s\n",
      "[CV 3/5; 13/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 13/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.8s\n",
      "[CV 4/5; 13/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 13/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.9s\n",
      "[CV 5/5; 13/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 13/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.9s\n",
      "[CV 1/5; 14/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 14/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   1.0s\n",
      "[CV 2/5; 14/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 14/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.8s\n",
      "[CV 3/5; 14/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 14/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.9s\n",
      "[CV 4/5; 14/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 14/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   1.0s\n",
      "[CV 5/5; 14/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 14/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.7s\n",
      "[CV 1/5; 15/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 15/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.8s\n",
      "[CV 2/5; 15/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 15/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.9s\n",
      "[CV 3/5; 15/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 15/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 4/5; 15/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 15/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   1.0s\n",
      "[CV 5/5; 15/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 15/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.9s\n",
      "[CV 1/5; 16/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 16/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.7s\n",
      "[CV 2/5; 16/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 16/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.6s\n",
      "[CV 3/5; 16/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 16/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 4/5; 16/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 16/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   1.0s\n",
      "[CV 5/5; 16/96] START colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 16/96] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.6s\n",
      "[CV 1/5; 17/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 17/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 2/5; 17/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 17/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 17/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 17/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 4/5; 17/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 17/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 5/5; 17/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 17/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 1/5; 18/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 18/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 18/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 18/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 18/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 18/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 18/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 18/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 18/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 18/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 19/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 19/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 2/5; 19/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 19/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 19/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 19/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 4/5; 19/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 19/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 5/5; 19/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 19/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 1/5; 20/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 20/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 20/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 20/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 20/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 20/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 20/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 20/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 20/96] START colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 20/96] END colsample_bytree=0.6, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.6s\n",
      "[CV 1/5; 21/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 21/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 2/5; 21/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 21/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.9s\n",
      "[CV 3/5; 21/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 21/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 4/5; 21/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 21/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 21/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 21/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.8s\n",
      "[CV 1/5; 22/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 22/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.6s\n",
      "[CV 2/5; 22/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 22/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.6s\n",
      "[CV 3/5; 22/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 22/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 22/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 22/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 5/5; 22/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 22/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 1/5; 23/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 23/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 2/5; 23/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 23/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 23/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 23/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 4/5; 23/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 23/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.8s\n",
      "[CV 5/5; 23/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 23/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 1/5; 24/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 24/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 24/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 24/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 24/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 24/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 24/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 24/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 24/96] START colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 24/96] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 25/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 25/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 2/5; 25/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 25/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 3/5; 25/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 25/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 4/5; 25/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 25/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 5/5; 25/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 25/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.8s\n",
      "[CV 1/5; 26/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 26/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.6s\n",
      "[CV 2/5; 26/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 26/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 3/5; 26/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 26/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.6s\n",
      "[CV 4/5; 26/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 26/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.6s\n",
      "[CV 5/5; 26/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 26/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.6s\n",
      "[CV 1/5; 27/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 27/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 2/5; 27/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 27/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 27/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 27/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 4/5; 27/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 27/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.8s\n",
      "[CV 5/5; 27/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 27/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 1/5; 28/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 28/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.7s\n",
      "[CV 2/5; 28/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 28/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.7s\n",
      "[CV 3/5; 28/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 28/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 4/5; 28/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 28/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 28/96] START colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 28/96] END colsample_bytree=0.6, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 29/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 29/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.8s\n",
      "[CV 2/5; 29/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 29/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 3/5; 29/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 29/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 4/5; 29/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 29/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 29/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 29/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 1/5; 30/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 30/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 30/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 30/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.6s\n",
      "[CV 3/5; 30/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 30/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.6s\n",
      "[CV 4/5; 30/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 30/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 30/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 30/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 31/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 31/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 2/5; 31/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 31/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 31/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 31/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 4/5; 31/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 31/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 31/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 31/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 1/5; 32/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 32/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 32/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 32/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.6s\n",
      "[CV 3/5; 32/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 32/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.6s\n",
      "[CV 4/5; 32/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 32/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 5/5; 32/96] START colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 32/96] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.6s\n",
      "[CV 1/5; 33/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 33/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 33/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 33/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 33/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 33/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 33/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 33/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 5/5; 33/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 33/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 34/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 34/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 34/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 34/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 34/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 34/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 34/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 34/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 34/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 34/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 35/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 35/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 35/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 35/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 35/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 35/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 35/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 35/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 35/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 35/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 1/5; 36/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 36/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 36/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 36/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 36/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 36/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 36/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 36/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 36/96] START colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 36/96] END colsample_bytree=0.6, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 37/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 37/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 2/5; 37/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 37/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 37/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 37/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 4/5; 37/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 37/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 37/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 37/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 38/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 38/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 38/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 38/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 38/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 38/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 38/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 38/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 38/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 38/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 39/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 39/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 39/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 39/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 39/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 39/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 4/5; 39/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 39/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 39/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 39/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 40/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 40/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 40/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 40/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 40/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 40/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 40/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 40/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 40/96] START colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 40/96] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 41/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 41/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 2/5; 41/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 41/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 41/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 41/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 4/5; 41/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 41/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 5/5; 41/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 41/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 1/5; 42/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 42/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 42/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 42/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 42/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 42/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 4/5; 42/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 42/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 42/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 42/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 43/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 43/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 2/5; 43/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 43/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 43/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 43/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 4/5; 43/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 43/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 5/5; 43/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 43/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 1/5; 44/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 44/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 44/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 44/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 44/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 44/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 44/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 44/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 44/96] START colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 44/96] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 45/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 45/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   1.5s\n",
      "[CV 2/5; 45/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 45/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 3/5; 45/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 45/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   1.0s\n",
      "[CV 4/5; 45/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 45/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.9s\n",
      "[CV 5/5; 45/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 45/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.9s\n",
      "[CV 1/5; 46/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 46/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.8s\n",
      "[CV 2/5; 46/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 46/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.9s\n",
      "[CV 3/5; 46/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 46/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.7s\n",
      "[CV 4/5; 46/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 46/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.8s\n",
      "[CV 5/5; 46/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 46/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.8s\n",
      "[CV 1/5; 47/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 47/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   1.0s\n",
      "[CV 2/5; 47/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 47/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.8s\n",
      "[CV 3/5; 47/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 47/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.9s\n",
      "[CV 4/5; 47/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 47/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.9s\n",
      "[CV 5/5; 47/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 47/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   1.5s\n",
      "[CV 1/5; 48/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 48/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.6s\n",
      "[CV 2/5; 48/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 48/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 3/5; 48/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 48/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 4/5; 48/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 48/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 5/5; 48/96] START colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 48/96] END colsample_bytree=0.6, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 1/5; 49/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 49/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 49/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 49/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 49/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 49/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 4/5; 49/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 49/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 49/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 49/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 50/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 50/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 50/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 50/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 50/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 50/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 50/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 50/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 50/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 50/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 51/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 51/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 2/5; 51/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 51/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 3/5; 51/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 51/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 4/5; 51/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 51/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 5/5; 51/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 51/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 52/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 52/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 52/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 52/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 52/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 52/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 52/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 52/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 52/96] START colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 52/96] END colsample_bytree=0.8, gamma=0.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 53/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 53/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 2/5; 53/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 53/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 53/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 53/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 4/5; 53/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 53/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 53/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 53/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 54/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 54/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 54/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 54/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 54/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 54/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 54/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 54/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 54/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 54/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 55/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 55/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 2/5; 55/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 55/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 55/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 55/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 4/5; 55/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 55/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 55/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 55/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 56/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 56/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 56/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 56/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 56/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 56/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 56/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 56/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 56/96] START colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 56/96] END colsample_bytree=0.8, gamma=0.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 57/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 57/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 2/5; 57/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 57/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 57/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 57/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 4/5; 57/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 57/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 57/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 57/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 1/5; 58/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 58/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 2/5; 58/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 58/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 3/5; 58/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 58/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 4/5; 58/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 58/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 5/5; 58/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 58/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 59/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 59/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 2/5; 59/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 59/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 59/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 59/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 4/5; 59/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 59/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 59/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 59/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 1/5; 60/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 60/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 60/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 60/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 60/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 60/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 4/5; 60/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 60/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 60/96] START colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 60/96] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 61/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 61/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 2/5; 61/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 61/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 61/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 61/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 4/5; 61/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 61/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 61/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 61/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 1/5; 62/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 62/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 2/5; 62/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 62/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 62/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 62/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 4/5; 62/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 62/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 5/5; 62/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 62/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 1/5; 63/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 63/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.8s\n",
      "[CV 2/5; 63/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 63/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 3/5; 63/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 63/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 4/5; 63/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 63/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 63/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 63/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 1/5; 64/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 64/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 2/5; 64/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 64/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 64/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 64/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 64/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 64/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 5/5; 64/96] START colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 64/96] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.7s\n",
      "[CV 1/5; 65/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 65/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 2/5; 65/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 65/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 65/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 65/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 65/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 65/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 65/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 65/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 66/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 66/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 66/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 66/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 66/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 66/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 66/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 66/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 66/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 66/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 67/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 67/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 67/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 67/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 67/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 67/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 67/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 67/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 67/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 67/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.4s\n",
      "[CV 1/5; 68/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 68/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 68/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 68/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 68/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 68/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 68/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 68/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 68/96] START colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 68/96] END colsample_bytree=0.8, gamma=1, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 69/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 69/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 2/5; 69/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 69/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 3/5; 69/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 69/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 4/5; 69/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 69/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 5/5; 69/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 69/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 1/5; 70/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 70/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 70/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 70/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 70/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 70/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 70/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 70/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 70/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 70/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 71/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 71/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 2/5; 71/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 71/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 3/5; 71/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 71/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 4/5; 71/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 71/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 71/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 71/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 1/5; 72/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 72/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 72/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 72/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 72/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 72/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 72/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 72/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 72/96] START colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 72/96] END colsample_bytree=0.8, gamma=1, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 73/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 73/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 2/5; 73/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 73/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 73/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 73/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 4/5; 73/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 73/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 73/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 73/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 1/5; 74/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 74/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 2/5; 74/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 74/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 74/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 74/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.6s\n",
      "[CV 4/5; 74/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 74/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 5/5; 74/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 74/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 1/5; 75/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 75/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 2/5; 75/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 75/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.8s\n",
      "[CV 3/5; 75/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 75/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 4/5; 75/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 75/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 5/5; 75/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 75/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 1/5; 76/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 76/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 2/5; 76/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 76/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 3/5; 76/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 76/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 4/5; 76/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 76/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 76/96] START colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 76/96] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 77/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 77/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 2/5; 77/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 77/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.8s\n",
      "[CV 3/5; 77/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 77/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.8s\n",
      "[CV 4/5; 77/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 77/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.9s\n",
      "[CV 5/5; 77/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 77/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 1/5; 78/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 78/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 2/5; 78/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 78/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 3/5; 78/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 78/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.6s\n",
      "[CV 4/5; 78/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 78/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 5/5; 78/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 78/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 1/5; 79/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 79/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 2/5; 79/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 79/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 79/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 79/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 4/5; 79/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 79/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 5/5; 79/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 79/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 1/5; 80/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 80/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 2/5; 80/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 80/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 80/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 80/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 4/5; 80/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 80/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.6s\n",
      "[CV 5/5; 80/96] START colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 80/96] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 1/5; 81/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 81/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 81/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 81/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 81/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 81/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 4/5; 81/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 81/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 5/5; 81/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 81/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 82/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 82/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 82/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 82/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 82/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 82/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 82/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 82/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 5/5; 82/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 82/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=1, subsample=1.0; total time=   0.2s\n",
      "[CV 1/5; 83/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 83/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 2/5; 83/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 83/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 3/5; 83/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 83/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 4/5; 83/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 83/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 5/5; 83/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 83/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=0.6; total time=   0.3s\n",
      "[CV 1/5; 84/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 84/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 2/5; 84/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 84/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 3/5; 84/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 84/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.2s\n",
      "[CV 4/5; 84/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 84/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 84/96] START colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 84/96] END colsample_bytree=0.8, gamma=1.5, max_depth=2, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 85/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 85/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 2/5; 85/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 85/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.4s\n",
      "[CV 3/5; 85/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 85/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 4/5; 85/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 85/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 85/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 85/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 1/5; 86/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 86/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 86/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 86/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 86/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 86/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 86/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 86/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 5/5; 86/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 86/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 87/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 87/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 2/5; 87/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 87/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 3/5; 87/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 87/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 4/5; 87/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 87/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 87/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 87/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 1/5; 88/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 88/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 88/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 88/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 3/5; 88/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 88/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 4/5; 88/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 88/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 5/5; 88/96] START colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 88/96] END colsample_bytree=0.8, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 1/5; 89/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 89/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 2/5; 89/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 89/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 89/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 89/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 4/5; 89/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 89/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 5/5; 89/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 89/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=   0.5s\n",
      "[CV 1/5; 90/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 90/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 90/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 90/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 3/5; 90/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 90/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 90/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 90/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 5/5; 90/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 90/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=   0.4s\n",
      "[CV 1/5; 91/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 91/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 2/5; 91/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 91/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 3/5; 91/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 91/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 4/5; 91/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 91/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 5/5; 91/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 91/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=0.6; total time=   0.5s\n",
      "[CV 1/5; 92/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 92/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.3s\n",
      "[CV 2/5; 92/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 92/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 3/5; 92/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 92/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 4/5; 92/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 92/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.7s\n",
      "[CV 5/5; 92/96] START colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 92/96] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 1/5; 93/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 1/5; 93/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.7s\n",
      "[CV 2/5; 93/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 2/5; 93/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.6s\n",
      "[CV 3/5; 93/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 3/5; 93/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.8s\n",
      "[CV 4/5; 93/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 4/5; 93/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   0.8s\n",
      "[CV 5/5; 93/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6\n",
      "[CV 5/5; 93/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time=   1.0s\n",
      "[CV 1/5; 94/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 1/5; 94/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.8s\n",
      "[CV 2/5; 94/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 2/5; 94/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.6s\n",
      "[CV 3/5; 94/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 3/5; 94/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.6s\n",
      "[CV 4/5; 94/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 4/5; 94/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 5/5; 94/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0\n",
      "[CV 5/5; 94/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=1.0; total time=   0.5s\n",
      "[CV 1/5; 95/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 1/5; 95/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 2/5; 95/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 2/5; 95/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.7s\n",
      "[CV 3/5; 95/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 3/5; 95/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.8s\n",
      "[CV 4/5; 95/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 4/5; 95/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.9s\n",
      "[CV 5/5; 95/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6\n",
      "[CV 5/5; 95/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=0.6; total time=   0.6s\n",
      "[CV 1/5; 96/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 1/5; 96/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.4s\n",
      "[CV 2/5; 96/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 2/5; 96/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.6s\n",
      "[CV 3/5; 96/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 3/5; 96/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.5s\n",
      "[CV 4/5; 96/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 4/5; 96/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.6s\n",
      "[CV 5/5; 96/96] START colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0\n",
      "[CV 5/5; 96/96] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time=   0.6s\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.6, gamma=1.5, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=5, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1.0,\n",
      "              tree_method='exact', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "parameters = {\n",
    "        'min_child_weight': [1, 5],\n",
    "        'gamma': [0.5, 1, 1.5],\n",
    "        'subsample': [0.6, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8],\n",
    "        'max_depth': [2, 3,4, 5]\n",
    "        }\n",
    "\n",
    "# Create the model\n",
    "xgboost_model = XGBClassifier(use_label_encoder=False)\n",
    "\n",
    "# Best model\n",
    "opt_model_xgb = GridSearchCV(xgboost_model, parameters,  scoring='accuracy', verbose=10)\n",
    "\n",
    "# Fit the model\n",
    "opt_model_xgb.fit(train_m5, train_m5_target)\n",
    "\n",
    "print (opt_model_xgb.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.6, gamma=1.5, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=5, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1.0,\n",
       "              tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model with best parameters\n",
    "xgboost_model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.6, gamma=1.5, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=0.300000012, max_delta_step=0, max_depth=3,\n",
    "              min_child_weight=5,\n",
    "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1.0,\n",
    "              tree_method='exact', use_label_encoder=False,\n",
    "              validate_parameters=1, verbosity=None)\n",
    "\n",
    "# Fit the best model\n",
    "xgboost_model.fit(train_m5, train_m5_target)\n",
    "xgboost_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted     0    1   All\n",
      "Actual                    \n",
      "0.0        7621  354  7975\n",
      "1.0         538  635  1173\n",
      "All        8159  989  9148\n"
     ]
    }
   ],
   "source": [
    "predictions = xgboost_model.predict(test_m5)\n",
    "\n",
    "# Confusion matrix\n",
    "confusion = pd.crosstab(test_m5_target,predictions, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(confusion )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.902492\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "score = accuracy_score(test_m5_target,predictions)\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.96      0.94      7975\n",
      "         1.0       0.64      0.54      0.59      1173\n",
      "\n",
      "    accuracy                           0.90      9148\n",
      "   macro avg       0.79      0.75      0.77      9148\n",
      "weighted avg       0.90      0.90      0.90      9148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report\n",
    "print(classification_report(test_m5_target,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9164439978417278"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate model using best model and cross validation\n",
    "pecc_xgb = cross_val_score(xgboost_model, train_m5, train_m5_target, cv = 5).mean()\n",
    "pecc_xgb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
