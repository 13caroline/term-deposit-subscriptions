{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing as sk_pp\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education default housing loan    contact month  \\\n",
       "0   56  housemaid  married     basic.4y      no      no   no  telephone   may   \n",
       "1   57   services  married  high.school     NaN      no   no  telephone   may   \n",
       "2   37   services  married  high.school      no     yes   no  telephone   may   \n",
       "3   40     admin.  married     basic.6y      no      no   no  telephone   may   \n",
       "4   56   services  married  high.school      no      no  yes  telephone   may   \n",
       "\n",
       "  day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../../../Data_AA2/bank-additional-full.csv', sep = ';',na_values=\"unknown\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30488 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             30488 non-null  int64  \n",
      " 1   job             30488 non-null  object \n",
      " 2   marital         30488 non-null  object \n",
      " 3   education       30488 non-null  object \n",
      " 4   default         30488 non-null  object \n",
      " 5   housing         30488 non-null  object \n",
      " 6   loan            30488 non-null  object \n",
      " 7   contact         30488 non-null  object \n",
      " 8   month           30488 non-null  object \n",
      " 9   day_of_week     30488 non-null  object \n",
      " 10  duration        30488 non-null  int64  \n",
      " 11  campaign        30488 non-null  int64  \n",
      " 12  pdays           30488 non-null  int64  \n",
      " 13  previous        30488 non-null  int64  \n",
      " 14  poutcome        30488 non-null  object \n",
      " 15  emp.var.rate    30488 non-null  float64\n",
      " 16  cons.price.idx  30488 non-null  float64\n",
      " 17  cons.conf.idx   30488 non-null  float64\n",
      " 18  euribor3m       30488 non-null  float64\n",
      " 19  nr.employed     30488 non-null  float64\n",
      " 20  y               30488 non-null  object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 5.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital            education default housing loan  \\\n",
       "0   56  housemaid  married             basic.4y      no      no   no   \n",
       "2   37   services  married          high.school      no     yes   no   \n",
       "3   40     admin.  married             basic.6y      no      no   no   \n",
       "4   56   services  married          high.school      no      no  yes   \n",
       "6   59     admin.  married  professional.course      no      no   no   \n",
       "\n",
       "     contact month day_of_week  ...  campaign  pdays  previous     poutcome  \\\n",
       "0  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "2  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "3  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "4  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "6  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "\n",
       "  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "3          1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "4          1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "6          1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def duration(df):\n",
    "\n",
    "    df.loc[df['duration'] <= 102, 'duration'] = 1\n",
    "    df.loc[(df['duration'] > 102) & (df['duration'] <= 180)  , 'duration'] = 2\n",
    "    df.loc[(df['duration'] > 180) & (df['duration'] <= 319)  , 'duration'] = 3\n",
    "    df.loc[(df['duration'] > 319) & (df['duration'] <= 644.5), 'duration'] = 4\n",
    "    df.loc[df['duration']  > 644.5, 'duration'] = 5\n",
    "\n",
    "    return df\n",
    "\n",
    "duration(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital            education default housing loan  \\\n",
       "0    3  housemaid  married             basic.4y      no      no   no   \n",
       "2    3   services  married          high.school      no     yes   no   \n",
       "3    3     admin.  married             basic.6y      no      no   no   \n",
       "4    3   services  married          high.school      no      no  yes   \n",
       "6    3     admin.  married  professional.course      no      no   no   \n",
       "\n",
       "     contact month day_of_week  ...  campaign  pdays  previous     poutcome  \\\n",
       "0  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "2  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "3  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "4  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "6  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "\n",
       "  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "3          1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "4          1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "6          1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def age(df):\n",
    "    df.loc[df['age'] <= 19, 'age'] = 1\n",
    "    df.loc[(df['age'] > 19) & (df['age'] <= 30), 'age'] = 2\n",
    "    df.loc[(df['age'] > 30) & (df['age'] <= 60), 'age'] = 3\n",
    "    df.loc[(df['age'] > 60) & (df['age'] <= 98), 'age'] = 4\n",
    "           \n",
    "    return df\n",
    "\n",
    "age(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  job  marital  education  default  housing  loan  contact  month  \\\n",
       "0     3    3        1          0        0        0     0        1      6   \n",
       "2     3    7        1          3        0        1     0        1      6   \n",
       "3     3    0        1          1        0        0     0        1      6   \n",
       "4     3    7        1          3        0        0     1        1      6   \n",
       "6     3    0        1          5        0        0     0        1      6   \n",
       "8     2    9        2          5        0        1     0        1      6   \n",
       "9     2    7        2          3        0        1     0        1      6   \n",
       "11    2    7        2          3        0        1     0        1      6   \n",
       "12    2    1        2          3        0        0     1        1      6   \n",
       "13    3    3        0          0        0        1     0        1      6   \n",
       "\n",
       "    day_of_week  ...  campaign  pdays  previous  poutcome  emp.var.rate  \\\n",
       "0             1  ...         1    999         0         1           1.1   \n",
       "2             1  ...         1    999         0         1           1.1   \n",
       "3             1  ...         1    999         0         1           1.1   \n",
       "4             1  ...         1    999         0         1           1.1   \n",
       "6             1  ...         1    999         0         1           1.1   \n",
       "8             1  ...         1    999         0         1           1.1   \n",
       "9             1  ...         1    999         0         1           1.1   \n",
       "11            1  ...         1    999         0         1           1.1   \n",
       "12            1  ...         1    999         0         1           1.1   \n",
       "13            1  ...         1    999         0         1           1.1   \n",
       "\n",
       "    cons.price.idx  cons.conf.idx  euribor3m  nr.employed  y  \n",
       "0           93.994          -36.4      4.857       5191.0  0  \n",
       "2           93.994          -36.4      4.857       5191.0  0  \n",
       "3           93.994          -36.4      4.857       5191.0  0  \n",
       "4           93.994          -36.4      4.857       5191.0  0  \n",
       "6           93.994          -36.4      4.857       5191.0  0  \n",
       "8           93.994          -36.4      4.857       5191.0  0  \n",
       "9           93.994          -36.4      4.857       5191.0  0  \n",
       "11          93.994          -36.4      4.857       5191.0  0  \n",
       "12          93.994          -36.4      4.857       5191.0  0  \n",
       "13          93.994          -36.4      4.857       5191.0  0  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label encoder order is alphabetical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "data['job'] = le.fit_transform(data['job']) \n",
    "data['marital'] = le.fit_transform(data['marital']) \n",
    "data['education'] = le.fit_transform(data['education']) \n",
    "data['default'] = le.fit_transform(data['default']) \n",
    "data['housing'] = le.fit_transform(data['housing']) \n",
    "data['loan'] = le.fit_transform(data['loan'])\n",
    "data['contact'] = le.fit_transform(data['contact']) \n",
    "data['month'] = le.fit_transform(data['month']) \n",
    "data['day_of_week'] = le.fit_transform(data['day_of_week'])\n",
    "data['poutcome'] = le.fit_transform(data['poutcome'])\n",
    "\n",
    "data['y'].replace(['no', 'yes'], [0,1], inplace  = True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_Y = data['y']\n",
    "data = data.drop(columns=['y']) \n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( data, data_Y, test_size=0.30)\n",
    "\n",
    "#Y_train = np.asarray(Y_train).astype('float32').reshape((-1,1))\n",
    "#Y_test = np.asarray(Y_test).astype('float32').reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.404098</td>\n",
       "      <td>-0.755894</td>\n",
       "      <td>-0.307668</td>\n",
       "      <td>-1.423818</td>\n",
       "      <td>-0.011857</td>\n",
       "      <td>0.918973</td>\n",
       "      <td>-0.430673</td>\n",
       "      <td>1.425874</td>\n",
       "      <td>-0.107763</td>\n",
       "      <td>-0.729772</td>\n",
       "      <td>-0.468537</td>\n",
       "      <td>2.007734</td>\n",
       "      <td>0.215368</td>\n",
       "      <td>-0.371585</td>\n",
       "      <td>0.189030</td>\n",
       "      <td>0.919365</td>\n",
       "      <td>1.610546</td>\n",
       "      <td>-0.248301</td>\n",
       "      <td>0.796564</td>\n",
       "      <td>0.899582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.404098</td>\n",
       "      <td>-0.755894</td>\n",
       "      <td>-0.307668</td>\n",
       "      <td>-1.925969</td>\n",
       "      <td>-0.011857</td>\n",
       "      <td>0.918973</td>\n",
       "      <td>-0.430673</td>\n",
       "      <td>1.425874</td>\n",
       "      <td>-0.526896</td>\n",
       "      <td>1.419461</td>\n",
       "      <td>-1.275498</td>\n",
       "      <td>-0.558111</td>\n",
       "      <td>0.215368</td>\n",
       "      <td>-0.371585</td>\n",
       "      <td>0.189030</td>\n",
       "      <td>0.919365</td>\n",
       "      <td>0.677547</td>\n",
       "      <td>-0.435917</td>\n",
       "      <td>0.851047</td>\n",
       "      <td>0.899582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.652238</td>\n",
       "      <td>0.351091</td>\n",
       "      <td>-0.307668</td>\n",
       "      <td>-0.419515</td>\n",
       "      <td>-0.011857</td>\n",
       "      <td>0.918973</td>\n",
       "      <td>-0.430673</td>\n",
       "      <td>-0.701324</td>\n",
       "      <td>-1.784292</td>\n",
       "      <td>1.419461</td>\n",
       "      <td>-0.468537</td>\n",
       "      <td>-0.191562</td>\n",
       "      <td>0.215368</td>\n",
       "      <td>-0.371585</td>\n",
       "      <td>0.189030</td>\n",
       "      <td>-1.064155</td>\n",
       "      <td>-0.760328</td>\n",
       "      <td>-1.353149</td>\n",
       "      <td>-1.141252</td>\n",
       "      <td>-0.811872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.844041</td>\n",
       "      <td>-1.032641</td>\n",
       "      <td>1.300054</td>\n",
       "      <td>-0.419515</td>\n",
       "      <td>-0.011857</td>\n",
       "      <td>0.918973</td>\n",
       "      <td>-0.430673</td>\n",
       "      <td>1.425874</td>\n",
       "      <td>-0.526896</td>\n",
       "      <td>0.703050</td>\n",
       "      <td>0.338424</td>\n",
       "      <td>6.772876</td>\n",
       "      <td>0.215368</td>\n",
       "      <td>-0.371585</td>\n",
       "      <td>0.189030</td>\n",
       "      <td>0.919365</td>\n",
       "      <td>0.677547</td>\n",
       "      <td>-0.435917</td>\n",
       "      <td>0.850485</td>\n",
       "      <td>0.899582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.404098</td>\n",
       "      <td>-1.032641</td>\n",
       "      <td>-0.307668</td>\n",
       "      <td>-0.419515</td>\n",
       "      <td>-0.011857</td>\n",
       "      <td>0.918973</td>\n",
       "      <td>-0.430673</td>\n",
       "      <td>-0.701324</td>\n",
       "      <td>1.149633</td>\n",
       "      <td>1.419461</td>\n",
       "      <td>-0.468537</td>\n",
       "      <td>-0.558111</td>\n",
       "      <td>0.215368</td>\n",
       "      <td>-0.371585</td>\n",
       "      <td>0.189030</td>\n",
       "      <td>-0.010410</td>\n",
       "      <td>-0.547120</td>\n",
       "      <td>-0.289993</td>\n",
       "      <td>0.378108</td>\n",
       "      <td>0.471055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.404098</td>\n",
       "      <td>-1.032641</td>\n",
       "      <td>-0.307668</td>\n",
       "      <td>1.086940</td>\n",
       "      <td>-0.011857</td>\n",
       "      <td>-1.088171</td>\n",
       "      <td>-0.430673</td>\n",
       "      <td>-0.701324</td>\n",
       "      <td>-1.784292</td>\n",
       "      <td>-1.446182</td>\n",
       "      <td>0.338424</td>\n",
       "      <td>0.174987</td>\n",
       "      <td>0.215368</td>\n",
       "      <td>-0.371585</td>\n",
       "      <td>0.189030</td>\n",
       "      <td>-1.064155</td>\n",
       "      <td>-0.760328</td>\n",
       "      <td>-1.353149</td>\n",
       "      <td>-1.146869</td>\n",
       "      <td>-0.811872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.404098</td>\n",
       "      <td>-1.032641</td>\n",
       "      <td>-0.307668</td>\n",
       "      <td>1.086940</td>\n",
       "      <td>-0.011857</td>\n",
       "      <td>-1.088171</td>\n",
       "      <td>-0.430673</td>\n",
       "      <td>1.425874</td>\n",
       "      <td>-0.526896</td>\n",
       "      <td>-0.729772</td>\n",
       "      <td>0.338424</td>\n",
       "      <td>-0.191562</td>\n",
       "      <td>0.215368</td>\n",
       "      <td>-0.371585</td>\n",
       "      <td>0.189030</td>\n",
       "      <td>0.919365</td>\n",
       "      <td>0.677547</td>\n",
       "      <td>-0.435917</td>\n",
       "      <td>0.849924</td>\n",
       "      <td>0.899582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.404098</td>\n",
       "      <td>-0.755894</td>\n",
       "      <td>-0.307668</td>\n",
       "      <td>-1.925969</td>\n",
       "      <td>-0.011857</td>\n",
       "      <td>-1.088171</td>\n",
       "      <td>-0.430673</td>\n",
       "      <td>-0.701324</td>\n",
       "      <td>-1.365160</td>\n",
       "      <td>1.419461</td>\n",
       "      <td>-0.468537</td>\n",
       "      <td>-0.191562</td>\n",
       "      <td>0.215368</td>\n",
       "      <td>-0.371585</td>\n",
       "      <td>0.189030</td>\n",
       "      <td>0.919365</td>\n",
       "      <td>-0.130938</td>\n",
       "      <td>0.939931</td>\n",
       "      <td>0.853856</td>\n",
       "      <td>0.899582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.404098</td>\n",
       "      <td>0.904583</td>\n",
       "      <td>1.300054</td>\n",
       "      <td>-0.419515</td>\n",
       "      <td>-0.011857</td>\n",
       "      <td>0.918973</td>\n",
       "      <td>-0.430673</td>\n",
       "      <td>1.425874</td>\n",
       "      <td>0.730501</td>\n",
       "      <td>-0.013361</td>\n",
       "      <td>1.952345</td>\n",
       "      <td>-0.558111</td>\n",
       "      <td>0.215368</td>\n",
       "      <td>-0.371585</td>\n",
       "      <td>0.189030</td>\n",
       "      <td>0.733410</td>\n",
       "      <td>0.807178</td>\n",
       "      <td>0.877392</td>\n",
       "      <td>0.790947</td>\n",
       "      <td>0.407373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.404098</td>\n",
       "      <td>-0.479148</td>\n",
       "      <td>1.300054</td>\n",
       "      <td>1.086940</td>\n",
       "      <td>-0.011857</td>\n",
       "      <td>0.918973</td>\n",
       "      <td>-0.430673</td>\n",
       "      <td>-0.701324</td>\n",
       "      <td>0.730501</td>\n",
       "      <td>1.419461</td>\n",
       "      <td>0.338424</td>\n",
       "      <td>0.174987</td>\n",
       "      <td>0.215368</td>\n",
       "      <td>1.514711</td>\n",
       "      <td>-2.406908</td>\n",
       "      <td>-1.064155</td>\n",
       "      <td>-1.070759</td>\n",
       "      <td>-1.165533</td>\n",
       "      <td>-1.216518</td>\n",
       "      <td>-0.811872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       job   marital  education   default   housing      loan  \\\n",
       "0  0.404098 -0.755894 -0.307668  -1.423818 -0.011857  0.918973 -0.430673   \n",
       "1  0.404098 -0.755894 -0.307668  -1.925969 -0.011857  0.918973 -0.430673   \n",
       "2  2.652238  0.351091 -0.307668  -0.419515 -0.011857  0.918973 -0.430673   \n",
       "3 -1.844041 -1.032641  1.300054  -0.419515 -0.011857  0.918973 -0.430673   \n",
       "4  0.404098 -1.032641 -0.307668  -0.419515 -0.011857  0.918973 -0.430673   \n",
       "5  0.404098 -1.032641 -0.307668   1.086940 -0.011857 -1.088171 -0.430673   \n",
       "6  0.404098 -1.032641 -0.307668   1.086940 -0.011857 -1.088171 -0.430673   \n",
       "7  0.404098 -0.755894 -0.307668  -1.925969 -0.011857 -1.088171 -0.430673   \n",
       "8  0.404098  0.904583  1.300054  -0.419515 -0.011857  0.918973 -0.430673   \n",
       "9  0.404098 -0.479148  1.300054   1.086940 -0.011857  0.918973 -0.430673   \n",
       "\n",
       "    contact     month  day_of_week  duration  campaign     pdays  previous  \\\n",
       "0  1.425874 -0.107763    -0.729772 -0.468537  2.007734  0.215368 -0.371585   \n",
       "1  1.425874 -0.526896     1.419461 -1.275498 -0.558111  0.215368 -0.371585   \n",
       "2 -0.701324 -1.784292     1.419461 -0.468537 -0.191562  0.215368 -0.371585   \n",
       "3  1.425874 -0.526896     0.703050  0.338424  6.772876  0.215368 -0.371585   \n",
       "4 -0.701324  1.149633     1.419461 -0.468537 -0.558111  0.215368 -0.371585   \n",
       "5 -0.701324 -1.784292    -1.446182  0.338424  0.174987  0.215368 -0.371585   \n",
       "6  1.425874 -0.526896    -0.729772  0.338424 -0.191562  0.215368 -0.371585   \n",
       "7 -0.701324 -1.365160     1.419461 -0.468537 -0.191562  0.215368 -0.371585   \n",
       "8  1.425874  0.730501    -0.013361  1.952345 -0.558111  0.215368 -0.371585   \n",
       "9 -0.701324  0.730501     1.419461  0.338424  0.174987  0.215368  1.514711   \n",
       "\n",
       "   poutcome  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
       "0  0.189030      0.919365        1.610546      -0.248301   0.796564   \n",
       "1  0.189030      0.919365        0.677547      -0.435917   0.851047   \n",
       "2  0.189030     -1.064155       -0.760328      -1.353149  -1.141252   \n",
       "3  0.189030      0.919365        0.677547      -0.435917   0.850485   \n",
       "4  0.189030     -0.010410       -0.547120      -0.289993   0.378108   \n",
       "5  0.189030     -1.064155       -0.760328      -1.353149  -1.146869   \n",
       "6  0.189030      0.919365        0.677547      -0.435917   0.849924   \n",
       "7  0.189030      0.919365       -0.130938       0.939931   0.853856   \n",
       "8  0.189030      0.733410        0.807178       0.877392   0.790947   \n",
       "9 -2.406908     -1.064155       -1.070759      -1.165533  -1.216518   \n",
       "\n",
       "   nr.employed  \n",
       "0     0.899582  \n",
       "1     0.899582  \n",
       "2    -0.811872  \n",
       "3     0.899582  \n",
       "4     0.471055  \n",
       "5    -0.811872  \n",
       "6     0.899582  \n",
       "7     0.899582  \n",
       "8     0.407373  \n",
       "9    -0.811872  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "\n",
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21341 entries, 0 to 21340\n",
      "Data columns (total 20 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             21341 non-null  float64\n",
      " 1   job             21341 non-null  float64\n",
      " 2   marital         21341 non-null  float64\n",
      " 3   education       21341 non-null  float64\n",
      " 4   default         21341 non-null  float64\n",
      " 5   housing         21341 non-null  float64\n",
      " 6   loan            21341 non-null  float64\n",
      " 7   contact         21341 non-null  float64\n",
      " 8   month           21341 non-null  float64\n",
      " 9   day_of_week     21341 non-null  float64\n",
      " 10  duration        21341 non-null  float64\n",
      " 11  campaign        21341 non-null  float64\n",
      " 12  pdays           21341 non-null  float64\n",
      " 13  previous        21341 non-null  float64\n",
      " 14  poutcome        21341 non-null  float64\n",
      " 15  emp.var.rate    21341 non-null  float64\n",
      " 16  cons.price.idx  21341 non-null  float64\n",
      " 17  cons.conf.idx   21341 non-null  float64\n",
      " 18  euribor3m       21341 non-null  float64\n",
      " 19  nr.employed     21341 non-null  float64\n",
      "dtypes: float64(20)\n",
      "memory usage: 3.3 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18597\n",
       "1     2744\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "strategy = {1:5000}\n",
    "sm = SMOTE(random_state = 2,sampling_strategy=strategy)\n",
    "\n",
    "X_train, Y_train = sm.fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "# define the undersampling method\n",
    "undersample = NearMiss(version=1, n_neighbors=3)\n",
    "# transform the dataset\n",
    "X_train, Y_train = undersample.fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5000\n",
       "0    5000\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1, 20)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.values.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test = X_test.values.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.asarray(Y_train).astype('float32').reshape((-1,1))\n",
    "Y_test = np.asarray(Y_test).astype('float32').reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, partial_X_train, Y_val, partial_Y_train = train_test_split( X_train, Y_train, test_size=0.50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN modelo 5\n",
    "Defining the model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32,input_shape=(partial_X_train.shape[1], partial_X_train.shape[2]), activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model and plotting errors along the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 [==============================] - 2s 140ms/step - loss: 0.6590 - acc: 0.5607 - val_loss: 0.5895 - val_acc: 0.6918\n",
      "Epoch 2/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5790 - acc: 0.6912 - val_loss: 0.5606 - val_acc: 0.7208\n",
      "Epoch 3/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5473 - acc: 0.7115 - val_loss: 0.5393 - val_acc: 0.7284\n",
      "Epoch 4/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5378 - acc: 0.7308 - val_loss: 0.5211 - val_acc: 0.7372\n",
      "Epoch 5/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5221 - acc: 0.7429 - val_loss: 0.5096 - val_acc: 0.7392\n",
      "Epoch 6/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5082 - acc: 0.7455 - val_loss: 0.4958 - val_acc: 0.7508\n",
      "Epoch 7/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5027 - acc: 0.7422 - val_loss: 0.4866 - val_acc: 0.7598\n",
      "Epoch 8/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5007 - acc: 0.7590 - val_loss: 0.4779 - val_acc: 0.7582\n",
      "Epoch 9/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4956 - acc: 0.7609 - val_loss: 0.4733 - val_acc: 0.7570\n",
      "Epoch 10/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4845 - acc: 0.7614 - val_loss: 0.4648 - val_acc: 0.7674\n",
      "Epoch 11/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4902 - acc: 0.7633 - val_loss: 0.4608 - val_acc: 0.7692\n",
      "Epoch 12/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4773 - acc: 0.7663 - val_loss: 0.4564 - val_acc: 0.7728\n",
      "Epoch 13/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4637 - acc: 0.7773 - val_loss: 0.4507 - val_acc: 0.7844\n",
      "Epoch 14/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4590 - acc: 0.7847 - val_loss: 0.4522 - val_acc: 0.7752\n",
      "Epoch 15/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4661 - acc: 0.7690 - val_loss: 0.4459 - val_acc: 0.7810\n",
      "Epoch 16/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4503 - acc: 0.7854 - val_loss: 0.4423 - val_acc: 0.7962\n",
      "Epoch 17/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4571 - acc: 0.7803 - val_loss: 0.4499 - val_acc: 0.7776\n",
      "Epoch 18/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4447 - acc: 0.7847 - val_loss: 0.4382 - val_acc: 0.7978\n",
      "Epoch 19/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4538 - acc: 0.7837 - val_loss: 0.4402 - val_acc: 0.7868\n",
      "Epoch 20/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4544 - acc: 0.7894 - val_loss: 0.4369 - val_acc: 0.7908\n",
      "Epoch 21/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4594 - acc: 0.7788 - val_loss: 0.4334 - val_acc: 0.7950\n",
      "Epoch 22/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4349 - acc: 0.7944 - val_loss: 0.4318 - val_acc: 0.8000\n",
      "Epoch 23/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4495 - acc: 0.7860 - val_loss: 0.4308 - val_acc: 0.8004\n",
      "Epoch 24/200\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.4463 - acc: 0.7912 - val_loss: 0.4307 - val_acc: 0.8024\n",
      "Epoch 25/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4368 - acc: 0.7935 - val_loss: 0.4283 - val_acc: 0.8034\n",
      "Epoch 26/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4267 - acc: 0.8022 - val_loss: 0.4261 - val_acc: 0.8050\n",
      "Epoch 27/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4414 - acc: 0.7950 - val_loss: 0.4278 - val_acc: 0.8010\n",
      "Epoch 28/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4400 - acc: 0.7902 - val_loss: 0.4238 - val_acc: 0.8050\n",
      "Epoch 29/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4341 - acc: 0.7956 - val_loss: 0.4267 - val_acc: 0.8016\n",
      "Epoch 30/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4261 - acc: 0.8014 - val_loss: 0.4262 - val_acc: 0.8016\n",
      "Epoch 31/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4378 - acc: 0.7912 - val_loss: 0.4233 - val_acc: 0.8060\n",
      "Epoch 32/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4268 - acc: 0.7984 - val_loss: 0.4268 - val_acc: 0.8024\n",
      "Epoch 33/200\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.4287 - acc: 0.8015 - val_loss: 0.4202 - val_acc: 0.8094\n",
      "Epoch 34/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4202 - acc: 0.8066 - val_loss: 0.4179 - val_acc: 0.8104\n",
      "Epoch 35/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4195 - acc: 0.8046 - val_loss: 0.4193 - val_acc: 0.8058\n",
      "Epoch 36/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4187 - acc: 0.7999 - val_loss: 0.4249 - val_acc: 0.8010\n",
      "Epoch 37/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4194 - acc: 0.8040 - val_loss: 0.4240 - val_acc: 0.8018\n",
      "Epoch 38/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4176 - acc: 0.8057 - val_loss: 0.4154 - val_acc: 0.8100\n",
      "Epoch 39/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4076 - acc: 0.8159 - val_loss: 0.4188 - val_acc: 0.8062\n",
      "Epoch 40/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4212 - acc: 0.8098 - val_loss: 0.4140 - val_acc: 0.8094\n",
      "Epoch 41/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4217 - acc: 0.7989 - val_loss: 0.4125 - val_acc: 0.8122\n",
      "Epoch 42/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4172 - acc: 0.8012 - val_loss: 0.4117 - val_acc: 0.8136\n",
      "Epoch 43/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4115 - acc: 0.8115 - val_loss: 0.4159 - val_acc: 0.8102\n",
      "Epoch 44/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4186 - acc: 0.8072 - val_loss: 0.4248 - val_acc: 0.7968\n",
      "Epoch 45/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4175 - acc: 0.8051 - val_loss: 0.4108 - val_acc: 0.8134\n",
      "Epoch 46/200\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.4177 - acc: 0.8076 - val_loss: 0.4128 - val_acc: 0.8110\n",
      "Epoch 47/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4061 - acc: 0.8155 - val_loss: 0.4108 - val_acc: 0.8142\n",
      "Epoch 48/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4130 - acc: 0.8025 - val_loss: 0.4118 - val_acc: 0.8126\n",
      "Epoch 49/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4188 - acc: 0.8012 - val_loss: 0.4109 - val_acc: 0.8136\n",
      "Epoch 50/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4051 - acc: 0.8097 - val_loss: 0.4064 - val_acc: 0.8160\n",
      "Epoch 51/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4108 - acc: 0.7978 - val_loss: 0.4120 - val_acc: 0.8120\n",
      "Epoch 52/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4169 - acc: 0.8061 - val_loss: 0.4066 - val_acc: 0.8158\n",
      "Epoch 53/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4035 - acc: 0.8139 - val_loss: 0.4086 - val_acc: 0.8170\n",
      "Epoch 54/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4102 - acc: 0.8142 - val_loss: 0.4087 - val_acc: 0.8150\n",
      "Epoch 55/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4061 - acc: 0.8125 - val_loss: 0.4060 - val_acc: 0.8150\n",
      "Epoch 56/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3961 - acc: 0.8201 - val_loss: 0.4073 - val_acc: 0.8146\n",
      "Epoch 57/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4081 - acc: 0.8110 - val_loss: 0.4073 - val_acc: 0.8124\n",
      "Epoch 58/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4089 - acc: 0.8102 - val_loss: 0.4080 - val_acc: 0.8140\n",
      "Epoch 59/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4073 - acc: 0.8110 - val_loss: 0.4123 - val_acc: 0.8090\n",
      "Epoch 60/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3908 - acc: 0.8181 - val_loss: 0.4162 - val_acc: 0.8042\n",
      "Epoch 61/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4016 - acc: 0.8169 - val_loss: 0.4040 - val_acc: 0.8168\n",
      "Epoch 62/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3885 - acc: 0.8235 - val_loss: 0.4089 - val_acc: 0.8136\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3891 - acc: 0.8211 - val_loss: 0.4090 - val_acc: 0.8132\n",
      "Epoch 64/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3957 - acc: 0.8147 - val_loss: 0.4047 - val_acc: 0.8148\n",
      "Epoch 65/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4022 - acc: 0.8205 - val_loss: 0.4076 - val_acc: 0.8112\n",
      "Epoch 66/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3875 - acc: 0.8217 - val_loss: 0.4096 - val_acc: 0.8110\n",
      "Epoch 67/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4001 - acc: 0.8150 - val_loss: 0.4138 - val_acc: 0.8060\n",
      "Epoch 68/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3862 - acc: 0.8222 - val_loss: 0.4012 - val_acc: 0.8188\n",
      "Epoch 69/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3911 - acc: 0.8113 - val_loss: 0.4048 - val_acc: 0.8142\n",
      "Epoch 70/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3924 - acc: 0.8176 - val_loss: 0.4079 - val_acc: 0.8130\n",
      "Epoch 71/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3882 - acc: 0.8234 - val_loss: 0.4056 - val_acc: 0.8138\n",
      "Epoch 72/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3916 - acc: 0.8205 - val_loss: 0.4110 - val_acc: 0.8094\n",
      "Epoch 73/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3952 - acc: 0.8168 - val_loss: 0.4107 - val_acc: 0.8114\n",
      "Epoch 74/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3936 - acc: 0.8226 - val_loss: 0.4053 - val_acc: 0.8138\n",
      "Epoch 75/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3887 - acc: 0.8137 - val_loss: 0.4108 - val_acc: 0.8116\n",
      "Epoch 76/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3916 - acc: 0.8170 - val_loss: 0.4043 - val_acc: 0.8148\n",
      "Epoch 77/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3785 - acc: 0.8287 - val_loss: 0.4210 - val_acc: 0.8012\n",
      "Epoch 78/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4009 - acc: 0.8140 - val_loss: 0.4075 - val_acc: 0.8138\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=10)\n",
    "mc = ModelCheckpoint('best_model_1.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "history = model.fit(partial_X_train,\n",
    "                    partial_Y_train,\n",
    "                    epochs=200,\n",
    "                    batch_size=512,\n",
    "                    callbacks = [es,mc],\n",
    "                    validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 0.44546860456466675\n",
      "Test accuracy 0.8071498870849609\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('best_model_1.h5')\n",
    "score = model.evaluate(X_test, Y_test, verbose = 0)\n",
    "\n",
    "print('Test Loss', score[0])\n",
    "print('Test accuracy', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "acc_values = history_dict['acc'] \n",
    "val_acc_values = history_dict['val_acc']\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN modelo 6\n",
    "Defining the model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "model2 = models.Sequential()\n",
    "model2.add(layers.Dense(32,input_shape=(partial_X_train.shape[1], partial_X_train.shape[2]), activation='relu'))\n",
    "model2.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model and plotting errors along the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 [==============================] - 1s 37ms/step - loss: 0.7043 - acc: 0.5472 - val_loss: 0.6530 - val_acc: 0.6138\n",
      "Epoch 2/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6364 - acc: 0.6345 - val_loss: 0.6141 - val_acc: 0.6574\n",
      "Epoch 3/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5944 - acc: 0.6777 - val_loss: 0.5875 - val_acc: 0.6866\n",
      "Epoch 4/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5760 - acc: 0.6888 - val_loss: 0.5665 - val_acc: 0.7032\n",
      "Epoch 5/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5514 - acc: 0.7164 - val_loss: 0.5500 - val_acc: 0.7202\n",
      "Epoch 6/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5341 - acc: 0.7323 - val_loss: 0.5363 - val_acc: 0.7328\n",
      "Epoch 7/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5218 - acc: 0.7382 - val_loss: 0.5250 - val_acc: 0.7394\n",
      "Epoch 8/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4982 - acc: 0.7562 - val_loss: 0.5154 - val_acc: 0.7442\n",
      "Epoch 9/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4985 - acc: 0.7572 - val_loss: 0.5074 - val_acc: 0.7500\n",
      "Epoch 10/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4891 - acc: 0.7620 - val_loss: 0.5001 - val_acc: 0.7550\n",
      "Epoch 11/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4875 - acc: 0.7683 - val_loss: 0.4937 - val_acc: 0.7548\n",
      "Epoch 12/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4815 - acc: 0.7680 - val_loss: 0.4877 - val_acc: 0.7596\n",
      "Epoch 13/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4821 - acc: 0.7593 - val_loss: 0.4825 - val_acc: 0.7628\n",
      "Epoch 14/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4683 - acc: 0.7728 - val_loss: 0.4776 - val_acc: 0.7662\n",
      "Epoch 15/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4612 - acc: 0.7763 - val_loss: 0.4733 - val_acc: 0.7688\n",
      "Epoch 16/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4571 - acc: 0.7783 - val_loss: 0.4693 - val_acc: 0.7720\n",
      "Epoch 17/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4584 - acc: 0.7739 - val_loss: 0.4656 - val_acc: 0.7714\n",
      "Epoch 18/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4561 - acc: 0.7767 - val_loss: 0.4623 - val_acc: 0.7732\n",
      "Epoch 19/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4412 - acc: 0.7851 - val_loss: 0.4586 - val_acc: 0.7740\n",
      "Epoch 20/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4546 - acc: 0.7825 - val_loss: 0.4557 - val_acc: 0.7748\n",
      "Epoch 21/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4388 - acc: 0.7888 - val_loss: 0.4532 - val_acc: 0.7770\n",
      "Epoch 22/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4444 - acc: 0.7820 - val_loss: 0.4503 - val_acc: 0.7814\n",
      "Epoch 23/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4303 - acc: 0.7962 - val_loss: 0.4477 - val_acc: 0.7852\n",
      "Epoch 24/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4379 - acc: 0.7918 - val_loss: 0.4456 - val_acc: 0.7852\n",
      "Epoch 25/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4345 - acc: 0.7916 - val_loss: 0.4439 - val_acc: 0.7868\n",
      "Epoch 26/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4354 - acc: 0.7878 - val_loss: 0.4423 - val_acc: 0.7890\n",
      "Epoch 27/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4374 - acc: 0.7957 - val_loss: 0.4408 - val_acc: 0.7920\n",
      "Epoch 28/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4349 - acc: 0.7918 - val_loss: 0.4394 - val_acc: 0.7928\n",
      "Epoch 29/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4293 - acc: 0.7927 - val_loss: 0.4378 - val_acc: 0.7958\n",
      "Epoch 30/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4282 - acc: 0.7993 - val_loss: 0.4364 - val_acc: 0.7968\n",
      "Epoch 31/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4227 - acc: 0.8008 - val_loss: 0.4352 - val_acc: 0.7984\n",
      "Epoch 32/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4339 - acc: 0.7924 - val_loss: 0.4341 - val_acc: 0.7986\n",
      "Epoch 33/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4108 - acc: 0.8104 - val_loss: 0.4334 - val_acc: 0.7984\n",
      "Epoch 34/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4289 - acc: 0.7993 - val_loss: 0.4327 - val_acc: 0.7984\n",
      "Epoch 35/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4174 - acc: 0.8073 - val_loss: 0.4318 - val_acc: 0.7978\n",
      "Epoch 36/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4335 - acc: 0.7927 - val_loss: 0.4306 - val_acc: 0.8000\n",
      "Epoch 37/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4156 - acc: 0.8082 - val_loss: 0.4298 - val_acc: 0.7992\n",
      "Epoch 38/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4193 - acc: 0.7983 - val_loss: 0.4291 - val_acc: 0.7994\n",
      "Epoch 39/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4181 - acc: 0.8021 - val_loss: 0.4283 - val_acc: 0.8006\n",
      "Epoch 40/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4269 - acc: 0.7988 - val_loss: 0.4276 - val_acc: 0.8020\n",
      "Epoch 41/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4227 - acc: 0.8043 - val_loss: 0.4269 - val_acc: 0.8018\n",
      "Epoch 42/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4160 - acc: 0.8039 - val_loss: 0.4261 - val_acc: 0.8040\n",
      "Epoch 43/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4142 - acc: 0.8008 - val_loss: 0.4262 - val_acc: 0.8036\n",
      "Epoch 44/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4209 - acc: 0.8069 - val_loss: 0.4253 - val_acc: 0.8040\n",
      "Epoch 45/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4179 - acc: 0.8055 - val_loss: 0.4248 - val_acc: 0.8050\n",
      "Epoch 46/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4142 - acc: 0.8098 - val_loss: 0.4249 - val_acc: 0.8006\n",
      "Epoch 47/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4004 - acc: 0.8132 - val_loss: 0.4232 - val_acc: 0.8070\n",
      "Epoch 48/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4197 - acc: 0.8071 - val_loss: 0.4234 - val_acc: 0.8058\n",
      "Epoch 49/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4158 - acc: 0.7939 - val_loss: 0.4231 - val_acc: 0.8058\n",
      "Epoch 50/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4113 - acc: 0.8067 - val_loss: 0.4225 - val_acc: 0.8064\n",
      "Epoch 51/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4111 - acc: 0.8086 - val_loss: 0.4222 - val_acc: 0.8046\n",
      "Epoch 52/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4000 - acc: 0.8183 - val_loss: 0.4217 - val_acc: 0.8038\n",
      "Epoch 53/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4091 - acc: 0.8089 - val_loss: 0.4217 - val_acc: 0.8050\n",
      "Epoch 54/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4034 - acc: 0.8127 - val_loss: 0.4211 - val_acc: 0.8070\n",
      "Epoch 55/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4121 - acc: 0.8060 - val_loss: 0.4208 - val_acc: 0.8076\n",
      "Epoch 56/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4172 - acc: 0.8039 - val_loss: 0.4207 - val_acc: 0.8072\n",
      "Epoch 57/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4006 - acc: 0.8141 - val_loss: 0.4204 - val_acc: 0.8072\n",
      "Epoch 58/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4135 - acc: 0.8053 - val_loss: 0.4198 - val_acc: 0.8086\n",
      "Epoch 59/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4081 - acc: 0.8087 - val_loss: 0.4198 - val_acc: 0.8078\n",
      "Epoch 60/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4092 - acc: 0.8061 - val_loss: 0.4197 - val_acc: 0.8060\n",
      "Epoch 61/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3955 - acc: 0.8168 - val_loss: 0.4190 - val_acc: 0.8080\n",
      "Epoch 62/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4049 - acc: 0.8140 - val_loss: 0.4187 - val_acc: 0.8090\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4097 - acc: 0.8063 - val_loss: 0.4188 - val_acc: 0.8092\n",
      "Epoch 64/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4043 - acc: 0.8132 - val_loss: 0.4189 - val_acc: 0.8110\n",
      "Epoch 65/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3943 - acc: 0.8209 - val_loss: 0.4182 - val_acc: 0.8086\n",
      "Epoch 66/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4007 - acc: 0.8141 - val_loss: 0.4184 - val_acc: 0.8096\n",
      "Epoch 67/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4006 - acc: 0.8107 - val_loss: 0.4178 - val_acc: 0.8088\n",
      "Epoch 68/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4044 - acc: 0.8181 - val_loss: 0.4176 - val_acc: 0.8098\n",
      "Epoch 69/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4012 - acc: 0.8139 - val_loss: 0.4176 - val_acc: 0.8064\n",
      "Epoch 70/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3922 - acc: 0.8218 - val_loss: 0.4174 - val_acc: 0.8106\n",
      "Epoch 71/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4128 - acc: 0.8052 - val_loss: 0.4171 - val_acc: 0.8126\n",
      "Epoch 72/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3987 - acc: 0.8165 - val_loss: 0.4170 - val_acc: 0.8080\n",
      "Epoch 73/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4013 - acc: 0.8210 - val_loss: 0.4175 - val_acc: 0.8090\n",
      "Epoch 74/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4090 - acc: 0.8134 - val_loss: 0.4173 - val_acc: 0.8098\n",
      "Epoch 75/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3907 - acc: 0.8184 - val_loss: 0.4164 - val_acc: 0.8114\n",
      "Epoch 76/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3931 - acc: 0.8223 - val_loss: 0.4160 - val_acc: 0.8096\n",
      "Epoch 77/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4007 - acc: 0.8105 - val_loss: 0.4156 - val_acc: 0.8112\n",
      "Epoch 78/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4026 - acc: 0.8134 - val_loss: 0.4156 - val_acc: 0.8102\n",
      "Epoch 79/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3964 - acc: 0.8185 - val_loss: 0.4157 - val_acc: 0.8142\n",
      "Epoch 80/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3916 - acc: 0.8184 - val_loss: 0.4152 - val_acc: 0.8128\n",
      "Epoch 81/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3927 - acc: 0.8225 - val_loss: 0.4151 - val_acc: 0.8114\n",
      "Epoch 82/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3861 - acc: 0.8216 - val_loss: 0.4152 - val_acc: 0.8092\n",
      "Epoch 83/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4011 - acc: 0.8154 - val_loss: 0.4146 - val_acc: 0.8114\n",
      "Epoch 84/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3980 - acc: 0.8181 - val_loss: 0.4152 - val_acc: 0.8110\n",
      "Epoch 85/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4001 - acc: 0.8151 - val_loss: 0.4154 - val_acc: 0.8080\n",
      "Epoch 86/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4031 - acc: 0.8144 - val_loss: 0.4144 - val_acc: 0.8122\n",
      "Epoch 87/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3889 - acc: 0.8195 - val_loss: 0.4145 - val_acc: 0.8100\n",
      "Epoch 88/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3903 - acc: 0.8168 - val_loss: 0.4146 - val_acc: 0.8132\n",
      "Epoch 89/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3966 - acc: 0.8172 - val_loss: 0.4147 - val_acc: 0.8086\n",
      "Epoch 90/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4051 - acc: 0.8101 - val_loss: 0.4150 - val_acc: 0.8106\n",
      "Epoch 91/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3990 - acc: 0.8167 - val_loss: 0.4141 - val_acc: 0.8126\n",
      "Epoch 92/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3917 - acc: 0.8191 - val_loss: 0.4143 - val_acc: 0.8104\n",
      "Epoch 93/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3872 - acc: 0.8234 - val_loss: 0.4135 - val_acc: 0.8138\n",
      "Epoch 94/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3876 - acc: 0.8188 - val_loss: 0.4138 - val_acc: 0.8138\n",
      "Epoch 95/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3886 - acc: 0.8226 - val_loss: 0.4139 - val_acc: 0.8124\n",
      "Epoch 96/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3986 - acc: 0.8140 - val_loss: 0.4136 - val_acc: 0.8114\n",
      "Epoch 97/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3947 - acc: 0.8260 - val_loss: 0.4137 - val_acc: 0.8124\n",
      "Epoch 98/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3941 - acc: 0.8165 - val_loss: 0.4135 - val_acc: 0.8144\n",
      "Epoch 99/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3958 - acc: 0.8138 - val_loss: 0.4133 - val_acc: 0.8138\n",
      "Epoch 100/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3870 - acc: 0.8243 - val_loss: 0.4129 - val_acc: 0.8114\n",
      "Epoch 101/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3898 - acc: 0.8213 - val_loss: 0.4130 - val_acc: 0.8124\n",
      "Epoch 102/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4035 - acc: 0.8127 - val_loss: 0.4136 - val_acc: 0.8116\n",
      "Epoch 103/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3896 - acc: 0.8226 - val_loss: 0.4131 - val_acc: 0.8146\n",
      "Epoch 104/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3942 - acc: 0.8182 - val_loss: 0.4129 - val_acc: 0.8120\n",
      "Epoch 105/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3971 - acc: 0.8148 - val_loss: 0.4129 - val_acc: 0.8124\n",
      "Epoch 106/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3988 - acc: 0.8127 - val_loss: 0.4131 - val_acc: 0.8114\n",
      "Epoch 107/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3933 - acc: 0.8147 - val_loss: 0.4130 - val_acc: 0.8122\n",
      "Epoch 108/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3852 - acc: 0.8206 - val_loss: 0.4126 - val_acc: 0.8144\n",
      "Epoch 109/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3847 - acc: 0.8229 - val_loss: 0.4123 - val_acc: 0.8118\n",
      "Epoch 110/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3891 - acc: 0.8218 - val_loss: 0.4121 - val_acc: 0.8132\n",
      "Epoch 111/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3900 - acc: 0.8197 - val_loss: 0.4126 - val_acc: 0.8126\n",
      "Epoch 112/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3867 - acc: 0.8237 - val_loss: 0.4121 - val_acc: 0.8120\n",
      "Epoch 113/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3869 - acc: 0.8212 - val_loss: 0.4121 - val_acc: 0.8118\n",
      "Epoch 114/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3853 - acc: 0.8211 - val_loss: 0.4114 - val_acc: 0.8138\n",
      "Epoch 115/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3883 - acc: 0.8239 - val_loss: 0.4113 - val_acc: 0.8134\n",
      "Epoch 116/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3925 - acc: 0.8189 - val_loss: 0.4115 - val_acc: 0.8136\n",
      "Epoch 117/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3870 - acc: 0.8208 - val_loss: 0.4115 - val_acc: 0.8136\n",
      "Epoch 118/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3860 - acc: 0.8216 - val_loss: 0.4116 - val_acc: 0.8132\n",
      "Epoch 119/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3834 - acc: 0.8275 - val_loss: 0.4115 - val_acc: 0.8120\n",
      "Epoch 120/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3797 - acc: 0.8262 - val_loss: 0.4117 - val_acc: 0.8138\n",
      "Epoch 121/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3835 - acc: 0.8258 - val_loss: 0.4115 - val_acc: 0.8128\n",
      "Epoch 122/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3827 - acc: 0.8240 - val_loss: 0.4124 - val_acc: 0.8124\n",
      "Epoch 123/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3731 - acc: 0.8314 - val_loss: 0.4112 - val_acc: 0.8124\n",
      "Epoch 124/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3703 - acc: 0.8298 - val_loss: 0.4110 - val_acc: 0.8136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3824 - acc: 0.8202 - val_loss: 0.4113 - val_acc: 0.8128\n",
      "Epoch 126/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3787 - acc: 0.8269 - val_loss: 0.4112 - val_acc: 0.8140\n",
      "Epoch 127/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3912 - acc: 0.8203 - val_loss: 0.4108 - val_acc: 0.8144\n",
      "Epoch 128/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3805 - acc: 0.8231 - val_loss: 0.4116 - val_acc: 0.8138\n",
      "Epoch 129/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3813 - acc: 0.8216 - val_loss: 0.4108 - val_acc: 0.8134\n",
      "Epoch 130/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3823 - acc: 0.8255 - val_loss: 0.4107 - val_acc: 0.8128\n",
      "Epoch 131/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3771 - acc: 0.8245 - val_loss: 0.4109 - val_acc: 0.8142\n",
      "Epoch 132/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3841 - acc: 0.8256 - val_loss: 0.4107 - val_acc: 0.8138\n",
      "Epoch 133/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3851 - acc: 0.8256 - val_loss: 0.4108 - val_acc: 0.8144\n",
      "Epoch 134/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3804 - acc: 0.8249 - val_loss: 0.4112 - val_acc: 0.8146\n",
      "Epoch 135/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3888 - acc: 0.8210 - val_loss: 0.4106 - val_acc: 0.8142\n",
      "Epoch 136/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3665 - acc: 0.8328 - val_loss: 0.4103 - val_acc: 0.8138\n",
      "Epoch 137/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3785 - acc: 0.8281 - val_loss: 0.4105 - val_acc: 0.8138\n",
      "Epoch 138/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3816 - acc: 0.8204 - val_loss: 0.4106 - val_acc: 0.8128\n",
      "Epoch 139/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3909 - acc: 0.8142 - val_loss: 0.4107 - val_acc: 0.8132\n",
      "Epoch 140/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3742 - acc: 0.8223 - val_loss: 0.4099 - val_acc: 0.8136\n",
      "Epoch 141/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3819 - acc: 0.8212 - val_loss: 0.4109 - val_acc: 0.8124\n",
      "Epoch 142/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3864 - acc: 0.8137 - val_loss: 0.4103 - val_acc: 0.8142\n",
      "Epoch 143/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3854 - acc: 0.8179 - val_loss: 0.4101 - val_acc: 0.8136\n",
      "Epoch 144/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3709 - acc: 0.8274 - val_loss: 0.4104 - val_acc: 0.8126\n",
      "Epoch 145/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3823 - acc: 0.8207 - val_loss: 0.4097 - val_acc: 0.8136\n",
      "Epoch 146/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3829 - acc: 0.8157 - val_loss: 0.4101 - val_acc: 0.8112\n",
      "Epoch 147/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3776 - acc: 0.8264 - val_loss: 0.4095 - val_acc: 0.8138\n",
      "Epoch 148/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3763 - acc: 0.8267 - val_loss: 0.4099 - val_acc: 0.8130\n",
      "Epoch 149/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3879 - acc: 0.8221 - val_loss: 0.4098 - val_acc: 0.8122\n",
      "Epoch 150/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3792 - acc: 0.8245 - val_loss: 0.4096 - val_acc: 0.8138\n",
      "Epoch 151/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3748 - acc: 0.8305 - val_loss: 0.4113 - val_acc: 0.8102\n",
      "Epoch 152/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3767 - acc: 0.8274 - val_loss: 0.4099 - val_acc: 0.8134\n",
      "Epoch 153/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3751 - acc: 0.8293 - val_loss: 0.4101 - val_acc: 0.8114\n",
      "Epoch 154/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3735 - acc: 0.8258 - val_loss: 0.4095 - val_acc: 0.8134\n",
      "Epoch 155/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3712 - acc: 0.8326 - val_loss: 0.4091 - val_acc: 0.8134\n",
      "Epoch 156/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3718 - acc: 0.8273 - val_loss: 0.4090 - val_acc: 0.8148\n",
      "Epoch 157/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3902 - acc: 0.8141 - val_loss: 0.4088 - val_acc: 0.8142\n",
      "Epoch 158/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3741 - acc: 0.8263 - val_loss: 0.4100 - val_acc: 0.8114\n",
      "Epoch 159/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3778 - acc: 0.8267 - val_loss: 0.4096 - val_acc: 0.8126\n",
      "Epoch 160/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3780 - acc: 0.8234 - val_loss: 0.4091 - val_acc: 0.8120\n",
      "Epoch 161/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3790 - acc: 0.8203 - val_loss: 0.4099 - val_acc: 0.8116\n",
      "Epoch 162/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3759 - acc: 0.8271 - val_loss: 0.4089 - val_acc: 0.8134\n",
      "Epoch 163/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3749 - acc: 0.8232 - val_loss: 0.4088 - val_acc: 0.8128\n",
      "Epoch 164/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3849 - acc: 0.8176 - val_loss: 0.4089 - val_acc: 0.8138\n",
      "Epoch 165/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3762 - acc: 0.8248 - val_loss: 0.4108 - val_acc: 0.8140\n",
      "Epoch 166/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3852 - acc: 0.8212 - val_loss: 0.4093 - val_acc: 0.8118\n",
      "Epoch 167/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3748 - acc: 0.8230 - val_loss: 0.4095 - val_acc: 0.8118\n",
      "Epoch 168/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3763 - acc: 0.8242 - val_loss: 0.4089 - val_acc: 0.8120\n",
      "Epoch 169/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3743 - acc: 0.8218 - val_loss: 0.4085 - val_acc: 0.8132\n",
      "Epoch 170/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3702 - acc: 0.8289 - val_loss: 0.4085 - val_acc: 0.8130\n",
      "Epoch 171/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3714 - acc: 0.8280 - val_loss: 0.4085 - val_acc: 0.8132\n",
      "Epoch 172/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3831 - acc: 0.8255 - val_loss: 0.4087 - val_acc: 0.8130\n",
      "Epoch 173/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3833 - acc: 0.8214 - val_loss: 0.4085 - val_acc: 0.8132\n",
      "Epoch 174/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3627 - acc: 0.8314 - val_loss: 0.4079 - val_acc: 0.8140\n",
      "Epoch 175/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3761 - acc: 0.8246 - val_loss: 0.4085 - val_acc: 0.8128\n",
      "Epoch 176/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3698 - acc: 0.8294 - val_loss: 0.4078 - val_acc: 0.8132\n",
      "Epoch 177/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3653 - acc: 0.8307 - val_loss: 0.4074 - val_acc: 0.8134\n",
      "Epoch 178/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3708 - acc: 0.8290 - val_loss: 0.4074 - val_acc: 0.8130\n",
      "Epoch 179/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3683 - acc: 0.8297 - val_loss: 0.4078 - val_acc: 0.8120\n",
      "Epoch 180/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3763 - acc: 0.8230 - val_loss: 0.4075 - val_acc: 0.8136\n",
      "Epoch 181/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3696 - acc: 0.8261 - val_loss: 0.4077 - val_acc: 0.8126\n",
      "Epoch 182/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3709 - acc: 0.8285 - val_loss: 0.4070 - val_acc: 0.8132\n",
      "Epoch 183/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3592 - acc: 0.8310 - val_loss: 0.4073 - val_acc: 0.8128\n",
      "Epoch 184/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3745 - acc: 0.8222 - val_loss: 0.4080 - val_acc: 0.8136\n",
      "Epoch 185/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3723 - acc: 0.8231 - val_loss: 0.4073 - val_acc: 0.8122\n",
      "Epoch 186/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3799 - acc: 0.8209 - val_loss: 0.4068 - val_acc: 0.8146\n",
      "Epoch 187/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3718 - acc: 0.8308 - val_loss: 0.4070 - val_acc: 0.8136\n",
      "Epoch 188/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3735 - acc: 0.8244 - val_loss: 0.4074 - val_acc: 0.8134\n",
      "Epoch 189/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3680 - acc: 0.8317 - val_loss: 0.4072 - val_acc: 0.8138\n",
      "Epoch 190/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3794 - acc: 0.8258 - val_loss: 0.4078 - val_acc: 0.8140\n",
      "Epoch 191/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3661 - acc: 0.8278 - val_loss: 0.4083 - val_acc: 0.8144\n",
      "Epoch 192/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3705 - acc: 0.8285 - val_loss: 0.4072 - val_acc: 0.8132\n",
      "Epoch 193/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3775 - acc: 0.8229 - val_loss: 0.4070 - val_acc: 0.8134\n",
      "Epoch 194/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3766 - acc: 0.8250 - val_loss: 0.4063 - val_acc: 0.8142\n",
      "Epoch 195/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3818 - acc: 0.8233 - val_loss: 0.4073 - val_acc: 0.8134\n",
      "Epoch 196/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3653 - acc: 0.8318 - val_loss: 0.4068 - val_acc: 0.8140\n",
      "Epoch 197/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3771 - acc: 0.8272 - val_loss: 0.4068 - val_acc: 0.8132\n",
      "Epoch 198/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3698 - acc: 0.8303 - val_loss: 0.4066 - val_acc: 0.8136\n",
      "Epoch 199/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3630 - acc: 0.8340 - val_loss: 0.4060 - val_acc: 0.8138\n",
      "Epoch 200/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3733 - acc: 0.8257 - val_loss: 0.4061 - val_acc: 0.8138\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=30)\n",
    "mc = ModelCheckpoint('best_model_2.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "history = model2.fit(partial_X_train,\n",
    "                    partial_Y_train,\n",
    "                    epochs=200,\n",
    "                    batch_size=512,\n",
    "                    callbacks = [es,mc],\n",
    "                    validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 0.5087128281593323\n",
      "Test accuracy 0.8101016879081726\n"
     ]
    }
   ],
   "source": [
    "model2.load_weights('best_model_2.h5')\n",
    "score = model2.evaluate(X_test, Y_test, verbose = 0)\n",
    "\n",
    "print('Test Loss', score[0])\n",
    "print('Test accuracy', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "acc_values = history_dict['acc'] \n",
    "val_acc_values = history_dict['val_acc']\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN modelo 7\n",
    "Defining the model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "model3 = models.Sequential()\n",
    "model3.add(layers.Dense(32,input_shape=(partial_X_train.shape[1], partial_X_train.shape[2]), activation='relu'))\n",
    "model3.add(layers.Dense(64, activation='relu'))\n",
    "model3.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model and plotting errors along the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer='Adamax',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 [==============================] - 1s 28ms/step - loss: 0.7073 - acc: 0.4711 - val_loss: 0.6632 - val_acc: 0.5422\n",
      "Epoch 2/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6485 - acc: 0.5675 - val_loss: 0.6297 - val_acc: 0.6362\n",
      "Epoch 3/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6136 - acc: 0.6580 - val_loss: 0.6051 - val_acc: 0.6932\n",
      "Epoch 4/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5911 - acc: 0.7048 - val_loss: 0.5858 - val_acc: 0.7188\n",
      "Epoch 5/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5733 - acc: 0.7222 - val_loss: 0.5700 - val_acc: 0.7254\n",
      "Epoch 6/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5583 - acc: 0.7350 - val_loss: 0.5566 - val_acc: 0.7314\n",
      "Epoch 7/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5439 - acc: 0.7332 - val_loss: 0.5449 - val_acc: 0.7322\n",
      "Epoch 8/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5303 - acc: 0.7476 - val_loss: 0.5347 - val_acc: 0.7344\n",
      "Epoch 9/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5199 - acc: 0.7493 - val_loss: 0.5255 - val_acc: 0.7394\n",
      "Epoch 10/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5066 - acc: 0.7622 - val_loss: 0.5171 - val_acc: 0.7418\n",
      "Epoch 11/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5036 - acc: 0.7562 - val_loss: 0.5096 - val_acc: 0.7450\n",
      "Epoch 12/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4934 - acc: 0.7629 - val_loss: 0.5027 - val_acc: 0.7478\n",
      "Epoch 13/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4898 - acc: 0.7624 - val_loss: 0.4965 - val_acc: 0.7524\n",
      "Epoch 14/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4761 - acc: 0.7777 - val_loss: 0.4909 - val_acc: 0.7564\n",
      "Epoch 15/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4735 - acc: 0.7675 - val_loss: 0.4858 - val_acc: 0.7592\n",
      "Epoch 16/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4651 - acc: 0.7783 - val_loss: 0.4810 - val_acc: 0.7606\n",
      "Epoch 17/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4751 - acc: 0.7707 - val_loss: 0.4767 - val_acc: 0.7650\n",
      "Epoch 18/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4640 - acc: 0.7728 - val_loss: 0.4730 - val_acc: 0.7656\n",
      "Epoch 19/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4571 - acc: 0.7801 - val_loss: 0.4695 - val_acc: 0.7680\n",
      "Epoch 20/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4620 - acc: 0.7729 - val_loss: 0.4666 - val_acc: 0.7676\n",
      "Epoch 21/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4554 - acc: 0.7739 - val_loss: 0.4640 - val_acc: 0.7702\n",
      "Epoch 22/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4438 - acc: 0.7839 - val_loss: 0.4615 - val_acc: 0.7728\n",
      "Epoch 23/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4464 - acc: 0.7879 - val_loss: 0.4589 - val_acc: 0.7738\n",
      "Epoch 24/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4443 - acc: 0.7846 - val_loss: 0.4567 - val_acc: 0.7762\n",
      "Epoch 25/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4387 - acc: 0.7901 - val_loss: 0.4548 - val_acc: 0.7786\n",
      "Epoch 26/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4368 - acc: 0.7931 - val_loss: 0.4529 - val_acc: 0.7792\n",
      "Epoch 27/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4404 - acc: 0.7920 - val_loss: 0.4511 - val_acc: 0.7792\n",
      "Epoch 28/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4330 - acc: 0.7958 - val_loss: 0.4494 - val_acc: 0.7822\n",
      "Epoch 29/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4401 - acc: 0.7908 - val_loss: 0.4479 - val_acc: 0.7822\n",
      "Epoch 30/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4348 - acc: 0.7897 - val_loss: 0.4466 - val_acc: 0.7826\n",
      "Epoch 31/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4313 - acc: 0.7953 - val_loss: 0.4451 - val_acc: 0.7848\n",
      "Epoch 32/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4268 - acc: 0.7982 - val_loss: 0.4440 - val_acc: 0.7844\n",
      "Epoch 33/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4334 - acc: 0.7896 - val_loss: 0.4426 - val_acc: 0.7864\n",
      "Epoch 34/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4322 - acc: 0.7940 - val_loss: 0.4414 - val_acc: 0.7858\n",
      "Epoch 35/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4313 - acc: 0.7947 - val_loss: 0.4404 - val_acc: 0.7872\n",
      "Epoch 36/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4205 - acc: 0.8026 - val_loss: 0.4395 - val_acc: 0.7882\n",
      "Epoch 37/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4148 - acc: 0.8044 - val_loss: 0.4384 - val_acc: 0.7890\n",
      "Epoch 38/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4245 - acc: 0.7997 - val_loss: 0.4373 - val_acc: 0.7904\n",
      "Epoch 39/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4224 - acc: 0.8033 - val_loss: 0.4365 - val_acc: 0.7906\n",
      "Epoch 40/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4163 - acc: 0.8038 - val_loss: 0.4358 - val_acc: 0.7904\n",
      "Epoch 41/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4122 - acc: 0.8067 - val_loss: 0.4350 - val_acc: 0.7916\n",
      "Epoch 42/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4176 - acc: 0.8021 - val_loss: 0.4340 - val_acc: 0.7928\n",
      "Epoch 43/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4190 - acc: 0.8055 - val_loss: 0.4333 - val_acc: 0.7926\n",
      "Epoch 44/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4123 - acc: 0.8016 - val_loss: 0.4325 - val_acc: 0.7936\n",
      "Epoch 45/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4188 - acc: 0.8017 - val_loss: 0.4318 - val_acc: 0.7928\n",
      "Epoch 46/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4177 - acc: 0.8044 - val_loss: 0.4308 - val_acc: 0.7934\n",
      "Epoch 47/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4057 - acc: 0.8121 - val_loss: 0.4303 - val_acc: 0.7916\n",
      "Epoch 48/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4199 - acc: 0.8039 - val_loss: 0.4298 - val_acc: 0.7944\n",
      "Epoch 49/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4123 - acc: 0.8086 - val_loss: 0.4292 - val_acc: 0.7942\n",
      "Epoch 50/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4069 - acc: 0.8151 - val_loss: 0.4286 - val_acc: 0.7952\n",
      "Epoch 51/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4022 - acc: 0.8115 - val_loss: 0.4279 - val_acc: 0.7954\n",
      "Epoch 52/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4117 - acc: 0.8096 - val_loss: 0.4273 - val_acc: 0.7964\n",
      "Epoch 53/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3997 - acc: 0.8178 - val_loss: 0.4266 - val_acc: 0.7984\n",
      "Epoch 54/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4040 - acc: 0.8190 - val_loss: 0.4261 - val_acc: 0.7994\n",
      "Epoch 55/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3928 - acc: 0.8264 - val_loss: 0.4262 - val_acc: 0.7992\n",
      "Epoch 56/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4053 - acc: 0.8136 - val_loss: 0.4253 - val_acc: 0.7998\n",
      "Epoch 57/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4106 - acc: 0.8191 - val_loss: 0.4245 - val_acc: 0.7996\n",
      "Epoch 58/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3993 - acc: 0.8196 - val_loss: 0.4243 - val_acc: 0.8000\n",
      "Epoch 59/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3955 - acc: 0.8184 - val_loss: 0.4241 - val_acc: 0.8006\n",
      "Epoch 60/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3967 - acc: 0.8213 - val_loss: 0.4235 - val_acc: 0.8010\n",
      "Epoch 61/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3982 - acc: 0.8160 - val_loss: 0.4231 - val_acc: 0.8018\n",
      "Epoch 62/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3943 - acc: 0.8222 - val_loss: 0.4228 - val_acc: 0.8032\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4003 - acc: 0.8202 - val_loss: 0.4223 - val_acc: 0.8032\n",
      "Epoch 64/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4033 - acc: 0.8142 - val_loss: 0.4220 - val_acc: 0.8030\n",
      "Epoch 65/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4041 - acc: 0.8116 - val_loss: 0.4219 - val_acc: 0.8018\n",
      "Epoch 66/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3949 - acc: 0.8201 - val_loss: 0.4215 - val_acc: 0.8038\n",
      "Epoch 67/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3940 - acc: 0.8180 - val_loss: 0.4207 - val_acc: 0.8042\n",
      "Epoch 68/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3899 - acc: 0.8261 - val_loss: 0.4205 - val_acc: 0.8052\n",
      "Epoch 69/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3950 - acc: 0.8186 - val_loss: 0.4205 - val_acc: 0.8066\n",
      "Epoch 70/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3972 - acc: 0.8239 - val_loss: 0.4203 - val_acc: 0.8038\n",
      "Epoch 71/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3924 - acc: 0.8246 - val_loss: 0.4198 - val_acc: 0.8050\n",
      "Epoch 72/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3989 - acc: 0.8237 - val_loss: 0.4202 - val_acc: 0.8060\n",
      "Epoch 73/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3984 - acc: 0.8279 - val_loss: 0.4192 - val_acc: 0.8076\n",
      "Epoch 74/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3948 - acc: 0.8178 - val_loss: 0.4191 - val_acc: 0.8064\n",
      "Epoch 75/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4006 - acc: 0.8196 - val_loss: 0.4189 - val_acc: 0.8064\n",
      "Epoch 76/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3938 - acc: 0.8248 - val_loss: 0.4187 - val_acc: 0.8074\n",
      "Epoch 77/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4023 - acc: 0.8172 - val_loss: 0.4183 - val_acc: 0.8080\n",
      "Epoch 78/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3854 - acc: 0.8289 - val_loss: 0.4182 - val_acc: 0.8080\n",
      "Epoch 79/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3962 - acc: 0.8234 - val_loss: 0.4177 - val_acc: 0.8086\n",
      "Epoch 80/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3871 - acc: 0.8238 - val_loss: 0.4180 - val_acc: 0.8080\n",
      "Epoch 81/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3876 - acc: 0.8252 - val_loss: 0.4172 - val_acc: 0.8102\n",
      "Epoch 82/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3854 - acc: 0.8241 - val_loss: 0.4173 - val_acc: 0.8090\n",
      "Epoch 83/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3914 - acc: 0.8218 - val_loss: 0.4170 - val_acc: 0.8100\n",
      "Epoch 84/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3967 - acc: 0.8218 - val_loss: 0.4168 - val_acc: 0.8112\n",
      "Epoch 85/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3926 - acc: 0.8247 - val_loss: 0.4168 - val_acc: 0.8104\n",
      "Epoch 86/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3837 - acc: 0.8240 - val_loss: 0.4165 - val_acc: 0.8108\n",
      "Epoch 87/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3889 - acc: 0.8232 - val_loss: 0.4162 - val_acc: 0.8110\n",
      "Epoch 88/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3830 - acc: 0.8283 - val_loss: 0.4160 - val_acc: 0.8112\n",
      "Epoch 89/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3848 - acc: 0.8246 - val_loss: 0.4160 - val_acc: 0.8114\n",
      "Epoch 90/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3818 - acc: 0.8249 - val_loss: 0.4162 - val_acc: 0.8116\n",
      "Epoch 91/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3766 - acc: 0.8313 - val_loss: 0.4156 - val_acc: 0.8110\n",
      "Epoch 92/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3799 - acc: 0.8341 - val_loss: 0.4157 - val_acc: 0.8126\n",
      "Epoch 93/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3765 - acc: 0.8314 - val_loss: 0.4157 - val_acc: 0.8128\n",
      "Epoch 94/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3747 - acc: 0.8318 - val_loss: 0.4150 - val_acc: 0.8128\n",
      "Epoch 95/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3869 - acc: 0.8242 - val_loss: 0.4152 - val_acc: 0.8128\n",
      "Epoch 96/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3761 - acc: 0.8295 - val_loss: 0.4149 - val_acc: 0.8132\n",
      "Epoch 97/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3868 - acc: 0.8259 - val_loss: 0.4151 - val_acc: 0.8132\n",
      "Epoch 98/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3882 - acc: 0.8240 - val_loss: 0.4152 - val_acc: 0.8132\n",
      "Epoch 99/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3753 - acc: 0.8274 - val_loss: 0.4147 - val_acc: 0.8126\n",
      "Epoch 100/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3752 - acc: 0.8327 - val_loss: 0.4146 - val_acc: 0.8140\n",
      "Epoch 101/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3842 - acc: 0.8252 - val_loss: 0.4146 - val_acc: 0.8142\n",
      "Epoch 102/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3756 - acc: 0.8305 - val_loss: 0.4143 - val_acc: 0.8126\n",
      "Epoch 103/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3722 - acc: 0.8390 - val_loss: 0.4145 - val_acc: 0.8144\n",
      "Epoch 104/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3772 - acc: 0.8284 - val_loss: 0.4141 - val_acc: 0.8128\n",
      "Epoch 105/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3729 - acc: 0.8336 - val_loss: 0.4145 - val_acc: 0.8136\n",
      "Epoch 106/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3874 - acc: 0.8175 - val_loss: 0.4139 - val_acc: 0.8142\n",
      "Epoch 107/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3707 - acc: 0.8337 - val_loss: 0.4142 - val_acc: 0.8148\n",
      "Epoch 108/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3824 - acc: 0.8262 - val_loss: 0.4137 - val_acc: 0.8146\n",
      "Epoch 109/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3752 - acc: 0.8283 - val_loss: 0.4136 - val_acc: 0.8142\n",
      "Epoch 110/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3772 - acc: 0.8295 - val_loss: 0.4142 - val_acc: 0.8132\n",
      "Epoch 111/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3735 - acc: 0.8298 - val_loss: 0.4136 - val_acc: 0.8144\n",
      "Epoch 112/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3711 - acc: 0.8332 - val_loss: 0.4135 - val_acc: 0.8132\n",
      "Epoch 113/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3841 - acc: 0.8239 - val_loss: 0.4133 - val_acc: 0.8140\n",
      "Epoch 114/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3681 - acc: 0.8303 - val_loss: 0.4137 - val_acc: 0.8142\n",
      "Epoch 115/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3718 - acc: 0.8288 - val_loss: 0.4133 - val_acc: 0.8138\n",
      "Epoch 116/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3756 - acc: 0.8303 - val_loss: 0.4132 - val_acc: 0.8134\n",
      "Epoch 117/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3660 - acc: 0.8348 - val_loss: 0.4131 - val_acc: 0.8142\n",
      "Epoch 118/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3771 - acc: 0.8315 - val_loss: 0.4129 - val_acc: 0.8144\n",
      "Epoch 119/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3806 - acc: 0.8283 - val_loss: 0.4129 - val_acc: 0.8138\n",
      "Epoch 120/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3696 - acc: 0.8363 - val_loss: 0.4131 - val_acc: 0.8142\n",
      "Epoch 121/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3719 - acc: 0.8343 - val_loss: 0.4128 - val_acc: 0.8140\n",
      "Epoch 122/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3710 - acc: 0.8329 - val_loss: 0.4127 - val_acc: 0.8136\n",
      "Epoch 123/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3751 - acc: 0.8319 - val_loss: 0.4129 - val_acc: 0.8134\n",
      "Epoch 124/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3716 - acc: 0.8306 - val_loss: 0.4127 - val_acc: 0.8140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3725 - acc: 0.8301 - val_loss: 0.4125 - val_acc: 0.8146\n",
      "Epoch 126/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3581 - acc: 0.8330 - val_loss: 0.4123 - val_acc: 0.8140\n",
      "Epoch 127/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3831 - acc: 0.8219 - val_loss: 0.4125 - val_acc: 0.8136\n",
      "Epoch 128/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3748 - acc: 0.8322 - val_loss: 0.4123 - val_acc: 0.8142\n",
      "Epoch 129/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3749 - acc: 0.8261 - val_loss: 0.4122 - val_acc: 0.8134\n",
      "Epoch 130/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3670 - acc: 0.8328 - val_loss: 0.4120 - val_acc: 0.8146\n",
      "Epoch 131/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3664 - acc: 0.8304 - val_loss: 0.4122 - val_acc: 0.8144\n",
      "Epoch 132/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3721 - acc: 0.8244 - val_loss: 0.4121 - val_acc: 0.8134\n",
      "Epoch 133/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3576 - acc: 0.8393 - val_loss: 0.4121 - val_acc: 0.8146\n",
      "Epoch 134/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3741 - acc: 0.8261 - val_loss: 0.4120 - val_acc: 0.8144\n",
      "Epoch 135/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3715 - acc: 0.8302 - val_loss: 0.4119 - val_acc: 0.8134\n",
      "Epoch 136/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3695 - acc: 0.8324 - val_loss: 0.4117 - val_acc: 0.8142\n",
      "Epoch 137/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3636 - acc: 0.8334 - val_loss: 0.4118 - val_acc: 0.8138\n",
      "Epoch 138/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3638 - acc: 0.8356 - val_loss: 0.4118 - val_acc: 0.8142\n",
      "Epoch 139/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3698 - acc: 0.8342 - val_loss: 0.4113 - val_acc: 0.8152\n",
      "Epoch 140/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3674 - acc: 0.8327 - val_loss: 0.4119 - val_acc: 0.8150\n",
      "Epoch 141/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3711 - acc: 0.8296 - val_loss: 0.4118 - val_acc: 0.8140\n",
      "Epoch 142/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3631 - acc: 0.8358 - val_loss: 0.4116 - val_acc: 0.8144\n",
      "Epoch 143/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3598 - acc: 0.8366 - val_loss: 0.4113 - val_acc: 0.8144\n",
      "Epoch 144/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3664 - acc: 0.8299 - val_loss: 0.4115 - val_acc: 0.8150\n",
      "Epoch 145/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3685 - acc: 0.8315 - val_loss: 0.4113 - val_acc: 0.8148\n",
      "Epoch 146/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3629 - acc: 0.8364 - val_loss: 0.4124 - val_acc: 0.8136\n",
      "Epoch 147/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3667 - acc: 0.8338 - val_loss: 0.4115 - val_acc: 0.8152\n",
      "Epoch 148/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3648 - acc: 0.8385 - val_loss: 0.4109 - val_acc: 0.8162\n",
      "Epoch 149/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3592 - acc: 0.8345 - val_loss: 0.4114 - val_acc: 0.8154\n",
      "Epoch 150/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3699 - acc: 0.8330 - val_loss: 0.4114 - val_acc: 0.8160\n",
      "Epoch 151/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3596 - acc: 0.8339 - val_loss: 0.4114 - val_acc: 0.8140\n",
      "Epoch 152/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3654 - acc: 0.8325 - val_loss: 0.4111 - val_acc: 0.8168\n",
      "Epoch 153/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3660 - acc: 0.8316 - val_loss: 0.4113 - val_acc: 0.8140\n",
      "Epoch 154/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3615 - acc: 0.8361 - val_loss: 0.4112 - val_acc: 0.8152\n",
      "Epoch 155/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3543 - acc: 0.8395 - val_loss: 0.4111 - val_acc: 0.8156\n",
      "Epoch 156/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3701 - acc: 0.8321 - val_loss: 0.4111 - val_acc: 0.8152\n",
      "Epoch 157/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3602 - acc: 0.8356 - val_loss: 0.4113 - val_acc: 0.8154\n",
      "Epoch 158/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3560 - acc: 0.8392 - val_loss: 0.4110 - val_acc: 0.8162\n",
      "Epoch 159/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3524 - acc: 0.8425 - val_loss: 0.4113 - val_acc: 0.8136\n",
      "Epoch 160/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3478 - acc: 0.8413 - val_loss: 0.4109 - val_acc: 0.8158\n",
      "Epoch 161/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3582 - acc: 0.8407 - val_loss: 0.4112 - val_acc: 0.8156\n",
      "Epoch 162/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3583 - acc: 0.8424 - val_loss: 0.4112 - val_acc: 0.8152\n",
      "Epoch 163/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3510 - acc: 0.8436 - val_loss: 0.4110 - val_acc: 0.8162\n",
      "Epoch 164/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3609 - acc: 0.8359 - val_loss: 0.4113 - val_acc: 0.8164\n",
      "Epoch 165/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3675 - acc: 0.8297 - val_loss: 0.4111 - val_acc: 0.8152\n",
      "Epoch 166/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3578 - acc: 0.8354 - val_loss: 0.4109 - val_acc: 0.8162\n",
      "Epoch 167/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3553 - acc: 0.8402 - val_loss: 0.4107 - val_acc: 0.8168\n",
      "Epoch 168/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3718 - acc: 0.8299 - val_loss: 0.4112 - val_acc: 0.8140\n",
      "Epoch 169/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3591 - acc: 0.8354 - val_loss: 0.4113 - val_acc: 0.8182\n",
      "Epoch 170/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3630 - acc: 0.8385 - val_loss: 0.4110 - val_acc: 0.8148\n",
      "Epoch 171/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3632 - acc: 0.8334 - val_loss: 0.4105 - val_acc: 0.8168\n",
      "Epoch 172/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3661 - acc: 0.8308 - val_loss: 0.4110 - val_acc: 0.8164\n",
      "Epoch 173/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3575 - acc: 0.8356 - val_loss: 0.4112 - val_acc: 0.8170\n",
      "Epoch 174/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3551 - acc: 0.8424 - val_loss: 0.4104 - val_acc: 0.8172\n",
      "Epoch 175/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3532 - acc: 0.8392 - val_loss: 0.4106 - val_acc: 0.8160\n",
      "Epoch 176/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3605 - acc: 0.8354 - val_loss: 0.4112 - val_acc: 0.8166\n",
      "Epoch 177/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3594 - acc: 0.8348 - val_loss: 0.4109 - val_acc: 0.8164\n",
      "Epoch 178/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3504 - acc: 0.8401 - val_loss: 0.4106 - val_acc: 0.8176\n",
      "Epoch 179/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3541 - acc: 0.8395 - val_loss: 0.4108 - val_acc: 0.8168\n",
      "Epoch 180/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3575 - acc: 0.8388 - val_loss: 0.4108 - val_acc: 0.8176\n",
      "Epoch 181/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3518 - acc: 0.8427 - val_loss: 0.4105 - val_acc: 0.8174\n",
      "Epoch 182/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3540 - acc: 0.8440 - val_loss: 0.4111 - val_acc: 0.8170\n",
      "Epoch 183/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3486 - acc: 0.8444 - val_loss: 0.4110 - val_acc: 0.8170\n",
      "Epoch 184/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3486 - acc: 0.8466 - val_loss: 0.4104 - val_acc: 0.8182\n",
      "Epoch 185/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3549 - acc: 0.8416 - val_loss: 0.4112 - val_acc: 0.8166\n",
      "Epoch 186/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3636 - acc: 0.8353 - val_loss: 0.4105 - val_acc: 0.8180\n",
      "Epoch 187/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3521 - acc: 0.8451 - val_loss: 0.4105 - val_acc: 0.8178\n",
      "Epoch 188/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3581 - acc: 0.8401 - val_loss: 0.4111 - val_acc: 0.8152\n",
      "Epoch 189/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3576 - acc: 0.8400 - val_loss: 0.4106 - val_acc: 0.8188\n",
      "Epoch 190/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3594 - acc: 0.8360 - val_loss: 0.4109 - val_acc: 0.8182\n",
      "Epoch 191/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3582 - acc: 0.8440 - val_loss: 0.4110 - val_acc: 0.8176\n",
      "Epoch 192/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3636 - acc: 0.8327 - val_loss: 0.4106 - val_acc: 0.8188\n",
      "Epoch 193/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3505 - acc: 0.8414 - val_loss: 0.4108 - val_acc: 0.8168\n",
      "Epoch 194/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3542 - acc: 0.8379 - val_loss: 0.4106 - val_acc: 0.8188\n",
      "Epoch 195/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3533 - acc: 0.8406 - val_loss: 0.4109 - val_acc: 0.8182\n",
      "Epoch 196/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3564 - acc: 0.8388 - val_loss: 0.4106 - val_acc: 0.8176\n",
      "Epoch 197/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3542 - acc: 0.8418 - val_loss: 0.4112 - val_acc: 0.8196\n",
      "Epoch 198/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3496 - acc: 0.8455 - val_loss: 0.4111 - val_acc: 0.8172\n",
      "Epoch 199/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3483 - acc: 0.8402 - val_loss: 0.4106 - val_acc: 0.8180\n",
      "Epoch 200/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3508 - acc: 0.8443 - val_loss: 0.4103 - val_acc: 0.8178\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=30)\n",
    "mc = ModelCheckpoint('best_model_3.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "history = model3.fit(partial_X_train,\n",
    "                    partial_Y_train,\n",
    "                    epochs=200,\n",
    "                    batch_size=512,\n",
    "                    callbacks = [es,mc],\n",
    "                    validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 0.4994361698627472\n",
      "Test accuracy 0.8193943500518799\n"
     ]
    }
   ],
   "source": [
    "model3.load_weights('best_model_3.h5')\n",
    "score = model3.evaluate(X_test, Y_test, verbose = 0)\n",
    "\n",
    "print('Test Loss', score[0])\n",
    "print('Test accuracy', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "acc_values = history_dict['acc'] \n",
    "val_acc_values = history_dict['val_acc']\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
